2025-01-13 22:32:07,119 - scrapy.utils.log - INFO - Scrapy 2.12.0 started (bot: scraper)
2025-01-13 22:32:07,144 - scrapy.utils.log - INFO - Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-10-10.0.22631-SP0
2025-01-13 22:32:07,147 - scrapy.addons - INFO - Enabled addons:
[]
2025-01-13 22:32:07,147 - asyncio - DEBUG - Using selector: SelectSelector
2025-01-13 22:32:07,149 - scrapy.utils.log - DEBUG - Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-13 22:32:07,149 - scrapy.utils.log - DEBUG - Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-01-13 22:32:07,150 - scrapy.utils.log - DEBUG - Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-13 22:32:07,150 - scrapy.utils.log - DEBUG - Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-01-13 22:32:07,161 - scrapy.extensions.telnet - INFO - Telnet Password: 88fa259b2f46dd92
2025-01-13 22:32:07,186 - scrapy.middleware - INFO - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-01-13 22:32:07,186 - scrapy.crawler - INFO - Overridden settings:
{'BOT_NAME': 'scraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-13 22:32:07,469 - scrapy.middleware - INFO - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-13 22:32:07,481 - scrapy.middleware - INFO - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-13 22:32:07,501 - twisted - CRITICAL - Unhandled error in Deferred:
2025-01-13 22:32:07,507 - twisted - CRITICAL - 
Traceback (most recent call last):
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\twisted\internet\defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\core\engine.py", line 102, in __init__
    self.scraper: Scraper = Scraper(crawler)
                            ^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\core\scraper.py", line 101, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\AJS\Desktop\DS Projects\deepmind-search-engine\.venv\Lib\site-packages\scrapy\utils\misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1126, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_crawler'
2025-01-13 22:33:53,687 - scrapy.utils.log - INFO - Scrapy 2.12.0 started (bot: scraper)
2025-01-13 22:33:53,717 - scrapy.utils.log - INFO - Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-10-10.0.22631-SP0
2025-01-13 22:33:53,720 - scrapy.addons - INFO - Enabled addons:
[]
2025-01-13 22:33:53,720 - asyncio - DEBUG - Using selector: SelectSelector
2025-01-13 22:33:53,722 - scrapy.utils.log - DEBUG - Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-13 22:33:53,722 - scrapy.utils.log - DEBUG - Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-01-13 22:33:53,723 - scrapy.utils.log - DEBUG - Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-13 22:33:53,723 - scrapy.utils.log - DEBUG - Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-01-13 22:33:53,728 - scrapy.extensions.telnet - INFO - Telnet Password: 63a0414e3a55735e
2025-01-13 22:33:53,750 - scrapy.middleware - INFO - Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-01-13 22:33:53,752 - scrapy.crawler - INFO - Overridden settings:
{'BOT_NAME': 'scraper',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'NEWSPIDER_MODULE': 'scraper.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-13 22:33:53,967 - scrapy.middleware - INFO - Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-13 22:33:53,973 - scrapy.middleware - INFO - Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-13 22:33:53,980 - scrapy.middleware - INFO - Enabled item pipelines:
['scraper.pipelines.SQLitePipeline']
2025-01-13 22:33:53,981 - scrapy.core.engine - INFO - Spider opened
2025-01-13 22:33:54,030 - scrapy.extensions.logstats - INFO - Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-13 22:33:54,031 - scrapy.extensions.telnet - INFO - Telnet console listening on 127.0.0.1:6023
2025-01-13 22:33:54,309 - scrapy.core.engine - DEBUG - Crawled (404) <GET https://deepmind.google/robots.txt> (referer: None)
2025-01-13 22:33:54,310 - protego - DEBUG - Rule at line 9 without any user agent to enforce it on.
2025-01-13 22:33:54,310 - protego - DEBUG - Rule at line 15 without any user agent to enforce it on.
2025-01-13 22:33:54,310 - protego - DEBUG - Rule at line 16 without any user agent to enforce it on.
2025-01-13 22:33:54,311 - protego - DEBUG - Rule at line 17 without any user agent to enforce it on.
2025-01-13 22:33:54,311 - protego - DEBUG - Rule at line 18 without any user agent to enforce it on.
2025-01-13 22:33:54,312 - protego - DEBUG - Rule at line 19 without any user agent to enforce it on.
2025-01-13 22:33:54,312 - protego - DEBUG - Rule at line 116 without any user agent to enforce it on.
2025-01-13 22:33:54,313 - protego - DEBUG - Rule at line 234 without any user agent to enforce it on.
2025-01-13 22:33:54,313 - protego - DEBUG - Rule at line 274 without any user agent to enforce it on.
2025-01-13 22:33:54,313 - protego - DEBUG - Rule at line 283 without any user agent to enforce it on.
2025-01-13 22:33:54,314 - protego - DEBUG - Rule at line 292 without any user agent to enforce it on.
2025-01-13 22:33:54,314 - protego - DEBUG - Rule at line 301 without any user agent to enforce it on.
2025-01-13 22:33:54,314 - protego - DEBUG - Rule at line 310 without any user agent to enforce it on.
2025-01-13 22:33:54,315 - protego - DEBUG - Rule at line 327 without any user agent to enforce it on.
2025-01-13 22:33:54,315 - protego - DEBUG - Rule at line 335 without any user agent to enforce it on.
2025-01-13 22:33:54,316 - protego - DEBUG - Rule at line 338 without any user agent to enforce it on.
2025-01-13 22:33:54,316 - protego - DEBUG - Rule at line 341 without any user agent to enforce it on.
2025-01-13 22:33:54,316 - protego - DEBUG - Rule at line 344 without any user agent to enforce it on.
2025-01-13 22:33:54,317 - protego - DEBUG - Rule at line 362 without any user agent to enforce it on.
2025-01-13 22:33:54,317 - protego - DEBUG - Rule at line 374 without any user agent to enforce it on.
2025-01-13 22:33:54,317 - protego - DEBUG - Rule at line 377 without any user agent to enforce it on.
2025-01-13 22:33:54,317 - protego - DEBUG - Rule at line 387 without any user agent to enforce it on.
2025-01-13 22:33:54,318 - protego - DEBUG - Rule at line 388 without any user agent to enforce it on.
2025-01-13 22:33:54,559 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/> (referer: None)
2025-01-13 22:33:54,670 - root - INFO - Parsing URL: https://deepmind.google/research/publications/
2025-01-13 22:33:54,938 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/101479/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:54,946 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/133302/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:55,091 - root - INFO - Scraped item: {'abstract': 'We articulate fundamental mismatches between technical methods '
             'for machine unlearning in Generative AI, and documented '
             'aspirations for broader impact that these methods could have for '
             'law and policy. These aspirations are both numerous and varied, '
             'motivated by issues that pertain to privacy, copyright, safety, '
             'and more. For example, unlearning is often invoked as a solution '
             'for removing the effects of targeted information from a '
             'generative-AI model’s parameters, e.g., a particular '
             'individual’s personal data or in-copyright expression of '
             'Spiderman that was included in the model’s training data. '
             'Unlearning is also proposed as a way to prevent a model from '
             'generating targeted types of information in its outputs, e.g., '
             'generations that closely resemble a particular individual’s data '
             'or reflect the concept of “Spiderman.” Both of these goals—the '
             'targeted removal of information from a model and the targeted '
             'suppression of information from a model’s outputs—present '
             'various technical and substantive challenges. We provide a '
             'framework for thinking rigorously about these challenges, which '
             'enables us to be clear about why unlearning is not a '
             'general-purpose solution for circumscribing generative-AI model '
             'behavior in service of broader positive impact. We aim for '
             'conceptual clarity and to encourage more thoughtful '
             'communication among machine learning (ML), law, and policy '
             'experts who seek to develop and apply technical methods for '
             'compliance with policy objectives.',
 'title': 'Machine Unlearning Doesn’t Do What You Think: Lessons for '
          'Generative AI Policy, Research, and Practice',
 'url': 'https://deepmind.google/research/publications/101479/'}
2025-01-13 22:33:55,103 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/101479/>
{'abstract': 'We articulate fundamental mismatches between technical methods '
             'for machine unlearning in Generative AI, and documented '
             'aspirations for broader impact that these methods could have for '
             'law and policy. These aspirations are both numerous and varied, '
             'motivated by issues that pertain to privacy, copyright, safety, '
             'and more. For example, unlearning is often invoked as a solution '
             'for removing the effects of targeted information from a '
             'generative-AI model’s parameters, e.g., a particular '
             'individual’s personal data or in-copyright expression of '
             'Spiderman that was included in the model’s training data. '
             'Unlearning is also proposed as a way to prevent a model from '
             'generating targeted types of information in its outputs, e.g., '
             'generations that closely resemble a particular individual’s data '
             'or reflect the concept of “Spiderman.” Both of these goals—the '
             'targeted removal of information from a model and the targeted '
             'suppression of information from a model’s outputs—present '
             'various technical and substantive challenges. We provide a '
             'framework for thinking rigorously about these challenges, which '
             'enables us to be clear about why unlearning is not a '
             'general-purpose solution for circumscribing generative-AI model '
             'behavior in service of broader positive impact. We aim for '
             'conceptual clarity and to encourage more thoughtful '
             'communication among machine learning (ML), law, and policy '
             'experts who seek to develop and apply technical methods for '
             'compliance with policy objectives.',
 'title': 'Machine Unlearning Doesn’t Do What You Think: Lessons for '
          'Generative AI Policy, Research, and Practice',
 'url': 'https://deepmind.google/research/publications/101479/'}
2025-01-13 22:33:55,142 - root - INFO - Scraped item: {'abstract': "We evaluate the ability of today's LLMs to perform latent "
             'multi-hop reasoning on factual knowledge, or the latent '
             'composability of the models to internally recall and compose the '
             'facts separately learned during training, by assessing the model '
             'completions on multi-hop queries like "In the year Scarlett '
             'Johansson was born, the Summer Olympics were hosted in the '
             'country of".\n'
             'However, it may be challenging to accurately measure the latent '
             'reasoning ability without careful data construction and '
             'evaluation. For example, models may have developed shortcuts by '
             'numerous encounters of the head entity "Scarlett Johansson" and '
             'the answer entity "United States" in the same training sequences '
             'or merely guesses the answer based on frequency-based prior '
             'without going through a multi-hop reasoning process. To take '
             'this account, we propose desiderata about the dataset and '
             'evaluation for shortcut-free evaluation of latent multi-hop '
             'reasoning ability, and construct an evaluation dataset named '
             'SOCRATES (ShOrtCut-fRee lATent rEaSoning) to measure latent '
             'composability as rigorously as possible without access to the '
             'actual pretraining data. To be specific, we select the relation '
             'compositions and facts which would minimize the chance of models '
             'exploiting shortcuts and exclude the test queries where none of '
             'the combinations of the aliases of the head and answer entity '
             'have never appeared together in the any document of multiple '
             'different pretraining corpora, and even Google Search for some '
             'cases, of which the importance is shown through comparison with '
             'the misleading results obtained from a shortcut-prone version of '
             'the data. The experimental results with the shortcut-free '
             "dataset reveal that even today's best models lack generalization "
             'in latent compositionality; the ability differs dramatically '
             'according to the type of the bridge entity. Latent composability '
             'of the best models is only about 5% for the test queries where '
             'the bridge entity is a year, but the number is above 80% when '
             'the bridge entity is a country. Latent composability tends to '
             'increase roughly linearly with respect to the number of known '
             'single-hop facts, and tends to be higher for larger models, but '
             'the rate of increment and the gain from model scale also '
             'significantly differs according to the type of the bridge '
             'entity. Comparisons with Chain-of-Thought composability '
             'highlight a significant gap between latent and explicit '
             'reasoning. By performing initial investigations and drawing '
             'connections to related works, we suggest several unlikely and '
             'plausible hypotheses on the factors that may determine latent '
             'compositionality. In sum, our work provides the resource, '
             'insights, and potential future directions for precise '
             'evaluation, understanding, and improvement of latent reasoning '
             'of LLMs.',
 'title': 'How Well Do Large Language Models Perform Latent Multi-Hop '
          'Reasoning without Exploiting Shortcuts?',
 'url': 'https://deepmind.google/research/publications/133302/'}
2025-01-13 22:33:55,154 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/133302/>
{'abstract': "We evaluate the ability of today's LLMs to perform latent "
             'multi-hop reasoning on factual knowledge, or the latent '
             'composability of the models to internally recall and compose the '
             'facts separately learned during training, by assessing the model '
             'completions on multi-hop queries like "In the year Scarlett '
             'Johansson was born, the Summer Olympics were hosted in the '
             'country of".\n'
             'However, it may be challenging to accurately measure the latent '
             'reasoning ability without careful data construction and '
             'evaluation. For example, models may have developed shortcuts by '
             'numerous encounters of the head entity "Scarlett Johansson" and '
             'the answer entity "United States" in the same training sequences '
             'or merely guesses the answer based on frequency-based prior '
             'without going through a multi-hop reasoning process. To take '
             'this account, we propose desiderata about the dataset and '
             'evaluation for shortcut-free evaluation of latent multi-hop '
             'reasoning ability, and construct an evaluation dataset named '
             'SOCRATES (ShOrtCut-fRee lATent rEaSoning) to measure latent '
             'composability as rigorously as possible without access to the '
             'actual pretraining data. To be specific, we select the relation '
             'compositions and facts which would minimize the chance of models '
             'exploiting shortcuts and exclude the test queries where none of '
             'the combinations of the aliases of the head and answer entity '
             'have never appeared together in the any document of multiple '
             'different pretraining corpora, and even Google Search for some '
             'cases, of which the importance is shown through comparison with '
             'the misleading results obtained from a shortcut-prone version of '
             'the data. The experimental results with the shortcut-free '
             "dataset reveal that even today's best models lack generalization "
             'in latent compositionality; the ability differs dramatically '
             'according to the type of the bridge entity. Latent composability '
             'of the best models is only about 5% for the test queries where '
             'the bridge entity is a year, but the number is above 80% when '
             'the bridge entity is a country. Latent composability tends to '
             'increase roughly linearly with respect to the number of known '
             'single-hop facts, and tends to be higher for larger models, but '
             'the rate of increment and the gain from model scale also '
             'significantly differs according to the type of the bridge '
             'entity. Comparisons with Chain-of-Thought composability '
             'highlight a significant gap between latent and explicit '
             'reasoning. By performing initial investigations and drawing '
             'connections to related works, we suggest several unlikely and '
             'plausible hypotheses on the factors that may determine latent '
             'compositionality. In sum, our work provides the resource, '
             'insights, and potential future directions for precise '
             'evaluation, understanding, and improvement of latent reasoning '
             'of LLMs.',
 'title': 'How Well Do Large Language Models Perform Latent Multi-Hop '
          'Reasoning without Exploiting Shortcuts?',
 'url': 'https://deepmind.google/research/publications/133302/'}
2025-01-13 22:33:55,166 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/9266/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:55,310 - root - INFO - Scraped item: {'abstract': 'Abstract reasoning is a key ability for an intelligent system. '
             'Large language models (LMs) achieve above-chance performance on '
             'abstract reasoning tasks but exhibit many imperfections. '
             'However, human abstract reasoning is also imperfect. Human '
             'reasoning is affected by our real-world knowledge and beliefs, '
             'and shows notable “content effects”; humans reason more reliably '
             'when the semantic content of a problem supports the correct '
             'logical inferences. These content-entangled reasoning patterns '
             'are central to debates about the fundamental nature of human '
             'intelligence. Here, we investigate whether language models—whose '
             'prior expectations capture some aspects of human '
             'knowledge—similarly mix content into their answers to logic '
             'problems. We explored this question across three logical '
             'reasoning tasks: natural language inference, judging the logical '
             'validity of syllogisms, and the Wason selection task. We '
             'evaluate state of the art LMs, as well as humans, and find that '
             'the LMs reflect many of the same qualitative human patterns on '
             'these tasks—like humans, models answer more accurately when the '
             'semantic content of a task supports the logical inferences. '
             'These parallels are reflected in accuracy patterns, and in some '
             'lower-level features like the relationship between LM confidence '
             'over possible answers and human response times. However, in some '
             'cases the humans and models behave differently—particularly on '
             'the Wason task, where humans perform much worse than large '
             'models, and exhibit a distinct error pattern. Our findings have '
             'implications for understanding possible contributors to these '
             'human cognitive effects, as well as the factors that influence '
             'language model performance.',
 'title': 'Language models, like humans, show content effects on reasoning '
          'tasks',
 'url': 'https://deepmind.google/research/publications/9266/'}
2025-01-13 22:33:55,328 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/9266/>
{'abstract': 'Abstract reasoning is a key ability for an intelligent system. '
             'Large language models (LMs) achieve above-chance performance on '
             'abstract reasoning tasks but exhibit many imperfections. '
             'However, human abstract reasoning is also imperfect. Human '
             'reasoning is affected by our real-world knowledge and beliefs, '
             'and shows notable “content effects”; humans reason more reliably '
             'when the semantic content of a problem supports the correct '
             'logical inferences. These content-entangled reasoning patterns '
             'are central to debates about the fundamental nature of human '
             'intelligence. Here, we investigate whether language models—whose '
             'prior expectations capture some aspects of human '
             'knowledge—similarly mix content into their answers to logic '
             'problems. We explored this question across three logical '
             'reasoning tasks: natural language inference, judging the logical '
             'validity of syllogisms, and the Wason selection task. We '
             'evaluate state of the art LMs, as well as humans, and find that '
             'the LMs reflect many of the same qualitative human patterns on '
             'these tasks—like humans, models answer more accurately when the '
             'semantic content of a task supports the logical inferences. '
             'These parallels are reflected in accuracy patterns, and in some '
             'lower-level features like the relationship between LM confidence '
             'over possible answers and human response times. However, in some '
             'cases the humans and models behave differently—particularly on '
             'the Wason task, where humans perform much worse than large '
             'models, and exhibit a distinct error pattern. Our findings have '
             'implications for understanding possible contributors to these '
             'human cognitive effects, as well as the factors that influence '
             'language model performance.',
 'title': 'Language models, like humans, show content effects on reasoning '
          'tasks',
 'url': 'https://deepmind.google/research/publications/9266/'}
2025-01-13 22:33:55,403 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/108549/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:55,541 - root - INFO - Scraped item: {'abstract': 'The visual medium (images and videos) naturally contains a large '
             'amount of information redundancy, thereby providing a great '
             'opportunity for leveraging efficiency in processing. While '
             'Vision Transformer (ViT) based models scale effectively to large '
             'data regimes, they fail to capitalize on this inherent '
             'redundancy, leading to higher computational costs. Mixture of '
             'Experts (MoE) networks demonstrate scalability while maintaining '
             'same inference-time costs, but they come with a larger parameter '
             'footprint. We present Mixture of Nested Experts (MoNE), which '
             'utilizes a nested structure for experts, wherein individual '
             'experts fall on an increasing compute-accuracy curve. Given a '
             'compute budget, MoNE learns to dynamically choose tokens in a '
             'priority order, and thus redundant tokens are processed through '
             'cheaper nested experts. Using this framework, we achieve '
             'equivalent performance as the baseline models, while reducing '
             'inference time compute by over two-fold. We validate our '
             'approach on standard image and video datasets - ImageNet-21K, '
             'Kinetics400, and Something-Something-v2. We further highlight '
             'MoNE’s adaptability by showcasing its ability to maintain strong '
             'performance across different inference-time compute budgets on '
             'videos, using only a single trained model.',
 'title': 'Mixture of Nested Experts: Adaptive Processing of Visual Tokens',
 'url': 'https://deepmind.google/research/publications/108549/'}
2025-01-13 22:33:55,551 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/108549/>
{'abstract': 'The visual medium (images and videos) naturally contains a large '
             'amount of information redundancy, thereby providing a great '
             'opportunity for leveraging efficiency in processing. While '
             'Vision Transformer (ViT) based models scale effectively to large '
             'data regimes, they fail to capitalize on this inherent '
             'redundancy, leading to higher computational costs. Mixture of '
             'Experts (MoE) networks demonstrate scalability while maintaining '
             'same inference-time costs, but they come with a larger parameter '
             'footprint. We present Mixture of Nested Experts (MoNE), which '
             'utilizes a nested structure for experts, wherein individual '
             'experts fall on an increasing compute-accuracy curve. Given a '
             'compute budget, MoNE learns to dynamically choose tokens in a '
             'priority order, and thus redundant tokens are processed through '
             'cheaper nested experts. Using this framework, we achieve '
             'equivalent performance as the baseline models, while reducing '
             'inference time compute by over two-fold. We validate our '
             'approach on standard image and video datasets - ImageNet-21K, '
             'Kinetics400, and Something-Something-v2. We further highlight '
             'MoNE’s adaptability by showcasing its ability to maintain strong '
             'performance across different inference-time compute budgets on '
             'videos, using only a single trained model.',
 'title': 'Mixture of Nested Experts: Adaptive Processing of Visual Tokens',
 'url': 'https://deepmind.google/research/publications/108549/'}
2025-01-13 22:33:55,738 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/135718/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:55,788 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/65220/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:55,881 - root - INFO - Scraped item: {'abstract': 'With the rise of large language models (LLMs) for flexibly '
             'processing information as strings, a natural application is '
             'regression, specifically by preprocessing string representations '
             'into LLM embeddings as downstream features for metric '
             'prediction. In this paper, we provide one of the first '
             'comprehensive investigations into embedding-based regression and '
             'demonstrate that LLM embeddings as features can be better for '
             'high-dimensional regression tasks than using traditional feature '
             'engineering. This regression performance can be explained in '
             'part due to LLM embeddings over numeric data inherently '
             'preserving Lipschitz continuity over the feature space. '
             'Furthermore, we quantify the contribution of different model '
             'effects, most notably model size and language understanding, '
             'which we find surprisingly do not always improve regression '
             'performance.',
 'title': 'Understanding LLM Embeddings for Regression',
 'url': 'https://deepmind.google/research/publications/135718/'}
2025-01-13 22:33:55,891 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/135718/>
{'abstract': 'With the rise of large language models (LLMs) for flexibly '
             'processing information as strings, a natural application is '
             'regression, specifically by preprocessing string representations '
             'into LLM embeddings as downstream features for metric '
             'prediction. In this paper, we provide one of the first '
             'comprehensive investigations into embedding-based regression and '
             'demonstrate that LLM embeddings as features can be better for '
             'high-dimensional regression tasks than using traditional feature '
             'engineering. This regression performance can be explained in '
             'part due to LLM embeddings over numeric data inherently '
             'preserving Lipschitz continuity over the feature space. '
             'Furthermore, we quantify the contribution of different model '
             'effects, most notably model size and language understanding, '
             'which we find surprisingly do not always improve regression '
             'performance.',
 'title': 'Understanding LLM Embeddings for Regression',
 'url': 'https://deepmind.google/research/publications/135718/'}
2025-01-13 22:33:55,930 - root - INFO - Scraped item: {'abstract': 'Finding agreement through a free exchange of views is often '
             'difficult. Collective deliberation can be slow, difficult to '
             'scale, and unequally attentive to different voices. In this '
             'study, we trained an artificial intelligence (AI) to mediate '
             'human deliberation. Using participants’ personal opinions and '
             'critiques, the AI mediator iteratively generates and refines '
             'statements that express common ground among the group on social '
             'or political issues. Participants (N= 5734) preferred '
             'AI-generated statements to those written by human mediators, '
             'rating them as more informative, clear, and unbiased. '
             'Discussants often updated their views after the deliberation, '
             'converging on a shared perspective. Text embeddings revealed '
             'that successful group statements incorporated dissenting voices '
             'while respecting the majority position. These findings were '
             'replicated in a virtual citizens’ assembly involving a '
             'demographically representative sample of the UK population.',
 'title': 'AI can help humans find common ground in democratic deliberation',
 'url': 'https://deepmind.google/research/publications/65220/'}
2025-01-13 22:33:55,941 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/65220/>
{'abstract': 'Finding agreement through a free exchange of views is often '
             'difficult. Collective deliberation can be slow, difficult to '
             'scale, and unequally attentive to different voices. In this '
             'study, we trained an artificial intelligence (AI) to mediate '
             'human deliberation. Using participants’ personal opinions and '
             'critiques, the AI mediator iteratively generates and refines '
             'statements that express common ground among the group on social '
             'or political issues. Participants (N= 5734) preferred '
             'AI-generated statements to those written by human mediators, '
             'rating them as more informative, clear, and unbiased. '
             'Discussants often updated their views after the deliberation, '
             'converging on a shared perspective. Text embeddings revealed '
             'that successful group statements incorporated dissenting voices '
             'while respecting the majority position. These findings were '
             'replicated in a virtual citizens’ assembly involving a '
             'demographically representative sample of the UK population.',
 'title': 'AI can help humans find common ground in democratic deliberation',
 'url': 'https://deepmind.google/research/publications/65220/'}
2025-01-13 22:33:56,172 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/139455/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,231 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50070/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,321 - root - INFO - Scraped item: {'abstract': 'While large language models perform well on a range of complex '
             'tasks (e.g., text generation, question answering, '
             'summarization), robust multi-step planning and reasoning remains '
             'a considerable challenge for them. In this paper we show that '
             'search-based planning can significantly improve LLMs’ playing '
             'strength across several board games (Chess, Fischer Random '
             'Chess, Connect Four, and Hex). We introduce, compare and '
             'contrast two major approaches: In external search, the model '
             'guides Monte Carlo Tree Search (MCTS) rollouts and evaluations '
             'without calls to an external engine, and in internal search,the '
             'model directly generates in-context a linearized tree of '
             'potential futures and a resulting final choice. Both build on a '
             'model pre-trained on relevant domain knowledge, capturing the '
             'transition and value functions across these games. We find that '
             'our pre-training method minimizes hallucinations, as our model '
             'is highly accurate regarding state prediction and legal moves. '
             'Additionally, both internal and external search indeed improve '
             'win-rates against state-of-the-art bots, even reaching '
             'Grandmaster-level performance in chess while operating on a '
             'similar move count search budget per decision as human '
             'Grandmasters. The way we combine search with domain knowledge is '
             'not specific to board games, suggesting direct extensions into '
             'more general language model inference and training techniques.',
 'title': 'Mastering Board Games by External and Internal Planning with '
          'Language Models',
 'url': 'https://deepmind.google/research/publications/139455/'}
2025-01-13 22:33:56,334 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/139455/>
{'abstract': 'While large language models perform well on a range of complex '
             'tasks (e.g., text generation, question answering, '
             'summarization), robust multi-step planning and reasoning remains '
             'a considerable challenge for them. In this paper we show that '
             'search-based planning can significantly improve LLMs’ playing '
             'strength across several board games (Chess, Fischer Random '
             'Chess, Connect Four, and Hex). We introduce, compare and '
             'contrast two major approaches: In external search, the model '
             'guides Monte Carlo Tree Search (MCTS) rollouts and evaluations '
             'without calls to an external engine, and in internal search,the '
             'model directly generates in-context a linearized tree of '
             'potential futures and a resulting final choice. Both build on a '
             'model pre-trained on relevant domain knowledge, capturing the '
             'transition and value functions across these games. We find that '
             'our pre-training method minimizes hallucinations, as our model '
             'is highly accurate regarding state prediction and legal moves. '
             'Additionally, both internal and external search indeed improve '
             'win-rates against state-of-the-art bots, even reaching '
             'Grandmaster-level performance in chess while operating on a '
             'similar move count search budget per decision as human '
             'Grandmasters. The way we combine search with domain knowledge is '
             'not specific to board games, suggesting direct extensions into '
             'more general language model inference and training techniques.',
 'title': 'Mastering Board Games by External and Internal Planning with '
          'Language Models',
 'url': 'https://deepmind.google/research/publications/139455/'}
2025-01-13 22:33:56,341 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/70169/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,345 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/105317/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,408 - root - INFO - Scraped item: {'abstract': 'One of the main challenges of multimodal models is that they '
             'need to combine heterogeneous modalities (e.g. video, audio, '
             'text), which have different characteristics. For example, video '
             'and audio are obtained at much higher rates than text and are '
             'roughly aligned in time. They are not necessarily synchronized '
             'with text which is often present as a global context, e.g. a '
             'title or description. Furthermore, video and audio inputs are of '
             'much larger volumes, and can grow with the increase of the video '
             'lengths, which naturally requires more compute dedicated to '
             'these modalities and makes modeling of long-range dependencies '
             'harder.',
 'title': 'Mirasol3B: A Multimodal Autoregressive Model for Time-Aligned and '
          'Contextual Modalities',
 'url': 'https://deepmind.google/research/publications/50070/'}
2025-01-13 22:33:56,418 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50070/>
{'abstract': 'One of the main challenges of multimodal models is that they '
             'need to combine heterogeneous modalities (e.g. video, audio, '
             'text), which have different characteristics. For example, video '
             'and audio are obtained at much higher rates than text and are '
             'roughly aligned in time. They are not necessarily synchronized '
             'with text which is often present as a global context, e.g. a '
             'title or description. Furthermore, video and audio inputs are of '
             'much larger volumes, and can grow with the increase of the video '
             'lengths, which naturally requires more compute dedicated to '
             'these modalities and makes modeling of long-range dependencies '
             'harder.',
 'title': 'Mirasol3B: A Multimodal Autoregressive Model for Time-Aligned and '
          'Contextual Modalities',
 'url': 'https://deepmind.google/research/publications/50070/'}
2025-01-13 22:33:56,479 - root - INFO - Scraped item: {'abstract': 'Bayesian optimization (BO) has become a popular strategy for '
             'global optimization of expensive real-world functions. Contrary '
             'to a common expectation that BO is suited to optimizing '
             'black-box functions, it actually requires domain knowledge about '
             'those functions to deploy BO successfully. Such domain knowledge '
             'often manifests in Gaussian process (GP) priors that specify '
             'initial beliefs on functions. However, even with expert '
             'knowledge, it is non-trivial to quantitatively define a prior. '
             'This is especially true for hyperparameter tuning problems on '
             'complex machine learning models, where landscapes of tuning '
             'objectives are often difficult to comprehend. We seek an '
             'alternative practice for setting these functional priors. In '
             'particular, we consider the scenario where we have data from '
             'similar functions that allow us to pre-train a tighter '
             'distribution a priori. We detail what pre-training entails for '
             'GPs using a KL divergence based loss function, and propose a new '
             'pre-training based BO framework named HyperBO. Theoretically, we '
             'show bounded posterior predictions and near-zero regrets for '
             'HyperBO without assuming the "ground truth" GP prior is known. '
             'To verify our approach in realistic setups, we collect a large '
             'multi-task hyperparameter tuning dataset by training tens of '
             'thousands of configurations of near-state-of-the-art deep '
             'learning models on popular image and text datasets, as well as a '
             'protein sequence dataset. Our results show that on average, '
             'HyperBO is able to locate good hyperparameters at least 3 times '
             'more efficiently than the best competing methods on both our new '
             'tuning dataset and existing multi-task BO benchmarks.',
 'title': 'Pre-trained Gaussian processes for Bayesian optimization',
 'url': 'https://deepmind.google/research/publications/70169/'}
2025-01-13 22:33:56,495 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/70169/>
{'abstract': 'Bayesian optimization (BO) has become a popular strategy for '
             'global optimization of expensive real-world functions. Contrary '
             'to a common expectation that BO is suited to optimizing '
             'black-box functions, it actually requires domain knowledge about '
             'those functions to deploy BO successfully. Such domain knowledge '
             'often manifests in Gaussian process (GP) priors that specify '
             'initial beliefs on functions. However, even with expert '
             'knowledge, it is non-trivial to quantitatively define a prior. '
             'This is especially true for hyperparameter tuning problems on '
             'complex machine learning models, where landscapes of tuning '
             'objectives are often difficult to comprehend. We seek an '
             'alternative practice for setting these functional priors. In '
             'particular, we consider the scenario where we have data from '
             'similar functions that allow us to pre-train a tighter '
             'distribution a priori. We detail what pre-training entails for '
             'GPs using a KL divergence based loss function, and propose a new '
             'pre-training based BO framework named HyperBO. Theoretically, we '
             'show bounded posterior predictions and near-zero regrets for '
             'HyperBO without assuming the "ground truth" GP prior is known. '
             'To verify our approach in realistic setups, we collect a large '
             'multi-task hyperparameter tuning dataset by training tens of '
             'thousands of configurations of near-state-of-the-art deep '
             'learning models on popular image and text datasets, as well as a '
             'protein sequence dataset. Our results show that on average, '
             'HyperBO is able to locate good hyperparameters at least 3 times '
             'more efficiently than the best competing methods on both our new '
             'tuning dataset and existing multi-task BO benchmarks.',
 'title': 'Pre-trained Gaussian processes for Bayesian optimization',
 'url': 'https://deepmind.google/research/publications/70169/'}
2025-01-13 22:33:56,534 - root - INFO - Scraped item: {'abstract': 'Atmospheric states derived from reanalysis comprise a '
             'substantial portion of weather and climate simulation outputs. '
             'Many stakeholders -- such as researchers, policy makers, and '
             'insurers -- use this data to better understand the earth system '
             'and guide policy decisions. Atmospheric states have also '
             'received increased interest as machine learning approaches to '
             'weather prediction have shown promising results. A key issue for '
             'all audiences is that dense time series of these '
             'high-dimensional states comprise an enormous amount of data, '
             'precluding all but the most well resourced groups from accessing '
             'and using historical data and future projections. To address '
             'this problem, we propose a method for compressing atmospheric '
             'states using methods from the neural network literature, '
             'adapting spherical data to processing by conventional neural '
             'architectures through the use of the area-preserving HEALPix '
             'projection. We investigate two model classes for building neural '
             'compressors: the hyperprior model from the neural image '
             'compression literature and recent vector-quantised models. We '
             'show that both families of models satisfy the desiderata of '
             'small average error, a small number of high-error reconstructed '
             'pixels, faithful reproduction of extreme events such as '
             'hurricanes and heatwaves, preservation of the spectral power '
             'distribution across spatial scales. We demonstrate compression '
             'ratios in excess of 1000x, with compression and decompression at '
             'a rate of approximately one second per global atmospheric state.',
 'title': 'Neural Climate Data Compression',
 'url': 'https://deepmind.google/research/publications/105317/'}
2025-01-13 22:33:56,546 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/105317/>
{'abstract': 'Atmospheric states derived from reanalysis comprise a '
             'substantial portion of weather and climate simulation outputs. '
             'Many stakeholders -- such as researchers, policy makers, and '
             'insurers -- use this data to better understand the earth system '
             'and guide policy decisions. Atmospheric states have also '
             'received increased interest as machine learning approaches to '
             'weather prediction have shown promising results. A key issue for '
             'all audiences is that dense time series of these '
             'high-dimensional states comprise an enormous amount of data, '
             'precluding all but the most well resourced groups from accessing '
             'and using historical data and future projections. To address '
             'this problem, we propose a method for compressing atmospheric '
             'states using methods from the neural network literature, '
             'adapting spherical data to processing by conventional neural '
             'architectures through the use of the area-preserving HEALPix '
             'projection. We investigate two model classes for building neural '
             'compressors: the hyperprior model from the neural image '
             'compression literature and recent vector-quantised models. We '
             'show that both families of models satisfy the desiderata of '
             'small average error, a small number of high-error reconstructed '
             'pixels, faithful reproduction of extreme events such as '
             'hurricanes and heatwaves, preservation of the spectral power '
             'distribution across spatial scales. We demonstrate compression '
             'ratios in excess of 1000x, with compression and decompression at '
             'a rate of approximately one second per global atmospheric state.',
 'title': 'Neural Climate Data Compression',
 'url': 'https://deepmind.google/research/publications/105317/'}
2025-01-13 22:33:56,552 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/117639/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,556 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/108347/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,561 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/66938/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,634 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=2> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,694 - root - INFO - Scraped item: {'abstract': 'We introduce Michelangelo: a minimal, synthetic, and unleaked '
             'long-context reasoning evaluation for large language models '
             'which is also easy to automatically score. This evaluation is '
             'derived via a novel, unifying framework for evaluations over '
             "arbitrarily long contexts which measure the model's ability to "
             'do more than retrieve a single piece of information from its '
             'context. The central idea of the Latent Structure Queries '
             'framework (LSQ) is to construct tasks which require a model to '
             "``chisel away'' the irrelevant information in the context, "
             "revealing a latent structure in the context. To verify a model's "
             'understanding of this latent structure, we query the model for '
             'details of the structure. Using LSQ, we produce three diagnostic '
             'long-context evaluations across code and natural-language '
             'domains intended to provide a stronger signal of long-context '
             'language model capabilities. We perform evaluations on several '
             'state-of-the-art models and demonstrate both that a) the '
             'proposed evaluations are high-signal and b) that there is '
             'significant room for improvement in synthesizing long-context '
             'information.',
 'title': 'Michelangelo: Long Context Evaluations Beyond Haystacks via Latent '
          'Structure Queries',
 'url': 'https://deepmind.google/research/publications/117639/'}
2025-01-13 22:33:56,707 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/117639/>
{'abstract': 'We introduce Michelangelo: a minimal, synthetic, and unleaked '
             'long-context reasoning evaluation for large language models '
             'which is also easy to automatically score. This evaluation is '
             'derived via a novel, unifying framework for evaluations over '
             "arbitrarily long contexts which measure the model's ability to "
             'do more than retrieve a single piece of information from its '
             'context. The central idea of the Latent Structure Queries '
             'framework (LSQ) is to construct tasks which require a model to '
             "``chisel away'' the irrelevant information in the context, "
             "revealing a latent structure in the context. To verify a model's "
             'understanding of this latent structure, we query the model for '
             'details of the structure. Using LSQ, we produce three diagnostic '
             'long-context evaluations across code and natural-language '
             'domains intended to provide a stronger signal of long-context '
             'language model capabilities. We perform evaluations on several '
             'state-of-the-art models and demonstrate both that a) the '
             'proposed evaluations are high-signal and b) that there is '
             'significant room for improvement in synthesizing long-context '
             'information.',
 'title': 'Michelangelo: Long Context Evaluations Beyond Haystacks via Latent '
          'Structure Queries',
 'url': 'https://deepmind.google/research/publications/117639/'}
2025-01-13 22:33:56,743 - root - INFO - Scraped item: {'abstract': 'Google Vizier has performed millions of optimizations and '
             'accelerated numerous research and production systems at Google, '
             'demonstrating the success of Bayesian optimization as a '
             'large-scale service. Over multiple years, its algorithm has been '
             'improved considerably, through the collective experiences of '
             'numerous research efforts and user feedback. In this technical '
             'report, we discuss the implementation details and design choices '
             'of the current default algorithm provided by Open Source Vizier. '
             'Our experiments on standardized benchmarks reveal its robustness '
             'and versatility against well-established industry baselines on '
             'multiple practical modes.',
 'title': 'The Vizier Gaussian Process Bandit Algorithm',
 'url': 'https://deepmind.google/research/publications/108347/'}
2025-01-13 22:33:56,755 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/108347/>
{'abstract': 'Google Vizier has performed millions of optimizations and '
             'accelerated numerous research and production systems at Google, '
             'demonstrating the success of Bayesian optimization as a '
             'large-scale service. Over multiple years, its algorithm has been '
             'improved considerably, through the collective experiences of '
             'numerous research efforts and user feedback. In this technical '
             'report, we discuss the implementation details and design choices '
             'of the current default algorithm provided by Open Source Vizier. '
             'Our experiments on standardized benchmarks reveal its robustness '
             'and versatility against well-established industry baselines on '
             'multiple practical modes.',
 'title': 'The Vizier Gaussian Process Bandit Algorithm',
 'url': 'https://deepmind.google/research/publications/108347/'}
2025-01-13 22:33:56,793 - root - INFO - Scraped item: {'abstract': 'We propose a framework for classifying the capabilities and '
             'behavior of Artificial General Intelligence (AGI) models and '
             'their precursors. This framework introduces levels of AGI '
             'performance, generality, and autonomy, providing a common '
             'language to compare models, assess risks, and measure progress '
             'along the path to AGI. To develop our framework, we analyze '
             'existing definitions of AGI, and distill six principles that a '
             'useful ontology for AGI should satisfy. With these principles in '
             'mind, we propose "Levels of AGI" based on depth (performance) '
             'and breadth (generality) of capabilities, and reflect on how '
             'current systems fit into this ontology. We discuss the '
             'challenging requirements for future benchmarks that quantify the '
             'behavior and capabilities of AGI models against these levels. '
             'Finally, we discuss how these levels of AGI interact with '
             'deployment considerations such as autonomy and risk, and '
             'emphasize the importance of carefully selecting Human-AI '
             'Interaction paradigms for responsible and safe deployment of '
             'highly capable AI systems.',
 'title': 'Levels of AGI for Operationalizing Progress on the Path to AGI',
 'url': 'https://deepmind.google/research/publications/66938/'}
2025-01-13 22:33:56,804 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/66938/>
{'abstract': 'We propose a framework for classifying the capabilities and '
             'behavior of Artificial General Intelligence (AGI) models and '
             'their precursors. This framework introduces levels of AGI '
             'performance, generality, and autonomy, providing a common '
             'language to compare models, assess risks, and measure progress '
             'along the path to AGI. To develop our framework, we analyze '
             'existing definitions of AGI, and distill six principles that a '
             'useful ontology for AGI should satisfy. With these principles in '
             'mind, we propose "Levels of AGI" based on depth (performance) '
             'and breadth (generality) of capabilities, and reflect on how '
             'current systems fit into this ontology. We discuss the '
             'challenging requirements for future benchmarks that quantify the '
             'behavior and capabilities of AGI models against these levels. '
             'Finally, we discuss how these levels of AGI interact with '
             'deployment considerations such as autonomy and risk, and '
             'emphasize the importance of carefully selecting Human-AI '
             'Interaction paradigms for responsible and safe deployment of '
             'highly capable AI systems.',
 'title': 'Levels of AGI for Operationalizing Progress on the Path to AGI',
 'url': 'https://deepmind.google/research/publications/66938/'}
2025-01-13 22:33:56,807 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=2
2025-01-13 22:33:56,813 - scrapy.dupefilters - DEBUG - Filtered duplicate request: <GET https://deepmind.google/research/publications/50070/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2025-01-13 22:33:56,820 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/93097/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:56,958 - root - INFO - Scraped item: {'abstract': 'We propose Diffusion Model Predictive Control (D-MPC), a novel '
             'MPC approach that learns a multi-step action proposal and a '
             'multi-step dynamics model, both using diffusion models, and '
             'combines them for use in online MPC. On the popular D4RL '
             'benchmark, we show performance that is significantly better than '
             'existing model-based offline planning methods using MPC and '
             'competitive with state-of-the-art (SOTA) model-based and '
             'model-free reinforcement learning methods. We additionally '
             "illustrate D-MPC's ability to optimize novel reward functions at "
             'run time and adapt to novel dynamics, and highlight its '
             'advantages compared to existing diffusion-based planning '
             'baselines.',
 'title': 'Diffusion model predictive control',
 'url': 'https://deepmind.google/research/publications/93097/'}
2025-01-13 22:33:56,970 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/93097/>
{'abstract': 'We propose Diffusion Model Predictive Control (D-MPC), a novel '
             'MPC approach that learns a multi-step action proposal and a '
             'multi-step dynamics model, both using diffusion models, and '
             'combines them for use in online MPC. On the popular D4RL '
             'benchmark, we show performance that is significantly better than '
             'existing model-based offline planning methods using MPC and '
             'competitive with state-of-the-art (SOTA) model-based and '
             'model-free reinforcement learning methods. We additionally '
             "illustrate D-MPC's ability to optimize novel reward functions at "
             'run time and adapt to novel dynamics, and highlight its '
             'advantages compared to existing diffusion-based planning '
             'baselines.',
 'title': 'Diffusion model predictive control',
 'url': 'https://deepmind.google/research/publications/93097/'}
2025-01-13 22:33:57,015 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/107338/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:57,052 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/78755/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:57,158 - root - INFO - Scraped item: {'abstract': 'During 2023, two interesting results were proven about the limit '
             'behavior of game dynamics: First, it was shown that there is a '
             'game for which no dynamics converges to the Nash equilibria. '
             'Second, it was shown that the sink equilibria of a game '
             'adequately capture the limit behavior of natural game dynamics. '
             'These two results have created a need and opportunity to '
             'articulate a principled computational theory of the meaning of '
             'the game that is based on game dynamics. Given any game in '
             'normal form, and any prior distribution of play, we study the '
             'problem of computing the asymptotic behavior of a class of '
             'natural dynamics called the noisy replicator dynamics as a limit '
             'distribution over the sink equilibria of the game. When the '
             'prior distribution has pure strategy support, we prove this '
             'distribution can be computed efficiently, in near-linear time to '
             'the size of the best-response graph. When the distribution can '
             'be sampled --- for example, if it is the uniform distribution '
             'over all mixed strategy profiles --- we show through experiments '
             'that the limit distribution of reasonably large games can be '
             'estimated quite accurately through sampling and simulation.',
 'title': 'Swim till you sink: Computing the limit of a game',
 'url': 'https://deepmind.google/research/publications/107338/'}
2025-01-13 22:33:57,170 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/107338/>
{'abstract': 'During 2023, two interesting results were proven about the limit '
             'behavior of game dynamics: First, it was shown that there is a '
             'game for which no dynamics converges to the Nash equilibria. '
             'Second, it was shown that the sink equilibria of a game '
             'adequately capture the limit behavior of natural game dynamics. '
             'These two results have created a need and opportunity to '
             'articulate a principled computational theory of the meaning of '
             'the game that is based on game dynamics. Given any game in '
             'normal form, and any prior distribution of play, we study the '
             'problem of computing the asymptotic behavior of a class of '
             'natural dynamics called the noisy replicator dynamics as a limit '
             'distribution over the sink equilibria of the game. When the '
             'prior distribution has pure strategy support, we prove this '
             'distribution can be computed efficiently, in near-linear time to '
             'the size of the best-response graph. When the distribution can '
             'be sampled --- for example, if it is the uniform distribution '
             'over all mixed strategy profiles --- we show through experiments '
             'that the limit distribution of reasonably large games can be '
             'estimated quite accurately through sampling and simulation.',
 'title': 'Swim till you sink: Computing the limit of a game',
 'url': 'https://deepmind.google/research/publications/107338/'}
2025-01-13 22:33:57,213 - root - INFO - Scraped item: {'abstract': 'In order to oversee advanced AI systems, it is important to '
             'understand their reasons for generating a given output. When '
             'prompted, large language models (LLMs) can provide natural '
             'language explanations or reasoning traces that sound plausible '
             'and receive high ratings from human annotators. However, it is '
             'unclear to what extent these explanations are truly capturing '
             "the factors responsible for the model's predictions: the most "
             "``human-like'' explanation may be different from the one that is "
             "most faithful to the model's true decision making process. In "
             'this work, we introduce the correlational counterfactual test '
             '(CCT), a faithfulness metric based on counterfactual input edits '
             'that takes into account not just the binary label change, but '
             "the total shift in the model's predicted label distribution. We "
             'evaluate the faithfulness of free-text explanations generated by '
             'few-shot-prompted LLMs from the Llama-2 family on three NLP '
             'tasks. We find that these explanations are indeed more likely to '
             "mention factors when they are impactful to the model's "
             'prediction, with the degree of association increasing with model '
             'size but varying significantly by task.',
 'title': 'The Probabilities Also Matter: A More Faithful Metric for '
          'Faithfulness of Free-Text Explanations in Large Language Models',
 'url': 'https://deepmind.google/research/publications/78755/'}
2025-01-13 22:33:57,225 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/78755/>
{'abstract': 'In order to oversee advanced AI systems, it is important to '
             'understand their reasons for generating a given output. When '
             'prompted, large language models (LLMs) can provide natural '
             'language explanations or reasoning traces that sound plausible '
             'and receive high ratings from human annotators. However, it is '
             'unclear to what extent these explanations are truly capturing '
             "the factors responsible for the model's predictions: the most "
             "``human-like'' explanation may be different from the one that is "
             "most faithful to the model's true decision making process. In "
             'this work, we introduce the correlational counterfactual test '
             '(CCT), a faithfulness metric based on counterfactual input edits '
             'that takes into account not just the binary label change, but '
             "the total shift in the model's predicted label distribution. We "
             'evaluate the faithfulness of free-text explanations generated by '
             'few-shot-prompted LLMs from the Llama-2 family on three NLP '
             'tasks. We find that these explanations are indeed more likely to '
             "mention factors when they are impactful to the model's "
             'prediction, with the degree of association increasing with model '
             'size but varying significantly by task.',
 'title': 'The Probabilities Also Matter: A More Faithful Metric for '
          'Faithfulness of Free-Text Explanations in Large Language Models',
 'url': 'https://deepmind.google/research/publications/78755/'}
2025-01-13 22:33:57,231 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/90369/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:57,379 - root - INFO - Scraped item: {'abstract': 'Representation learning, and interpreting learned '
             'representations, are key areas of focus in machine learning and '
             'neuroscience. Both fields generally use representations as a '
             "means to understand or improve a system's computations. In this "
             'work, however, we explore surprising dissociations between '
             'representation and computation that may pose challenges for such '
             'efforts. We create datasets in which we attempt to match the '
             'computational role that different features play, while '
             'manipulating other properties of the features or the data. We '
             'train various deep learning architectures to compute these '
             'multiple abstract features about their inputs. We find that '
             'their learned feature representations are systematically biased '
             'towards representing some features more strongly than others, '
             'depending upon extraneous properties such as feature complexity, '
             'the order in which features are learned, and the distribution of '
             'features over the inputs. For example, features that are simpler '
             'to compute or learned first tend to be represented more strongly '
             'and densely than features that are more complex or learned '
             'later, even if all features are learned equally well. We also '
             'explore how these biases are affected by architectures, '
             'optimizers, and training regimes (e.g., in transformers, '
             'features decoded earlier in the output sequence also tend to be '
             'represented more strongly). Our results help to characterize the '
             'inductive biases of gradient-based representation learning. We '
             'then illustrate the downstream effects of these biases on '
             'various commonly-used methods for analyzing or intervening on '
             'representations. These results highlight a key challenge for '
             'interpretability—or for comparing the representations of models '
             'and brains—disentangling extraneous biases from the '
             "computationally important aspects of a system's internal "
             'representations.',
 'title': 'Learned feature representations are biased by complexity, learning '
          'order, position, and more',
 'url': 'https://deepmind.google/research/publications/90369/'}
2025-01-13 22:33:57,392 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/90369/>
{'abstract': 'Representation learning, and interpreting learned '
             'representations, are key areas of focus in machine learning and '
             'neuroscience. Both fields generally use representations as a '
             "means to understand or improve a system's computations. In this "
             'work, however, we explore surprising dissociations between '
             'representation and computation that may pose challenges for such '
             'efforts. We create datasets in which we attempt to match the '
             'computational role that different features play, while '
             'manipulating other properties of the features or the data. We '
             'train various deep learning architectures to compute these '
             'multiple abstract features about their inputs. We find that '
             'their learned feature representations are systematically biased '
             'towards representing some features more strongly than others, '
             'depending upon extraneous properties such as feature complexity, '
             'the order in which features are learned, and the distribution of '
             'features over the inputs. For example, features that are simpler '
             'to compute or learned first tend to be represented more strongly '
             'and densely than features that are more complex or learned '
             'later, even if all features are learned equally well. We also '
             'explore how these biases are affected by architectures, '
             'optimizers, and training regimes (e.g., in transformers, '
             'features decoded earlier in the output sequence also tend to be '
             'represented more strongly). Our results help to characterize the '
             'inductive biases of gradient-based representation learning. We '
             'then illustrate the downstream effects of these biases on '
             'various commonly-used methods for analyzing or intervening on '
             'representations. These results highlight a key challenge for '
             'interpretability—or for comparing the representations of models '
             'and brains—disentangling extraneous biases from the '
             "computationally important aspects of a system's internal "
             'representations.',
 'title': 'Learned feature representations are biased by complexity, learning '
          'order, position, and more',
 'url': 'https://deepmind.google/research/publications/90369/'}
2025-01-13 22:33:57,468 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49566/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:57,610 - root - INFO - Scraped item: {'abstract': 'Sparse mixture of expert architectures (MoEs) scale model '
             'capacity without significant increases in training or inference '
             'costs.\n'
             'Despite their success, MoEs suffer from a number of issues: '
             'training instability, token dropping, inability to scale the '
             'number of experts, or ineffective finetuning.\n'
             'In this work, we propose Soft MoE, afully-differentiablesparse '
             'Transformer that addresses these challenges, while maintaining '
             'the benefits of MoEs.\n'
             'Soft MoE performs an implicit soft assignment by passing '
             'different weighted combinations of all input tokens to each '
             'expert.\n'
             'As in other MoEs, experts in Soft MoE only process a subset of '
             'the (combined) tokens, enabling larger model capacity (and '
             'performance) at lower inference cost.\n'
             'In the context of visual recognition, Soft MoE greatly '
             'outperforms dense Transformers (ViTs) and popular MoEs (Tokens '
             'Choice and Experts Choice).\n'
             'Furthermore, Soft MoE scales well: Soft MoE Huge/14 with 128 '
             'experts in 16 MoE layers has over $40\\times$ more parameters '
             'than ViT Huge/14, with only 2% increased inference time, and '
             'substantially better quality.',
 'title': 'From Sparse to Soft Mixture of Experts',
 'url': 'https://deepmind.google/research/publications/49566/'}
2025-01-13 22:33:57,623 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49566/>
{'abstract': 'Sparse mixture of expert architectures (MoEs) scale model '
             'capacity without significant increases in training or inference '
             'costs.\n'
             'Despite their success, MoEs suffer from a number of issues: '
             'training instability, token dropping, inability to scale the '
             'number of experts, or ineffective finetuning.\n'
             'In this work, we propose Soft MoE, afully-differentiablesparse '
             'Transformer that addresses these challenges, while maintaining '
             'the benefits of MoEs.\n'
             'Soft MoE performs an implicit soft assignment by passing '
             'different weighted combinations of all input tokens to each '
             'expert.\n'
             'As in other MoEs, experts in Soft MoE only process a subset of '
             'the (combined) tokens, enabling larger model capacity (and '
             'performance) at lower inference cost.\n'
             'In the context of visual recognition, Soft MoE greatly '
             'outperforms dense Transformers (ViTs) and popular MoEs (Tokens '
             'Choice and Experts Choice).\n'
             'Furthermore, Soft MoE scales well: Soft MoE Huge/14 with 128 '
             'experts in 16 MoE layers has over $40\\times$ more parameters '
             'than ViT Huge/14, with only 2% increased inference time, and '
             'substantially better quality.',
 'title': 'From Sparse to Soft Mixture of Experts',
 'url': 'https://deepmind.google/research/publications/49566/'}
2025-01-13 22:33:57,735 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/36940/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:57,874 - root - INFO - Scraped item: {'abstract': 'Many robot manipulation tasks can be framed as geometric '
             'reasoning tasks, where an agent must be able to precisely '
             'manipulate an object into a position that satisfies the task '
             'from a set of initial conditions. Often, task success is defined '
             'based on the relationship between two objects - for instance, '
             'hanging a mug on a rack.  In such cases, the solution should be '
             'equivariant to the initial position of the objects as well as '
             'the agent, and invariant to the pose of the camera. This poses a '
             'challenge for learning systems which attempt to solve this task '
             'by learning directly from high-dimensional demonstrations: the '
             'agent must learn to be both equivariant as well as precise, '
             'which can be challenging without any inductive biases about the '
             'problem. In this work, we propose a method for precise relative '
             'pose prediction which is provably SE(3)-equivariant, can be '
             'learned from only a few demonstrations, and can generalize '
             'across variations in a class of objects. We accomplish this by '
             'factoring the problem into learning an SE(3) invariant '
             'task-specific representation of the scene and then interpreting '
             'this representation with novel geometric reasoning layers which '
             'are provably SE(3) equivariant. We demonstrate that our method '
             'can yield substantially more precise predictions in simulated '
             'placement tasks than previous methods trained with the same '
             'amount of data, and can accurately represent relative placement '
             'relationships data collected from real-world demonstrations. '
             'Supplementary information and videos can be found atthis URL.',
 'title': 'Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement '
          'Tasks',
 'url': 'https://deepmind.google/research/publications/36940/'}
2025-01-13 22:33:57,887 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/36940/>
{'abstract': 'Many robot manipulation tasks can be framed as geometric '
             'reasoning tasks, where an agent must be able to precisely '
             'manipulate an object into a position that satisfies the task '
             'from a set of initial conditions. Often, task success is defined '
             'based on the relationship between two objects - for instance, '
             'hanging a mug on a rack.  In such cases, the solution should be '
             'equivariant to the initial position of the objects as well as '
             'the agent, and invariant to the pose of the camera. This poses a '
             'challenge for learning systems which attempt to solve this task '
             'by learning directly from high-dimensional demonstrations: the '
             'agent must learn to be both equivariant as well as precise, '
             'which can be challenging without any inductive biases about the '
             'problem. In this work, we propose a method for precise relative '
             'pose prediction which is provably SE(3)-equivariant, can be '
             'learned from only a few demonstrations, and can generalize '
             'across variations in a class of objects. We accomplish this by '
             'factoring the problem into learning an SE(3) invariant '
             'task-specific representation of the scene and then interpreting '
             'this representation with novel geometric reasoning layers which '
             'are provably SE(3) equivariant. We demonstrate that our method '
             'can yield substantially more precise predictions in simulated '
             'placement tasks than previous methods trained with the same '
             'amount of data, and can accurately represent relative placement '
             'relationships data collected from real-world demonstrations. '
             'Supplementary information and videos can be found atthis URL.',
 'title': 'Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement '
          'Tasks',
 'url': 'https://deepmind.google/research/publications/36940/'}
2025-01-13 22:33:58,009 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/107741/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:58,026 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/90773/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:58,045 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/43000/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:58,079 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/81077/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:58,156 - root - INFO - Scraped item: {'abstract': 'Achieving human-level speed and performance on real world tasks '
             'is a north star for the robotics research community. This work '
             'takes a step towards that goal and presents the first learned '
             'robot agent that reaches amateur human-level performance in '
             'competitive table tennis. Table tennis is a physically demanding '
             'sport which requires human players to undergo years of training '
             'to achieve an advanced level of proficiency. In this paper, we '
             'contribute (1) a hierarchical and modular policy architecture '
             'consisting of (i) low level controllers with their detailed '
             "skill descriptors which model the agent's capabilities and help "
             'to bridge the sim-to-real gap and (ii) a high level controller '
             'that chooses the low level skills, (2) techniques for enabling '
             'zero-shot sim-to-real including an iterative approach to '
             'defining the task distribution that is grounded in the '
             'real-world and defines an automatic curriculum, and (3) real '
             'time adaptation to unseen opponents. Policy performance was '
             'assessed through 29 robot vs. human matches of which the robot '
             'won 45% (13/29). All humans were unseen players and their skill '
             'level varied from beginner to tournament level. Whilst the robot '
             'lost all matches vs. the most advanced players it won 100% '
             'matches vs. beginners and 55% matches vs. intermediate players, '
             'demonstrating solidly amateur human-level performance. Videos of '
             'the matches can be viewed '
             'here:https://sites.google.com/view/competitive-robot-table-tennis.',
 'title': 'Achieving Human Level Competitive Robot Table Tennis',
 'url': 'https://deepmind.google/research/publications/107741/'}
2025-01-13 22:33:58,172 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/107741/>
{'abstract': 'Achieving human-level speed and performance on real world tasks '
             'is a north star for the robotics research community. This work '
             'takes a step towards that goal and presents the first learned '
             'robot agent that reaches amateur human-level performance in '
             'competitive table tennis. Table tennis is a physically demanding '
             'sport which requires human players to undergo years of training '
             'to achieve an advanced level of proficiency. In this paper, we '
             'contribute (1) a hierarchical and modular policy architecture '
             'consisting of (i) low level controllers with their detailed '
             "skill descriptors which model the agent's capabilities and help "
             'to bridge the sim-to-real gap and (ii) a high level controller '
             'that chooses the low level skills, (2) techniques for enabling '
             'zero-shot sim-to-real including an iterative approach to '
             'defining the task distribution that is grounded in the '
             'real-world and defines an automatic curriculum, and (3) real '
             'time adaptation to unseen opponents. Policy performance was '
             'assessed through 29 robot vs. human matches of which the robot '
             'won 45% (13/29). All humans were unseen players and their skill '
             'level varied from beginner to tournament level. Whilst the robot '
             'lost all matches vs. the most advanced players it won 100% '
             'matches vs. beginners and 55% matches vs. intermediate players, '
             'demonstrating solidly amateur human-level performance. Videos of '
             'the matches can be viewed '
             'here:https://sites.google.com/view/competitive-robot-table-tennis.',
 'title': 'Achieving Human Level Competitive Robot Table Tennis',
 'url': 'https://deepmind.google/research/publications/107741/'}
2025-01-13 22:33:58,222 - root - INFO - Scraped item: {'abstract': 'As a computer scientist with one foot in AI research and the '
             'other in HCI research, I have become increasingly concerned that '
             '“prompting” has transitioned from what was essentially a test '
             'and debugging interface for ML engineers into the de-facto '
             'interaction paradigm for end-users of large language models and '
             'their multimodal generative AI brethren. It is my professional '
             'opinion that prompting is a poor user interface for generative '
             'AI systems, and should be phased out as quickly as possible.',
 'title': 'Prompting Considered Harmful',
 'url': 'https://deepmind.google/research/publications/90773/'}
2025-01-13 22:33:58,233 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/90773/>
{'abstract': 'As a computer scientist with one foot in AI research and the '
             'other in HCI research, I have become increasingly concerned that '
             '“prompting” has transitioned from what was essentially a test '
             'and debugging interface for ML engineers into the de-facto '
             'interaction paradigm for end-users of large language models and '
             'their multimodal generative AI brethren. It is my professional '
             'opinion that prompting is a poor user interface for generative '
             'AI systems, and should be phased out as quickly as possible.',
 'title': 'Prompting Considered Harmful',
 'url': 'https://deepmind.google/research/publications/90773/'}
2025-01-13 22:33:58,315 - root - INFO - Scraped item: {'abstract': 'When large language models are trained on private data, it can '
             'be asignificantprivacy risk for them to memorize and regurgitate '
             'sensitive information. In this work, we propose a '
             'newpracticaldata extraction attack that we call ``neural '
             "phishing''. This attack enables an adversary to target and "
             'extract sensitive or personally identifiable information (PII), '
             'e.g., credit card numbers, from a model trained on user data '
             'with upwards of10%attack success rates, at times, as high '
             'as50%.\n'
             'Our attack assumes only that an adversary can insert as few '
             'as10sof benign-appearing sentences into the training dataset '
             'using only vague priors on the structure of the user data.',
 'title': 'Teach LLMs to Phish: Stealing Private Information from Language '
          'Models',
 'url': 'https://deepmind.google/research/publications/43000/'}
2025-01-13 22:33:58,331 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/43000/>
{'abstract': 'When large language models are trained on private data, it can '
             'be asignificantprivacy risk for them to memorize and regurgitate '
             'sensitive information. In this work, we propose a '
             'newpracticaldata extraction attack that we call ``neural '
             "phishing''. This attack enables an adversary to target and "
             'extract sensitive or personally identifiable information (PII), '
             'e.g., credit card numbers, from a model trained on user data '
             'with upwards of10%attack success rates, at times, as high '
             'as50%.\n'
             'Our attack assumes only that an adversary can insert as few '
             'as10sof benign-appearing sentences into the training dataset '
             'using only vague priors on the structure of the user data.',
 'title': 'Teach LLMs to Phish: Stealing Private Information from Language '
          'Models',
 'url': 'https://deepmind.google/research/publications/43000/'}
2025-01-13 22:33:58,380 - root - INFO - Scraped item: {'abstract': 'Hash tables are ubiquitous, and the choice of hash function, '
             'which maps a key to a bucket, is key for their performance. We '
             'argue that the predominant approach of fixing the hash function '
             'for the lifetime of the hash table is suboptimal and propose '
             'adapting it to the current set of keys. In the prevailing view, '
             "good hash functions spread the keys ``randomly'' and are fast to "
             'evaluate. General-purpose ones (e.g. Murmur) are designed to do '
             'both while remaining agnostic to the distribution of the keys, '
             'which limits their bucketing ability and wastes computation. '
             'When these shortcomings are recognised, the user of the hash '
             'table may specify a hash function more tailored to the expected '
             'key distribution, but doing so almost always introduces an '
             'unbounded risk in case their assumptions do not bear out in '
             'practice. At the other, fully key-aware end of the spectrum, '
             'Perfect Hashing algorithms can discover hash functions to bucket '
             'a given set of keys optimally, but they are costly to run and '
             'require the keys to be known and fixed ahead of time. Our main '
             "conceptual contribution is that adapting the hash table's hash "
             'function to the keys online is necessary for the best '
             'performance as adaptivity allows for better bucketing of '
             'keysandfaster hash functions. We instantiate the idea of online '
             'adaptation with minimal overhead and no change to the hash table '
             'API. The experiments show that the adaptive approach marries the '
             'common-case performance of weak hash functions with the '
             'robustness of general-purpose ones.',
 'title': 'Adaptive Hashing: Faster Hash Functions Perhaps with Fewer '
          'Collisions',
 'url': 'https://deepmind.google/research/publications/81077/'}
2025-01-13 22:33:58,391 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/81077/>
{'abstract': 'Hash tables are ubiquitous, and the choice of hash function, '
             'which maps a key to a bucket, is key for their performance. We '
             'argue that the predominant approach of fixing the hash function '
             'for the lifetime of the hash table is suboptimal and propose '
             'adapting it to the current set of keys. In the prevailing view, '
             "good hash functions spread the keys ``randomly'' and are fast to "
             'evaluate. General-purpose ones (e.g. Murmur) are designed to do '
             'both while remaining agnostic to the distribution of the keys, '
             'which limits their bucketing ability and wastes computation. '
             'When these shortcomings are recognised, the user of the hash '
             'table may specify a hash function more tailored to the expected '
             'key distribution, but doing so almost always introduces an '
             'unbounded risk in case their assumptions do not bear out in '
             'practice. At the other, fully key-aware end of the spectrum, '
             'Perfect Hashing algorithms can discover hash functions to bucket '
             'a given set of keys optimally, but they are costly to run and '
             'require the keys to be known and fixed ahead of time. Our main '
             "conceptual contribution is that adapting the hash table's hash "
             'function to the keys online is necessary for the best '
             'performance as adaptivity allows for better bucketing of '
             'keysandfaster hash functions. We instantiate the idea of online '
             'adaptation with minimal overhead and no change to the hash table '
             'API. The experiments show that the adaptive approach marries the '
             'common-case performance of weak hash functions with the '
             'robustness of general-purpose ones.',
 'title': 'Adaptive Hashing: Faster Hash Functions Perhaps with Fewer '
          'Collisions',
 'url': 'https://deepmind.google/research/publications/81077/'}
2025-01-13 22:33:58,398 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50878/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:58,404 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/122292/> (referer: https://deepmind.google/research/publications/)
2025-01-13 22:33:58,543 - root - INFO - Scraped item: {'abstract': 'Realistic simulation is critical for applications ranging from '
             'robotics to animation. Traditional analytic simulators sometimes '
             'struggle to capture sufficiently realistic simulation which can '
             'lead to problems including the well known "sim-to-real" gap. '
             'Learned simulators have emerged as an alternative for better '
             'capturing real-world physical dynamics, but require access to '
             'privileged ground truth physics information such as precise '
             'object geometry or particle tracks. Here we propose a method for '
             'learning simulators directly from observations.  Visual Particle '
             'Dynamics (VPD) jointly learns a latent particle-based '
             'representation of 3D scenes, a neural simulator of the dynamics '
             'of that representation, and a renderer that can produce images '
             'of the scene from arbitrary views. VPD learns end to end from '
             'posed videos and does not require access to privileged '
             'information. Unlike existing 2D video prediction models, we show '
             'that 3D inductive biases enable VPD to compositionally '
             'generalize and make long-term predictions. These results pave '
             'the way for downstream applications ranging from video editing '
             'to robotic planning.',
 'title': 'Learning 3D Particle-based Simulators from RGB-D Videos',
 'url': 'https://deepmind.google/research/publications/50878/'}
2025-01-13 22:33:58,555 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50878/>
{'abstract': 'Realistic simulation is critical for applications ranging from '
             'robotics to animation. Traditional analytic simulators sometimes '
             'struggle to capture sufficiently realistic simulation which can '
             'lead to problems including the well known "sim-to-real" gap. '
             'Learned simulators have emerged as an alternative for better '
             'capturing real-world physical dynamics, but require access to '
             'privileged ground truth physics information such as precise '
             'object geometry or particle tracks. Here we propose a method for '
             'learning simulators directly from observations.  Visual Particle '
             'Dynamics (VPD) jointly learns a latent particle-based '
             'representation of 3D scenes, a neural simulator of the dynamics '
             'of that representation, and a renderer that can produce images '
             'of the scene from arbitrary views. VPD learns end to end from '
             'posed videos and does not require access to privileged '
             'information. Unlike existing 2D video prediction models, we show '
             'that 3D inductive biases enable VPD to compositionally '
             'generalize and make long-term predictions. These results pave '
             'the way for downstream applications ranging from video editing '
             'to robotic planning.',
 'title': 'Learning 3D Particle-based Simulators from RGB-D Videos',
 'url': 'https://deepmind.google/research/publications/50878/'}
2025-01-13 22:33:58,592 - root - INFO - Scraped item: {'abstract': 'Bayesian Optimization is ubiquitous in the field of experimental '
             'design and blackbox optimization for improving search '
             'efficiency, but has been traditionally restricted to regression '
             'models which are only applicable to fixed search spaces and '
             'tabular input features. We proposeEmbed-then-Regress, a paradigm '
             'for applying in-context regression over string inputs, through '
             'the use of string embedding capabilities of pretrained language '
             'models. By expressing all inputs as strings, we are able to '
             'perform general-purpose regression for Bayesian Optimization '
             'over various domains including synthetic, combinatorial, and '
             'hyperparameter optimization, obtaining comparable results to '
             'state-of-the-art Gaussian Process-based algorithms.',
 'title': 'Predicting from Strings: Language Model Embeddings for Bayesian '
          'Optimization',
 'url': 'https://deepmind.google/research/publications/122292/'}
2025-01-13 22:33:58,604 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/122292/>
{'abstract': 'Bayesian Optimization is ubiquitous in the field of experimental '
             'design and blackbox optimization for improving search '
             'efficiency, but has been traditionally restricted to regression '
             'models which are only applicable to fixed search spaces and '
             'tabular input features. We proposeEmbed-then-Regress, a paradigm '
             'for applying in-context regression over string inputs, through '
             'the use of string embedding capabilities of pretrained language '
             'models. By expressing all inputs as strings, we are able to '
             'perform general-purpose regression for Bayesian Optimization '
             'over various domains including synthetic, combinatorial, and '
             'hyperparameter optimization, obtaining comparable results to '
             'state-of-the-art Gaussian Process-based algorithms.',
 'title': 'Predicting from Strings: Language Model Embeddings for Bayesian '
          'Optimization',
 'url': 'https://deepmind.google/research/publications/122292/'}
2025-01-13 22:33:58,628 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/42798/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:58,637 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/78149/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:58,777 - root - INFO - Scraped item: {'abstract': 'Privacy amplification exploits randomness in data selection to '
             'provide tighter differential privacy (DP) guarantees. This '
             "analysis is key to DP-SGD's success in machine learning, but, is "
             'not readily applicable to the newer state-of-the-art algorithms. '
             'This is because these algorithms, known as DP-FTRL, use the '
             'matrix mechanism to add correlated noise instead of independent '
             'noise as in DP-SGD.\n'
             'In this paper, we propose "MMCC", the first algorithm to analyze '
             'privacy amplification via sampling for any generic matrix '
             'mechanism. MMCC is nearly tight in that it approaches a lower '
             'bound as \u03f5\u21920. To analyze correlated outputs in MMCC, we prove '
             'that they can be analyzed as if they were independent, by '
             'conditioning them on prior outputs. Our "conditional composition '
             'theorem" has broad utility: we use it to show that the noise '
             'added to binary-tree-DP-FTRL can asymptotically match the noise '
             'added to DP-SGD with amplification. Our amplification algorithm '
             'also has practical empirical utility: we show it leads to '
             'significant improvement in the privacy-utility trade-offs for '
             'DP-FTRL algorithms on standard benchmarks.',
 'title': 'Privacy Amplification by Sampling for the Matrix Mechanism.',
 'url': 'https://deepmind.google/research/publications/42798/'}
2025-01-13 22:33:58,795 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/42798/>
{'abstract': 'Privacy amplification exploits randomness in data selection to '
             'provide tighter differential privacy (DP) guarantees. This '
             "analysis is key to DP-SGD's success in machine learning, but, is "
             'not readily applicable to the newer state-of-the-art algorithms. '
             'This is because these algorithms, known as DP-FTRL, use the '
             'matrix mechanism to add correlated noise instead of independent '
             'noise as in DP-SGD.\n'
             'In this paper, we propose "MMCC", the first algorithm to analyze '
             'privacy amplification via sampling for any generic matrix '
             'mechanism. MMCC is nearly tight in that it approaches a lower '
             'bound as \u03f5\u21920. To analyze correlated outputs in MMCC, we prove '
             'that they can be analyzed as if they were independent, by '
             'conditioning them on prior outputs. Our "conditional composition '
             'theorem" has broad utility: we use it to show that the noise '
             'added to binary-tree-DP-FTRL can asymptotically match the noise '
             'added to DP-SGD with amplification. Our amplification algorithm '
             'also has practical empirical utility: we show it leads to '
             'significant improvement in the privacy-utility trade-offs for '
             'DP-FTRL algorithms on standard benchmarks.',
 'title': 'Privacy Amplification by Sampling for the Matrix Mechanism.',
 'url': 'https://deepmind.google/research/publications/42798/'}
2025-01-13 22:33:58,833 - root - INFO - Scraped item: {'abstract': 'AI evaluation–the measurement of AI capabilities, behavior, and '
             'impact–is critical for safety. The field of safety evaluations '
             'however remains nascent. In the development of Google DeepMind’s '
             'Gemini models, we innovated on and applied a diverse set of '
             'approaches to safety evaluation. To contribute to the maturation '
             'of the field, we share here some aspects of our evolving '
             'approach and lessons learned. First, theoretical frameworks are '
             'invaluable to organize the breadth of risk domains, modalities, '
             'forms, metrics, and goals. Second, theory and practice each '
             'benefit from collaboration: clarifying goals, methods, and '
             'challenges, and facilitating the transfer of insights and work '
             'across the evaluation development pipeline. Third, methods, '
             'lessons, and institutions transfer across the range of concerns '
             'in responsibility and safety, including present harms and '
             'dangerous capabilities. Safety evaluations are a public good, '
             'and as such we need to rapidly advance the science of evals, the '
             'thickness of scientifically-grounded norms and standards, the '
             'innovativeness of the ecosystem, and the integration of these '
             'measures into company policy and public policy.',
 'title': 'Holistic Safety and Responsibility Evaluations of Advanced AI '
          'Models',
 'url': 'https://deepmind.google/research/publications/78149/'}
2025-01-13 22:33:58,846 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/78149/>
{'abstract': 'AI evaluation–the measurement of AI capabilities, behavior, and '
             'impact–is critical for safety. The field of safety evaluations '
             'however remains nascent. In the development of Google DeepMind’s '
             'Gemini models, we innovated on and applied a diverse set of '
             'approaches to safety evaluation. To contribute to the maturation '
             'of the field, we share here some aspects of our evolving '
             'approach and lessons learned. First, theoretical frameworks are '
             'invaluable to organize the breadth of risk domains, modalities, '
             'forms, metrics, and goals. Second, theory and practice each '
             'benefit from collaboration: clarifying goals, methods, and '
             'challenges, and facilitating the transfer of insights and work '
             'across the evaluation development pipeline. Third, methods, '
             'lessons, and institutions transfer across the range of concerns '
             'in responsibility and safety, including present harms and '
             'dangerous capabilities. Safety evaluations are a public good, '
             'and as such we need to rapidly advance the science of evals, the '
             'thickness of scientifically-grounded norms and standards, the '
             'innovativeness of the ecosystem, and the integration of these '
             'measures into company policy and public policy.',
 'title': 'Holistic Safety and Responsibility Evaluations of Advanced AI '
          'Models',
 'url': 'https://deepmind.google/research/publications/78149/'}
2025-01-13 22:33:58,933 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/90066/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:59,071 - root - INFO - Scraped item: {'abstract': 'We improve the proofs of the lower bounds of Coquelin and Munos '
             '(2007)\n'
             'that demonstrate that UCT can have $\\exp(\\dots\\exp(1)\\dots)$ '
             'regret\n'
             '(with $\\Omega(D)$ exp terms)\n'
             "on the $D$-chain environment, and that a `polynomial' UCT "
             'variant has $\\exp_2(\\exp_2(D - O(\\log D)))$ regret on the '
             'same environment ---\n'
             'the original proofs contain an oversight for rewards bounded in '
             '$[0, 1]$, which we fix in the present draft.\n'
             "We also adapt the proofs to AlphaGo's MCTS and its descendants "
             '(e.g., AlphaZero, Leela Zero) to also show\n'
             '$\\exp_2(\\exp_2(D - O(\\log D)))$ regret.',
 'title': 'Super-Exponential Regret for UCT, AlphaGo and Variants',
 'url': 'https://deepmind.google/research/publications/90066/'}
2025-01-13 22:33:59,084 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/90066/>
{'abstract': 'We improve the proofs of the lower bounds of Coquelin and Munos '
             '(2007)\n'
             'that demonstrate that UCT can have $\\exp(\\dots\\exp(1)\\dots)$ '
             'regret\n'
             '(with $\\Omega(D)$ exp terms)\n'
             "on the $D$-chain environment, and that a `polynomial' UCT "
             'variant has $\\exp_2(\\exp_2(D - O(\\log D)))$ regret on the '
             'same environment ---\n'
             'the original proofs contain an oversight for rewards bounded in '
             '$[0, 1]$, which we fix in the present draft.\n'
             "We also adapt the proofs to AlphaGo's MCTS and its descendants "
             '(e.g., AlphaZero, Leela Zero) to also show\n'
             '$\\exp_2(\\exp_2(D - O(\\log D)))$ regret.',
 'title': 'Super-Exponential Regret for UCT, AlphaGo and Variants',
 'url': 'https://deepmind.google/research/publications/90066/'}
2025-01-13 22:33:59,098 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/33304/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:59,108 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=3> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:59,245 - root - INFO - Scraped item: {'abstract': 'The bookAn Introduction to Universal Artificial '
             'Intelligenceprovides the formal underpinning of what it means '
             'for an agent to act intelligently in an unknown environment. '
             'First presented in Universal Algorithmic Intelligence (Hutter, '
             '2000), UAI offers a framework in which virtually all AI problems '
             'can be formulated, and a theory of how to solve them. UAI '
             'unifies ideas from sequential decision theory, Bayesian '
             'inference, and algorithmic information theory to construct AIXI, '
             'an optimal reinforcement learning agent that learns to act '
             'optimally in unknown environments. AIXI is the theoretical gold '
             'standard for intelligent behavior.',
 'title': 'An Introduction to Universal Artificial Intelligence',
 'url': 'https://deepmind.google/research/publications/33304/'}
2025-01-13 22:33:59,259 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/33304/>
{'abstract': 'The bookAn Introduction to Universal Artificial '
             'Intelligenceprovides the formal underpinning of what it means '
             'for an agent to act intelligently in an unknown environment. '
             'First presented in Universal Algorithmic Intelligence (Hutter, '
             '2000), UAI offers a framework in which virtually all AI problems '
             'can be formulated, and a theory of how to solve them. UAI '
             'unifies ideas from sequential decision theory, Bayesian '
             'inference, and algorithmic information theory to construct AIXI, '
             'an optimal reinforcement learning agent that learns to act '
             'optimally in unknown environments. AIXI is the theoretical gold '
             'standard for intelligent behavior.',
 'title': 'An Introduction to Universal Artificial Intelligence',
 'url': 'https://deepmind.google/research/publications/33304/'}
2025-01-13 22:33:59,263 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=3
2025-01-13 22:33:59,639 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/77643/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:59,652 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49061/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:59,757 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/88147/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:33:59,795 - root - INFO - Scraped item: {'abstract': 'Undeniably, Large Language Models (LLMs) have stirred an '
             'extraordinary wave of innovation in the machine learning '
             'research domain, resulting in substantial impact across diverse '
             'fields such as reinforcement learning, robotics, and computer '
             'vision. Their incorporation has been rapid and transformative, '
             'marking a significant paradigm shift in the field of machine '
             'learning research. However, the field of experimental design, '
             'grounded on black-box optimization, has been much less affected '
             'by such a paradigm shift, even though integrating LLMs with '
             'optimization presents a unique landscape ripe for exploration. '
             'In this position paper, we frame the field of black-box '
             'optimization around sequence-based foundation models and '
             'organize their relationship with previous literature. We discuss '
             'the most promising ways foundational language models can '
             'revolutionize optimization, which include harnessing the vast '
             'wealth of information encapsulated in free-form text to enrich '
             'task comprehension, utilizing highly flexible sequence models '
             'such as Transformers to engineer superior optimization '
             'strategies, and enhancing performance prediction over previously '
             'unseen search spaces.',
 'title': 'Position: Leverage Foundational Models for Black-Box Optimization',
 'url': 'https://deepmind.google/research/publications/77643/'}
2025-01-13 22:33:59,807 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/77643/>
{'abstract': 'Undeniably, Large Language Models (LLMs) have stirred an '
             'extraordinary wave of innovation in the machine learning '
             'research domain, resulting in substantial impact across diverse '
             'fields such as reinforcement learning, robotics, and computer '
             'vision. Their incorporation has been rapid and transformative, '
             'marking a significant paradigm shift in the field of machine '
             'learning research. However, the field of experimental design, '
             'grounded on black-box optimization, has been much less affected '
             'by such a paradigm shift, even though integrating LLMs with '
             'optimization presents a unique landscape ripe for exploration. '
             'In this position paper, we frame the field of black-box '
             'optimization around sequence-based foundation models and '
             'organize their relationship with previous literature. We discuss '
             'the most promising ways foundational language models can '
             'revolutionize optimization, which include harnessing the vast '
             'wealth of information encapsulated in free-form text to enrich '
             'task comprehension, utilizing highly flexible sequence models '
             'such as Transformers to engineer superior optimization '
             'strategies, and enhancing performance prediction over previously '
             'unseen search spaces.',
 'title': 'Position: Leverage Foundational Models for Black-Box Optimization',
 'url': 'https://deepmind.google/research/publications/77643/'}
2025-01-13 22:33:59,847 - root - INFO - Scraped item: {'abstract': 'When writing programs, people have the ability to tackle a new '
             'complex task by decomposing it into smaller and more familiar '
             'subtasks. While it is difficult to measure whether neural '
             'program synthesis methods have similar capabilities, we can '
             'measure whether they compositionally generalize, that is, '
             'whether a model that has been trained on the simpler subtasks is '
             'subsequently able to solve more complex tasks. In this paper, we '
             'characterize several different forms of compositional '
             'generalization that are desirable in program synthesis, forming '
             'a meta-benchmark which we use to create generalization tasks for '
             'two popular datasets, RobustFill and DeepCoder. We then propose '
             'ExeDec, a novel decomposition-based synthesis strategy that '
             'predicts execution subgoals to solve problems step-by-step '
             'informed by program execution at each step. When used with '
             'Transformer models trained from scratch, ExeDec has better '
             'synthesis performance and greatly improved compositional '
             'generalization ability compared to baselines. Finally, we use '
             'our benchmarks to demonstrate that LLMs struggle to '
             'compositionally generalize when asked to do '
             'programming-by-example in a few-shot setting, but an '
             'ExeDec-style prompting approach can improve the generalization '
             'ability and overall performance.',
 'title': 'ExeDec: Execution Decomposition for Compositional Generalization in '
          'Neural Program Synthesis',
 'url': 'https://deepmind.google/research/publications/49061/'}
2025-01-13 22:33:59,860 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49061/>
{'abstract': 'When writing programs, people have the ability to tackle a new '
             'complex task by decomposing it into smaller and more familiar '
             'subtasks. While it is difficult to measure whether neural '
             'program synthesis methods have similar capabilities, we can '
             'measure whether they compositionally generalize, that is, '
             'whether a model that has been trained on the simpler subtasks is '
             'subsequently able to solve more complex tasks. In this paper, we '
             'characterize several different forms of compositional '
             'generalization that are desirable in program synthesis, forming '
             'a meta-benchmark which we use to create generalization tasks for '
             'two popular datasets, RobustFill and DeepCoder. We then propose '
             'ExeDec, a novel decomposition-based synthesis strategy that '
             'predicts execution subgoals to solve problems step-by-step '
             'informed by program execution at each step. When used with '
             'Transformer models trained from scratch, ExeDec has better '
             'synthesis performance and greatly improved compositional '
             'generalization ability compared to baselines. Finally, we use '
             'our benchmarks to demonstrate that LLMs struggle to '
             'compositionally generalize when asked to do '
             'programming-by-example in a few-shot setting, but an '
             'ExeDec-style prompting approach can improve the generalization '
             'ability and overall performance.',
 'title': 'ExeDec: Execution Decomposition for Compositional Generalization in '
          'Neural Program Synthesis',
 'url': 'https://deepmind.google/research/publications/49061/'}
2025-01-13 22:33:59,903 - root - INFO - Scraped item: {'abstract': 'Recent work has found that sparse autoencoders (SAEs) are an '
             'effective technique for unsupervised discovery of interpretable '
             "features in language models' (LMs) activations, by finding "
             'sparse, linear reconstructions of LM activations. We introduce '
             'the Gated Sparse Autoencoder (Gated SAE), which achieves a '
             'Pareto improvement over training with prevailing methods. In '
             'SAEs, the L1 penalty used to encourage sparsity introduces many '
             'undesirable biases, such as shrinkage -- systematic '
             'underestimation of feature activations. The key insight of Gated '
             'SAEs is to separate the functionality of (a) determining which '
             'directions to use and (b) estimating the magnitudes of those '
             'directions: this enables us to apply the L1 penalty only to the '
             'former, limiting the scope of undesirable side effects. Through '
             'training SAEs on LMs of up to 7B parameters we find that, in '
             'typical hyper-parameter ranges, Gated SAEs solve shrinkage, are '
             'similarly interpretable, and require half as many firing '
             'features to achieve comparable reconstruction fidelity.',
 'title': 'Improving Dictionary Learning with Gated Sparse Autoencoders',
 'url': 'https://deepmind.google/research/publications/88147/'}
2025-01-13 22:33:59,917 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/88147/>
{'abstract': 'Recent work has found that sparse autoencoders (SAEs) are an '
             'effective technique for unsupervised discovery of interpretable '
             "features in language models' (LMs) activations, by finding "
             'sparse, linear reconstructions of LM activations. We introduce '
             'the Gated Sparse Autoencoder (Gated SAE), which achieves a '
             'Pareto improvement over training with prevailing methods. In '
             'SAEs, the L1 penalty used to encourage sparsity introduces many '
             'undesirable biases, such as shrinkage -- systematic '
             'underestimation of feature activations. The key insight of Gated '
             'SAEs is to separate the functionality of (a) determining which '
             'directions to use and (b) estimating the magnitudes of those '
             'directions: this enables us to apply the L1 penalty only to the '
             'former, limiting the scope of undesirable side effects. Through '
             'training SAEs on LMs of up to 7B parameters we find that, in '
             'typical hyper-parameter ranges, Gated SAEs solve shrinkage, are '
             'similarly interpretable, and require half as many firing '
             'features to achieve comparable reconstruction fidelity.',
 'title': 'Improving Dictionary Learning with Gated Sparse Autoencoders',
 'url': 'https://deepmind.google/research/publications/88147/'}
2025-01-13 22:34:00,142 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/39768/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,151 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/70876/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,284 - root - INFO - Scraped item: {'abstract': 'The established correlation between predictive ability '
             'andcompression in models forms the cornerstone of this research. '
             'Given that languagemodels exhibit strong predictive qualities, '
             'it is assumed that they will also excelat compression. This '
             'paper seeks to evaluate the efficacy of language models '
             'ascompressors and assess how they measure up against other '
             'prominent predictors.Furthermore, we delve into the constraints '
             'of these models and explore the potentialbenefits of reframing '
             'the AI problem from a compression standpoint, as opposedto a '
             'purely predictive one.',
 'title': 'Language Modeling Is Compression',
 'url': 'https://deepmind.google/research/publications/39768/'}
2025-01-13 22:34:00,293 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/39768/>
{'abstract': 'The established correlation between predictive ability '
             'andcompression in models forms the cornerstone of this research. '
             'Given that languagemodels exhibit strong predictive qualities, '
             'it is assumed that they will also excelat compression. This '
             'paper seeks to evaluate the efficacy of language models '
             'ascompressors and assess how they measure up against other '
             'prominent predictors.Furthermore, we delve into the constraints '
             'of these models and explore the potentialbenefits of reframing '
             'the AI problem from a compression standpoint, as opposedto a '
             'purely predictive one.',
 'title': 'Language Modeling Is Compression',
 'url': 'https://deepmind.google/research/publications/39768/'}
2025-01-13 22:34:00,337 - root - INFO - Scraped item: {'abstract': 'We interviewed professional comedians who perform live shows in '
             'front of audiences and who use artificial intelligence in their '
             'artistic process. To that end, we recruited ten participants at '
             'the Edinburgh Festival Fringe in August 2023 and ten more '
             'participants online for 3-hour workshops on "AI x Comedy", '
             'aiming to ensure linguistic, cultural, gender, sexual, national '
             'and racial diversity among participants. The workshop consisted '
             'of a comedy writing session with large language models (LLMs), a '
             'human-computer interaction questionnaire to assess the '
             'Creativity Support Index of the AI writing tool, and a focus '
             'group. Guided discussions in the focus group touched about the '
             "comedians' motivations and artistic processes, the biases and "
             'potentials of the LLM tools and their limitations as a '
             "Creativity Support Tool, as well as the comedians' ethical "
             'concerns about bias, censorship and copyright. Participants '
             'noted that the moderation strategies used during '
             'instruction-tuning of the LLMs reinforced hegemonic viewpoints '
             'by erasing minority groups, and qualified this as a form of '
             'censorship. At the same time, the LLMs did not succeed as a good '
             'creativity support tool, by producing stereotypical and biased '
             'comedy tropes, akin to "cruise ship comedy material from the '
             '1950ies, but a bit less racist". Our work extends scholarship '
             'about the subtle difference between "offensive" language as a '
             'practice of resistance---and, equivalently, in comedy, of '
             '"punching up" and satire---and harmful speech. We also '
             'interrogate the global value alignment behind such language '
             'models and discuss community-based value alignment and data '
             "ownership to build AI tools that better suit the artists' needs.",
 'title': 'A Robot Walks into a Bar: Can Language Models Serve as Creativity '
          "Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment "
          'with Comedians',
 'url': 'https://deepmind.google/research/publications/70876/'}
2025-01-13 22:34:00,348 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/70876/>
{'abstract': 'We interviewed professional comedians who perform live shows in '
             'front of audiences and who use artificial intelligence in their '
             'artistic process. To that end, we recruited ten participants at '
             'the Edinburgh Festival Fringe in August 2023 and ten more '
             'participants online for 3-hour workshops on "AI x Comedy", '
             'aiming to ensure linguistic, cultural, gender, sexual, national '
             'and racial diversity among participants. The workshop consisted '
             'of a comedy writing session with large language models (LLMs), a '
             'human-computer interaction questionnaire to assess the '
             'Creativity Support Index of the AI writing tool, and a focus '
             'group. Guided discussions in the focus group touched about the '
             "comedians' motivations and artistic processes, the biases and "
             'potentials of the LLM tools and their limitations as a '
             "Creativity Support Tool, as well as the comedians' ethical "
             'concerns about bias, censorship and copyright. Participants '
             'noted that the moderation strategies used during '
             'instruction-tuning of the LLMs reinforced hegemonic viewpoints '
             'by erasing minority groups, and qualified this as a form of '
             'censorship. At the same time, the LLMs did not succeed as a good '
             'creativity support tool, by producing stereotypical and biased '
             'comedy tropes, akin to "cruise ship comedy material from the '
             '1950ies, but a bit less racist". Our work extends scholarship '
             'about the subtle difference between "offensive" language as a '
             'practice of resistance---and, equivalently, in comedy, of '
             '"punching up" and satire---and harmful speech. We also '
             'interrogate the global value alignment behind such language '
             'models and discuss community-based value alignment and data '
             "ownership to build AI tools that better suit the artists' needs.",
 'title': 'A Robot Walks into a Bar: Can Language Models Serve as Creativity '
          "Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment "
          'with Comedians',
 'url': 'https://deepmind.google/research/publications/70876/'}
2025-01-13 22:34:00,376 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/33405/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,433 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/25628/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,518 - root - INFO - Scraped item: {'abstract': 'In Online Continual Learning (OCL) a learning system receives a '
             'stream of data and sequentially performs prediction and training '
             'steps. Key challenges in OCL include automatic adaptation to the '
             'specific non-stationary structure of the data and maintaining '
             'appropriate predictive uncertainty. To address these challenges '
             'we introduce a probabilistic Bayesian online learning approach '
             'that utilizes a (possibly pretrained) neural representation and '
             'a state space model over the linear predictor weights. '
             'Non-stationarity in the linear predictor weights is modelled '
             'using a “parameter drift” transition density, parametrized by a '
             'coefficient that quantifies forgetting. Inference in the model '
             'is implemented with efficient Kalman filter recursions which '
             'track the posterior distribution over the linear weights, while '
             'online SGD updates over the transition dynamics coefficient '
             'allow for adaptation to the non-stationarity observed in the '
             'data. While the framework is developed assuming a linear '
             'Gaussian model, we extend it to deal with classification '
             'problems and for fine-tuning the deep learning representation. '
             'In a set of experiments in multi-class classification using data '
             'sets such as CIFAR-100 and CLOC we demonstrate the model’s '
             'predictive ability and its flexibility in capturing '
             'non-stationarity.',
 'title': 'Kalman Filter for Online Classification of Non-Stationary Data',
 'url': 'https://deepmind.google/research/publications/33405/'}
2025-01-13 22:34:00,532 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/33405/>
{'abstract': 'In Online Continual Learning (OCL) a learning system receives a '
             'stream of data and sequentially performs prediction and training '
             'steps. Key challenges in OCL include automatic adaptation to the '
             'specific non-stationary structure of the data and maintaining '
             'appropriate predictive uncertainty. To address these challenges '
             'we introduce a probabilistic Bayesian online learning approach '
             'that utilizes a (possibly pretrained) neural representation and '
             'a state space model over the linear predictor weights. '
             'Non-stationarity in the linear predictor weights is modelled '
             'using a “parameter drift” transition density, parametrized by a '
             'coefficient that quantifies forgetting. Inference in the model '
             'is implemented with efficient Kalman filter recursions which '
             'track the posterior distribution over the linear weights, while '
             'online SGD updates over the transition dynamics coefficient '
             'allow for adaptation to the non-stationarity observed in the '
             'data. While the framework is developed assuming a linear '
             'Gaussian model, we extend it to deal with classification '
             'problems and for fine-tuning the deep learning representation. '
             'In a set of experiments in multi-class classification using data '
             'sets such as CIFAR-100 and CLOC we demonstrate the model’s '
             'predictive ability and its flexibility in capturing '
             'non-stationarity.',
 'title': 'Kalman Filter for Online Classification of Non-Stationary Data',
 'url': 'https://deepmind.google/research/publications/33405/'}
2025-01-13 22:34:00,539 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/61382/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,613 - root - INFO - Scraped item: {'abstract': 'This paper introduces \u03c02vec, a method for representing black box '
             'policies as comparable feature vectors. Our method combines the '
             'strengths of foundation models that serve as generic and '
             'powerful state representations and successor features that can '
             'model the future occurrence of the states for a policy. \u03c02vec '
             'represents the behavior of policies by capturing the statistics '
             'of the features from a pretrained model with the help of '
             'successor feature framework. We focus on the offline setting '
             'where policies and their representations are trained on a fixed '
             'dataset of trajectories. Finally, we employ linear regression on '
             '\u03c02vec vector representations to predict the performance of held '
             'out policies. The synergy of these techniques results in a '
             'method for efficient policy evaluation in resource constrained '
             'environments.',
 'title': '\u03c02vec: Policy Representations with SuccessorFeatures',
 'url': 'https://deepmind.google/research/publications/25628/'}
2025-01-13 22:34:00,624 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/25628/>
{'abstract': 'This paper introduces \u03c02vec, a method for representing black box '
             'policies as comparable feature vectors. Our method combines the '
             'strengths of foundation models that serve as generic and '
             'powerful state representations and successor features that can '
             'model the future occurrence of the states for a policy. \u03c02vec '
             'represents the behavior of policies by capturing the statistics '
             'of the features from a pretrained model with the help of '
             'successor feature framework. We focus on the offline setting '
             'where policies and their representations are trained on a fixed '
             'dataset of trajectories. Finally, we employ linear regression on '
             '\u03c02vec vector representations to predict the performance of held '
             'out policies. The synergy of these techniques results in a '
             'method for efficient policy evaluation in resource constrained '
             'environments.',
 'title': '\u03c02vec: Policy Representations with SuccessorFeatures',
 'url': 'https://deepmind.google/research/publications/25628/'}
2025-01-13 22:34:00,630 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50273/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,686 - root - INFO - Scraped item: {'abstract': 'Neural fields have emerged as a powerful and broadly applicable '
             'method for representing signals. While there has been much work '
             'on applying these representations to various types of signals, '
             'the portfolio of signal processing tools that has been built up '
             'around discrete signal representations has seen only limited '
             'application to the world of neural fields. In this paper, we '
             'address this problem by showing how a probabilistic '
             're-interpretation of neural fields can enable their training and '
             'inference processes to become filter aware. The formulation we '
             'propose not only merges training and filtering in an efficient '
             'way, but also generalizes beyond the familiar Euclidean '
             'coordinate spaces to the more general set of smooth manifolds '
             'and convolutions induced by the actions of Lie groups. We '
             'demonstrate how this framework can enable novel filtering '
             'applications for neural fields on both Euclidean domains, such '
             'as images and audio, as well as non-Euclidean domains, such as '
             'rotations and rays. This is achieved with minimal modification '
             'to network architecture and training pipelines, and without an '
             'increase in computational complexity.',
 'title': 'Neural Fields as Distributions: Signal Processing Beyond Euclidean '
          'Space',
 'url': 'https://deepmind.google/research/publications/61382/'}
2025-01-13 22:34:00,702 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/61382/>
{'abstract': 'Neural fields have emerged as a powerful and broadly applicable '
             'method for representing signals. While there has been much work '
             'on applying these representations to various types of signals, '
             'the portfolio of signal processing tools that has been built up '
             'around discrete signal representations has seen only limited '
             'application to the world of neural fields. In this paper, we '
             'address this problem by showing how a probabilistic '
             're-interpretation of neural fields can enable their training and '
             'inference processes to become filter aware. The formulation we '
             'propose not only merges training and filtering in an efficient '
             'way, but also generalizes beyond the familiar Euclidean '
             'coordinate spaces to the more general set of smooth manifolds '
             'and convolutions induced by the actions of Lie groups. We '
             'demonstrate how this framework can enable novel filtering '
             'applications for neural fields on both Euclidean domains, such '
             'as images and audio, as well as non-Euclidean domains, such as '
             'rotations and rays. This is achieved with minimal modification '
             'to network architecture and training pipelines, and without an '
             'increase in computational complexity.',
 'title': 'Neural Fields as Distributions: Signal Processing Beyond Euclidean '
          'Space',
 'url': 'https://deepmind.google/research/publications/61382/'}
2025-01-13 22:34:00,729 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49869/> (referer: https://deepmind.google/research/publications/?page=2)
2025-01-13 22:34:00,781 - root - INFO - Scraped item: {'abstract': 'Differentially private (DP) learning algorithms inject noise '
             'into the learning process. While the most common private '
             'learning algorithm, DP-SGD, adds independent Gaussian noise in '
             'each iteration, recent work on matrix factorization mechanisms '
             'has shown empirically that introducing correlations in the noise '
             'can greatly improve their utility. We characterize the '
             'asymptotic learning utility for any choice of the correlation '
             'function, giving precise analytical bounds for linear regression '
             'and as the solution to a convex program for general convex '
             'functions. We show, using these bounds, how correlated noise '
             'provably improves upon vanilla DP-SGD as a function of problem '
             'parameters such as the effective dimension and condition number. '
             'Moreover, our analytical expression for the near-optimal '
             'correlation function circumvents the cubic complexity of the '
             'semi-definite program used to optimize the noise correlation '
             'matrix in previous work. We validate our theory with experiments '
             'on private deep learning. Our work matches or outperforms prior '
             'work while being efficient both in terms of compute and memory.',
 'title': 'CORRELATED NOISE PROVABLY BEATS INDEPENDENT NOISE FOR '
          'DIFFERENTIALLY PRIVATE LEARNING',
 'url': 'https://deepmind.google/research/publications/50273/'}
2025-01-13 22:34:00,794 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50273/>
{'abstract': 'Differentially private (DP) learning algorithms inject noise '
             'into the learning process. While the most common private '
             'learning algorithm, DP-SGD, adds independent Gaussian noise in '
             'each iteration, recent work on matrix factorization mechanisms '
             'has shown empirically that introducing correlations in the noise '
             'can greatly improve their utility. We characterize the '
             'asymptotic learning utility for any choice of the correlation '
             'function, giving precise analytical bounds for linear regression '
             'and as the solution to a convex program for general convex '
             'functions. We show, using these bounds, how correlated noise '
             'provably improves upon vanilla DP-SGD as a function of problem '
             'parameters such as the effective dimension and condition number. '
             'Moreover, our analytical expression for the near-optimal '
             'correlation function circumvents the cubic complexity of the '
             'semi-definite program used to optimize the noise correlation '
             'matrix in previous work. We validate our theory with experiments '
             'on private deep learning. Our work matches or outperforms prior '
             'work while being efficient both in terms of compute and memory.',
 'title': 'CORRELATED NOISE PROVABLY BEATS INDEPENDENT NOISE FOR '
          'DIFFERENTIALLY PRIVATE LEARNING',
 'url': 'https://deepmind.google/research/publications/50273/'}
2025-01-13 22:34:00,872 - root - INFO - Scraped item: {'abstract': 'How do neural networks extract patterns from pixels? Feature '
             'visualizations attempt to answer this important question by '
             'visualizing highly\n'
             'activating patterns through optimization. Today, visualization '
             'methods form the foundation of our knowledge about the internal '
             'workings of neural\n'
             'networks, as a type of mechanistic interpretability. Here we '
             'ask: How reliable are feature visualizations? We start our '
             'investigation by developing\n'
             'network circuits that trick feature visualizations into showing '
             'arbitrary patterns that are completely disconnected from normal '
             'network behavior on natural input. We then provide evidence for '
             'a similar phenomenon occurring in standard, unmanipulated '
             'networks: feature visualizations are\n'
             'processed very differently from standard input, casting doubt on '
             'their ability to “explain” how neural networks process natural '
             'images. We underpin this empirical finding by theory proving '
             'that the set of functions that can be reliably understood by '
             'feature visualization is extremely small and does not include '
             'black-box neural networks.',
 'title': "Don't trust your eyes: on the (un)reliability of feature "
          'visualizations',
 'url': 'https://deepmind.google/research/publications/49869/'}
2025-01-13 22:34:00,883 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49869/>
{'abstract': 'How do neural networks extract patterns from pixels? Feature '
             'visualizations attempt to answer this important question by '
             'visualizing highly\n'
             'activating patterns through optimization. Today, visualization '
             'methods form the foundation of our knowledge about the internal '
             'workings of neural\n'
             'networks, as a type of mechanistic interpretability. Here we '
             'ask: How reliable are feature visualizations? We start our '
             'investigation by developing\n'
             'network circuits that trick feature visualizations into showing '
             'arbitrary patterns that are completely disconnected from normal '
             'network behavior on natural input. We then provide evidence for '
             'a similar phenomenon occurring in standard, unmanipulated '
             'networks: feature visualizations are\n'
             'processed very differently from standard input, casting doubt on '
             'their ability to “explain” how neural networks process natural '
             'images. We underpin this empirical finding by theory proving '
             'that the set of functions that can be reliably understood by '
             'feature visualization is extremely small and does not include '
             'black-box neural networks.',
 'title': "Don't trust your eyes: on the (un)reliability of feature "
          'visualizations',
 'url': 'https://deepmind.google/research/publications/49869/'}
2025-01-13 22:34:01,057 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/31284/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:01,081 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/85521/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:01,200 - root - INFO - Scraped item: {'abstract': 'We investigated whether deep reinforcement learning (deep RL) is '
             'able to synthesize sophisticated and safe movement skills for a '
             'low-cost, miniature humanoid robot that can be composed into '
             'complex behavioral strategies. We used deep RL to train a '
             'humanoid robot to play a simplified one-versus-one soccer game. '
             'The resulting agent exhibits robust and dynamic movement skills, '
             'such as rapid fall recovery, walking, turning, and kicking, and '
             'it transitions between them in a smooth and efficient manner. It '
             'also learned to anticipate ball movements and block opponent '
             'shots. The agent’s tactical behavior adapts to specific game '
             'contexts in a way that would be impractical to manually design. '
             'Our agent was trained in simulation and transferred to real '
             'robots zero-shot. A combination of sufficiently high-frequency '
             'control, targeted dynamics randomization, and perturbations '
             'during training enabled good-quality transfer. In experiments, '
             'the agent walked 181% faster, turned 302% faster, took 63% less '
             'time to get up, and kicked a ball 34% faster than a scripted '
             'baseline.',
 'title': 'Learning Agile Soccer Skills for a Bipedal Robot with Deep '
          'Reinforcement Learning',
 'url': 'https://deepmind.google/research/publications/31284/'}
2025-01-13 22:34:01,214 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/31284/>
{'abstract': 'We investigated whether deep reinforcement learning (deep RL) is '
             'able to synthesize sophisticated and safe movement skills for a '
             'low-cost, miniature humanoid robot that can be composed into '
             'complex behavioral strategies. We used deep RL to train a '
             'humanoid robot to play a simplified one-versus-one soccer game. '
             'The resulting agent exhibits robust and dynamic movement skills, '
             'such as rapid fall recovery, walking, turning, and kicking, and '
             'it transitions between them in a smooth and efficient manner. It '
             'also learned to anticipate ball movements and block opponent '
             'shots. The agent’s tactical behavior adapts to specific game '
             'contexts in a way that would be impractical to manually design. '
             'Our agent was trained in simulation and transferred to real '
             'robots zero-shot. A combination of sufficiently high-frequency '
             'control, targeted dynamics randomization, and perturbations '
             'during training enabled good-quality transfer. In experiments, '
             'the agent walked 181% faster, turned 302% faster, took 63% less '
             'time to get up, and kicked a ball 34% faster than a scripted '
             'baseline.',
 'title': 'Learning Agile Soccer Skills for a Bipedal Robot with Deep '
          'Reinforcement Learning',
 'url': 'https://deepmind.google/research/publications/31284/'}
2025-01-13 22:34:01,252 - root - INFO - Scraped item: {'abstract': 'We present Gecko, a compact and versatile text embedding model. '
             'Gecko achieves strong retrieval performance by leveraging a key '
             'idea: distilling knowledge from large language models (LLMs) '
             'into a retriever. Our two-step distillation process begins with '
             'generating diverse, synthetic paired data using an LLM. Next, we '
             'further refine the data quality by retrieving a set of candidate '
             'passages for each query, and relabeling the positive and hard '
             'negative passages using the same LLM. The effectiveness of our '
             'approach is demonstrated by the compactness of the Gecko. On the '
             'Massive Text Embedding Benchmark (MTEB), Gecko with 256 '
             'embedding dimensions outperforms all existing entries with 768 '
             'embedding size. Gecko with 768 embedding dimensions achieves an '
             'average score of 66.31, competing with 7x larger models and 5x '
             'higher dimensional embeddings.',
 'title': 'Gecko: Versatile Text Embeddings Distilled from Large Language '
          'Models',
 'url': 'https://deepmind.google/research/publications/85521/'}
2025-01-13 22:34:01,265 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/85521/>
{'abstract': 'We present Gecko, a compact and versatile text embedding model. '
             'Gecko achieves strong retrieval performance by leveraging a key '
             'idea: distilling knowledge from large language models (LLMs) '
             'into a retriever. Our two-step distillation process begins with '
             'generating diverse, synthetic paired data using an LLM. Next, we '
             'further refine the data quality by retrieving a set of candidate '
             'passages for each query, and relabeling the positive and hard '
             'negative passages using the same LLM. The effectiveness of our '
             'approach is demonstrated by the compactness of the Gecko. On the '
             'Massive Text Embedding Benchmark (MTEB), Gecko with 256 '
             'embedding dimensions outperforms all existing entries with 768 '
             'embedding size. Gecko with 768 embedding dimensions achieves an '
             'average score of 66.31, competing with 7x larger models and 5x '
             'higher dimensional embeddings.',
 'title': 'Gecko: Versatile Text Embeddings Distilled from Large Language '
          'Models',
 'url': 'https://deepmind.google/research/publications/85521/'}
2025-01-13 22:34:01,449 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/62998/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:01,587 - root - INFO - Scraped item: {'abstract': 'Power-law scaling indicates that large-scale training with '
             'uniform sampling is prohibitively slow. Active learning methods '
             'aim to increase data efficiency by prioritizing learning on the '
             'most relevant examples. Despite their appeal, these methods have '
             'yet to be widely adopted since no one algorithm has been shown '
             'to a) generalize across models and tasks b) scale to large '
             'datasets and c) yield overall FLOP savings when accounting for '
             'the overhead of data selection. In this work we propose a method '
             'which satisfies these three properties, leveraging small, cheap '
             'proxy models to estimate "learnability" scores for datapoints, '
             'which are used to prioritize data for the training of much '
             'larger models. As a result, our models require 46% and 51% fewer '
             'training updates and up to 25% less total computation to reach '
             'the same performance as uniformly trained visual classifiers on '
             'JFT and multimodal models on ALIGN. Finally, we find our '
             'data-prioritization scheme to be complementary with recent '
             'data-curation and learning objectives, yielding a new '
             'state-of-the-art in several multimodal transfer tasks.',
 'title': 'Bad Students Make Great Teachers: Active Learning Accelerates Large '
          'Scale Visual Understanding',
 'url': 'https://deepmind.google/research/publications/62998/'}
2025-01-13 22:34:01,600 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/62998/>
{'abstract': 'Power-law scaling indicates that large-scale training with '
             'uniform sampling is prohibitively slow. Active learning methods '
             'aim to increase data efficiency by prioritizing learning on the '
             'most relevant examples. Despite their appeal, these methods have '
             'yet to be widely adopted since no one algorithm has been shown '
             'to a) generalize across models and tasks b) scale to large '
             'datasets and c) yield overall FLOP savings when accounting for '
             'the overhead of data selection. In this work we propose a method '
             'which satisfies these three properties, leveraging small, cheap '
             'proxy models to estimate "learnability" scores for datapoints, '
             'which are used to prioritize data for the training of much '
             'larger models. As a result, our models require 46% and 51% fewer '
             'training updates and up to 25% less total computation to reach '
             'the same performance as uniformly trained visual classifiers on '
             'JFT and multimodal models on ALIGN. Finally, we find our '
             'data-prioritization scheme to be complementary with recent '
             'data-curation and learning objectives, yielding a new '
             'state-of-the-art in several multimodal transfer tasks.',
 'title': 'Bad Students Make Great Teachers: Active Learning Accelerates Large '
          'Scale Visual Understanding',
 'url': 'https://deepmind.google/research/publications/62998/'}
2025-01-13 22:34:01,814 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/88551/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:01,957 - root - INFO - Scraped item: {'abstract': 'Molecular dynamics (MD) simulations allow insights into complex '
             'processes, but accurate MD simulations require costly '
             'quantum-mechanical calculations. For larger systems, efficient '
             'but less reliable empirical force fields are used. '
             'Machine-learned force fields (MLFFs) offer similar accuracy as '
             'ab initio methods at orders-of-magnitude speedup, but struggle '
             'to model long-range interactions in large molecules. This work '
             'proposes a general approach to constructing accurate MLFFs for '
             'large-scale molecular simulations (GEMS) by training on '
             '“bottom-up” and “top-down” molecular fragments, from which the '
             'relevant interactions can be learned. GEMS allows '
             'nanosecond-scale MD simulations of >25,000 atoms at essentially '
             'ab initio quality, correctly predicts dynamical oscillations '
             'between different helical motifs in polyalanine, and yields good '
             'agreement with terahertz vibrational spectroscopy for '
             'large-scale protein-water fluctuations in solvated crambin. Our '
             'analyses indicate that simulations at ab initio accuracy might '
             'be necessary to understand dynamic biomolecular processes.',
 'title': 'Biomolecular dynamics with machine-learned quantum-mechanical force '
          'fields trained on diverse chemical fragments',
 'url': 'https://deepmind.google/research/publications/88551/'}
2025-01-13 22:34:01,971 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/88551/>
{'abstract': 'Molecular dynamics (MD) simulations allow insights into complex '
             'processes, but accurate MD simulations require costly '
             'quantum-mechanical calculations. For larger systems, efficient '
             'but less reliable empirical force fields are used. '
             'Machine-learned force fields (MLFFs) offer similar accuracy as '
             'ab initio methods at orders-of-magnitude speedup, but struggle '
             'to model long-range interactions in large molecules. This work '
             'proposes a general approach to constructing accurate MLFFs for '
             'large-scale molecular simulations (GEMS) by training on '
             '“bottom-up” and “top-down” molecular fragments, from which the '
             'relevant interactions can be learned. GEMS allows '
             'nanosecond-scale MD simulations of >25,000 atoms at essentially '
             'ab initio quality, correctly predicts dynamical oscillations '
             'between different helical motifs in polyalanine, and yields good '
             'agreement with terahertz vibrational spectroscopy for '
             'large-scale protein-water fluctuations in solvated crambin. Our '
             'analyses indicate that simulations at ab initio accuracy might '
             'be necessary to understand dynamic biomolecular processes.',
 'title': 'Biomolecular dynamics with machine-learned quantum-mechanical force '
          'fields trained on diverse chemical fragments',
 'url': 'https://deepmind.google/research/publications/88551/'}
2025-01-13 22:34:02,076 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/75635/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,184 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/88349/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,224 - root - INFO - Scraped item: {'abstract': 'In recent years, various methods and benchmarks have been '
             'proposed to empirically evaluate the alignment of artificial '
             'neural networks to human neural and behavioral data. But how '
             'aligned are different alignment metrics? To answer this '
             'question, we here analyze visual data from Brain-Score (Schrimpf '
             'et al., 2018), including metrics from the model-vs-human toolbox '
             '(Geirhos et al., 2021), together with human feature alignment '
             '(Linsley et al., 2018; Fel et al., 2022) and human similarity '
             'judgements (Muttenthaler et al., 2022). We find that pairwise '
             'correlations between neural scores and behavioral scores are '
             'quite low and sometimes even negative. For instance, the average '
             'correlation between those 95 models on Brain-Score that were '
             'fully evaluated on all 51 alignment metrics is only 0.161. '
             'Assuming that all of the employed metrics are sound, this '
             'implies that alignment\n'
             'with human perception may best be thought of as a '
             'multidimensional concept, with different methods measuring '
             'fundamentally different aspects. Our results underline the '
             'importance of integrative benchmarking, but also raise questions '
             'about how to correctly combine and aggregate individual metrics. '
             'Aggregating by taking the arithmetic average, as done in '
             'Brain-Score, leads to the overall performance currently being '
             'dominated by behavior (81.24% explained variance) while the '
             'neural predictivity plays a less important role (only 67.31% '
             'explained variance). As a first step towards making sure that '
             'different alignment metrics all contribute towards aggregated '
             'scores, we therefore conclude by comparing three different '
             'aggregation options.',
 'title': 'How aligned are different alignment metrics?',
 'url': 'https://deepmind.google/research/publications/75635/'}
2025-01-13 22:34:02,236 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/75635/>
{'abstract': 'In recent years, various methods and benchmarks have been '
             'proposed to empirically evaluate the alignment of artificial '
             'neural networks to human neural and behavioral data. But how '
             'aligned are different alignment metrics? To answer this '
             'question, we here analyze visual data from Brain-Score (Schrimpf '
             'et al., 2018), including metrics from the model-vs-human toolbox '
             '(Geirhos et al., 2021), together with human feature alignment '
             '(Linsley et al., 2018; Fel et al., 2022) and human similarity '
             'judgements (Muttenthaler et al., 2022). We find that pairwise '
             'correlations between neural scores and behavioral scores are '
             'quite low and sometimes even negative. For instance, the average '
             'correlation between those 95 models on Brain-Score that were '
             'fully evaluated on all 51 alignment metrics is only 0.161. '
             'Assuming that all of the employed metrics are sound, this '
             'implies that alignment\n'
             'with human perception may best be thought of as a '
             'multidimensional concept, with different methods measuring '
             'fundamentally different aspects. Our results underline the '
             'importance of integrative benchmarking, but also raise questions '
             'about how to correctly combine and aggregate individual metrics. '
             'Aggregating by taking the arithmetic average, as done in '
             'Brain-Score, leads to the overall performance currently being '
             'dominated by behavior (81.24% explained variance) while the '
             'neural predictivity plays a less important role (only 67.31% '
             'explained variance). As a first step towards making sure that '
             'different alignment metrics all contribute towards aggregated '
             'scores, we therefore conclude by comparing three different '
             'aggregation options.',
 'title': 'How aligned are different alignment metrics?',
 'url': 'https://deepmind.google/research/publications/75635/'}
2025-01-13 22:34:02,317 - root - INFO - Scraped item: {'abstract': 'Large language models (LLMs) excel at few-shot in-context '
             'learning (ICL) – learning from a few examples provided in '
             'context at inference, without any weight updates. Newly expanded '
             'context windows allow us to investigate ICL with hundreds or '
             'thousands of examples – the many-shot regime. Going from '
             'few-shot to many-shot, we observe significant performance gains '
             'across a wide variety of generative and discriminative tasks. '
             'While promising, many-shot ICL can be bottlenecked by the '
             'available amount of human-generated outputs. To mitigate this '
             'limitation, we explore two new settings: “Reinforced ICL” and '
             '“Unsupervised ICL”. Reinforced ICL uses model-generated '
             'chain-of-thought rationales in place of human rationales. '
             'Unsupervised ICL removes rationales from the prompt altogether, '
             'and prompts the model only with domain-specific inputs. We find '
             'that both Reinforced and Unsupervised ICL can be quite effective '
             'in the many-shot regime, particularly on complex reasoning '
             'tasks. Finally, we demonstrate that, unlike few-shot learning, '
             'many-shot learning is effective at overriding pretraining biases '
             'and can learn high-dimensional functions with numerical inputs. '
             'Our analysis also reveals the limitations of next-token '
             'prediction loss as an indicator of downstream performance.',
 'title': 'Many-Shot In-Context Learning',
 'url': 'https://deepmind.google/research/publications/88349/'}
2025-01-13 22:34:02,331 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/88349/>
{'abstract': 'Large language models (LLMs) excel at few-shot in-context '
             'learning (ICL) – learning from a few examples provided in '
             'context at inference, without any weight updates. Newly expanded '
             'context windows allow us to investigate ICL with hundreds or '
             'thousands of examples – the many-shot regime. Going from '
             'few-shot to many-shot, we observe significant performance gains '
             'across a wide variety of generative and discriminative tasks. '
             'While promising, many-shot ICL can be bottlenecked by the '
             'available amount of human-generated outputs. To mitigate this '
             'limitation, we explore two new settings: “Reinforced ICL” and '
             '“Unsupervised ICL”. Reinforced ICL uses model-generated '
             'chain-of-thought rationales in place of human rationales. '
             'Unsupervised ICL removes rationales from the prompt altogether, '
             'and prompts the model only with domain-specific inputs. We find '
             'that both Reinforced and Unsupervised ICL can be quite effective '
             'in the many-shot regime, particularly on complex reasoning '
             'tasks. Finally, we demonstrate that, unlike few-shot learning, '
             'many-shot learning is effective at overriding pretraining biases '
             'and can learn high-dimensional functions with numerical inputs. '
             'Our analysis also reveals the limitations of next-token '
             'prediction loss as an indicator of downstream performance.',
 'title': 'Many-Shot In-Context Learning',
 'url': 'https://deepmind.google/research/publications/88349/'}
2025-01-13 22:34:02,368 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/68553/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,509 - root - INFO - Scraped item: {'abstract': 'Causal attribution of behaviour is a foundational problem in '
             'interpretability. Activation Patching is a method of directly '
             'computing these causal attributions, and is ubiquitous in '
             'mechanistic interpretability analyses. However, scaling it to '
             'many attributions requires a sweep with cost scales linear in '
             'the number of model components, which can be prohibitively '
             'expensive, involving millions to billions of forward passes in '
             'SoTA models. We propose to use Attribution Patching (AtP), a '
             'gradient-based approximation that runs in $O(1)$ passes, as a '
             'pre-filtering step to Activation Patching.',
 'title': 'AtP*: Efficient and scalable methods for localizing LLM behaviour '
          'to components',
 'url': 'https://deepmind.google/research/publications/68553/'}
2025-01-13 22:34:02,521 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/68553/>
{'abstract': 'Causal attribution of behaviour is a foundational problem in '
             'interpretability. Activation Patching is a method of directly '
             'computing these causal attributions, and is ubiquitous in '
             'mechanistic interpretability analyses. However, scaling it to '
             'many attributions requires a sweep with cost scales linear in '
             'the number of model components, which can be prohibitively '
             'expensive, involving millions to billions of forward passes in '
             'SoTA models. We propose to use Attribution Patching (AtP), a '
             'gradient-based approximation that runs in $O(1)$ passes, as a '
             'pre-filtering step to Activation Patching.',
 'title': 'AtP*: Efficient and scalable methods for localizing LLM behaviour '
          'to components',
 'url': 'https://deepmind.google/research/publications/68553/'}
2025-01-13 22:34:02,572 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/32193/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,723 - root - INFO - Scraped item: {'abstract': 'In this paper, we present Randomized Q-learning (RandQL), a new '
             "algorithm that doesn't rely on a model and uses randomness to "
             'minimize regret in episodic Markov Decision Processes (MDPs). As '
             'far as we know, RandQL is the first feasible algorithm based on '
             "posterior sampling without needing a model. We evaluate RandQL's "
             'performance in both tabular and non-tabular settings. In tabular '
             'MDPs, RandQL achieves a regret bound of approximately O(sqrt(H^5 '
             '* S * A * T)), where H is the planning horizon, S is the number '
             'of states, A is the number of actions, and T is the number of '
             "episodes. For a metric state-action space, RandQL's regret bound "
             'is approximately O(H^(5/2) * T * (dz+1)/(dz+2)), where dz '
             'represents the zooming dimension. Importantly, RandQL achieves '
             'optimistic exploration without using bonuses; instead, it relies '
             'on a novel concept of randomizing the learning rate. Our '
             'experimental results demonstrate that RandQL surpasses existing '
             'methods in standard exploration environments.',
 'title': 'Model-free Posterior Sampling via Learning Rate Randomization',
 'url': 'https://deepmind.google/research/publications/32193/'}
2025-01-13 22:34:02,734 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/32193/>
{'abstract': 'In this paper, we present Randomized Q-learning (RandQL), a new '
             "algorithm that doesn't rely on a model and uses randomness to "
             'minimize regret in episodic Markov Decision Processes (MDPs). As '
             'far as we know, RandQL is the first feasible algorithm based on '
             "posterior sampling without needing a model. We evaluate RandQL's "
             'performance in both tabular and non-tabular settings. In tabular '
             'MDPs, RandQL achieves a regret bound of approximately O(sqrt(H^5 '
             '* S * A * T)), where H is the planning horizon, S is the number '
             'of states, A is the number of actions, and T is the number of '
             "episodes. For a metric state-action space, RandQL's regret bound "
             'is approximately O(H^(5/2) * T * (dz+1)/(dz+2)), where dz '
             'represents the zooming dimension. Importantly, RandQL achieves '
             'optimistic exploration without using bonuses; instead, it relies '
             'on a novel concept of randomizing the learning rate. Our '
             'experimental results demonstrate that RandQL surpasses existing '
             'methods in standard exploration environments.',
 'title': 'Model-free Posterior Sampling via Learning Rate Randomization',
 'url': 'https://deepmind.google/research/publications/32193/'}
2025-01-13 22:34:02,739 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/52090/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,743 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/30578/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,806 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/15533/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,822 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=4> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:02,882 - root - INFO - Scraped item: {'abstract': 'The core is a long standing solution concept in cooperative game '
             'theory, but is known to be hard to compute even for restricted '
             'classes of coalitional games. Cooperative game theory has many '
             'applications, ranging from analyzing power in decision making '
             'bodies and politics to predicting how human teams might decide '
             'to share profits achieved jointly. Another recent application of '
             'cooperative games in machine learning is explainable AI (XAI), '
             'and in particular identifying the key features or data points '
             'that were most influential on the predictions made by a black '
             'box model. Recent research has applied the Shapley value for '
             'these purposes, as it can be approximated\n'
             'using fast random algorithms. In this paper, we propose '
             'efficient algorithms for approximating the core in coalitional '
             'games, that iteratively refine a payoff vector by sampling the '
             'constraints posed by randomly selected coalitions. By overcoming '
             'the computational barrier, we show how the core can provide a '
             'desirable alternative to the Shapley value for many '
             'applications: political power analysis, predicting individual '
             'payoffs in human teams and explainable AI. Our empirical '
             'analysis shows how team stability is affected by game parameters '
             'for important classes of cooperative games (weighted voting '
             'games, graph games and marginal contribution networks). Further, '
             'we contrast the individual impact estimates of the Shapley value '
             'and the least-core in political settings and explainable AI '
             'analysis of multiple datasets.',
 'title': 'Approximating the Core of Cooperative Games',
 'url': 'https://deepmind.google/research/publications/52090/'}
2025-01-13 22:34:02,896 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/52090/>
{'abstract': 'The core is a long standing solution concept in cooperative game '
             'theory, but is known to be hard to compute even for restricted '
             'classes of coalitional games. Cooperative game theory has many '
             'applications, ranging from analyzing power in decision making '
             'bodies and politics to predicting how human teams might decide '
             'to share profits achieved jointly. Another recent application of '
             'cooperative games in machine learning is explainable AI (XAI), '
             'and in particular identifying the key features or data points '
             'that were most influential on the predictions made by a black '
             'box model. Recent research has applied the Shapley value for '
             'these purposes, as it can be approximated\n'
             'using fast random algorithms. In this paper, we propose '
             'efficient algorithms for approximating the core in coalitional '
             'games, that iteratively refine a payoff vector by sampling the '
             'constraints posed by randomly selected coalitions. By overcoming '
             'the computational barrier, we show how the core can provide a '
             'desirable alternative to the Shapley value for many '
             'applications: political power analysis, predicting individual '
             'payoffs in human teams and explainable AI. Our empirical '
             'analysis shows how team stability is affected by game parameters '
             'for important classes of cooperative games (weighted voting '
             'games, graph games and marginal contribution networks). Further, '
             'we contrast the individual impact estimates of the Shapley value '
             'and the least-core in political settings and explainable AI '
             'analysis of multiple datasets.',
 'title': 'Approximating the Core of Cooperative Games',
 'url': 'https://deepmind.google/research/publications/52090/'}
2025-01-13 22:34:02,935 - root - INFO - Scraped item: {'abstract': 'Reinforcement learning (RL) has shown promising results for '
             'real-time control systems, including the domain of plasma '
             'magnetic control. However, there are still significant drawbacks '
             'compared to traditional feedback control approaches for magnetic '
             'confinement. In this work, we address key drawbacks of the RL '
             'method; achieving higher control accuracy for desired plasma '
             'properties, reducing the steady-state error, and decreasing the '
             'required time to learn new tasks. We build on top of Degrave et '
             'al. (2022), and present algorithmic improvements to the agent '
             'architecture and training procedure. We present simulation '
             'results that show up to 65% improvement in shape accuracy, '
             'achieve substantial reduction in the long-term bias of the '
             'plasma current, and additionally reduce the training time '
             'required to learn new tasks by a factor of 3 or more. We present '
             'new experiments using the upgraded RL-based controllers on the '
             'TCV tokamak, which validate the simulation results achieved, and '
             'point the way towards routinely achieving accurate discharges '
             'using the RL approach.',
 'title': 'Towards Practical Reinforcement Learning for Tokamak Magnetic '
          'Control',
 'url': 'https://deepmind.google/research/publications/30578/'}
2025-01-13 22:34:02,947 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/30578/>
{'abstract': 'Reinforcement learning (RL) has shown promising results for '
             'real-time control systems, including the domain of plasma '
             'magnetic control. However, there are still significant drawbacks '
             'compared to traditional feedback control approaches for magnetic '
             'confinement. In this work, we address key drawbacks of the RL '
             'method; achieving higher control accuracy for desired plasma '
             'properties, reducing the steady-state error, and decreasing the '
             'required time to learn new tasks. We build on top of Degrave et '
             'al. (2022), and present algorithmic improvements to the agent '
             'architecture and training procedure. We present simulation '
             'results that show up to 65% improvement in shape accuracy, '
             'achieve substantial reduction in the long-term bias of the '
             'plasma current, and additionally reduce the training time '
             'required to learn new tasks by a factor of 3 or more. We present '
             'new experiments using the upgraded RL-based controllers on the '
             'TCV tokamak, which validate the simulation results achieved, and '
             'point the way towards routinely achieving accurate discharges '
             'using the RL approach.',
 'title': 'Towards Practical Reinforcement Learning for Tokamak Magnetic '
          'Control',
 'url': 'https://deepmind.google/research/publications/30578/'}
2025-01-13 22:34:02,987 - root - INFO - Scraped item: {'abstract': 'Humans learn powerful representations of objects and scenes by '
             'observing how they evolve over time. Yet, outside of specific '
             'tasks that require explicit temporal understanding, static image '
             'pretraining remains the dominant paradigm for learning visual '
             'foundation models. We question this mismatch, and ask whether '
             'video pretraining can yield visual representations that bear the '
             'hallmarks of human perception: generalisation across tasks, '
             'robustness to perturbations, and consistency with human '
             'judgements. To that end we propose a novel procedure for '
             'curating videos, and develop a contrastive framework which '
             'learns from the complex transformations therein. This simple '
             'paradigm for distilling knowledge from videos, called VITO, '
             'yields general representations that far outperform prior video '
             'pretraining methods on image understanding tasks, and image '
             'pretraining methods on video understanding tasks. Moreover, VITO '
             'representations are significantly more robust to natural and '
             'synthetic deformations than image-, video-, and '
             "adversarially-trained ones. Finally, VITO's predictions are "
             'strongly aligned with human judgements, surpassing models that '
             'were specifically trained for that purpose. Together, these '
             'results suggest that video pretraining could be a simple way of '
             'learning unified, robust, and human-aligned representations of '
             'the visual world.',
 'title': 'Self-supervised video pretraining yields strong image '
          'representations',
 'url': 'https://deepmind.google/research/publications/15533/'}
2025-01-13 22:34:02,998 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/15533/>
{'abstract': 'Humans learn powerful representations of objects and scenes by '
             'observing how they evolve over time. Yet, outside of specific '
             'tasks that require explicit temporal understanding, static image '
             'pretraining remains the dominant paradigm for learning visual '
             'foundation models. We question this mismatch, and ask whether '
             'video pretraining can yield visual representations that bear the '
             'hallmarks of human perception: generalisation across tasks, '
             'robustness to perturbations, and consistency with human '
             'judgements. To that end we propose a novel procedure for '
             'curating videos, and develop a contrastive framework which '
             'learns from the complex transformations therein. This simple '
             'paradigm for distilling knowledge from videos, called VITO, '
             'yields general representations that far outperform prior video '
             'pretraining methods on image understanding tasks, and image '
             'pretraining methods on video understanding tasks. Moreover, VITO '
             'representations are significantly more robust to natural and '
             'synthetic deformations than image-, video-, and '
             "adversarially-trained ones. Finally, VITO's predictions are "
             'strongly aligned with human judgements, surpassing models that '
             'were specifically trained for that purpose. Together, these '
             'results suggest that video pretraining could be a simple way of '
             'learning unified, robust, and human-aligned representations of '
             'the visual world.',
 'title': 'Self-supervised video pretraining yields strong image '
          'representations',
 'url': 'https://deepmind.google/research/publications/15533/'}
2025-01-13 22:34:03,001 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=4
2025-01-13 22:34:03,013 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/54918/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,017 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/78150/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,020 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/74310/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,160 - root - INFO - Scraped item: {'abstract': 'The prevalent deployment for learning from human preferences '
             'through reinforcement learning (RLHF) relies\n'
             'on two important approximations: the first assumes that pairwise '
             'preferences can be substituted with pointwise rewards. The '
             'second assumes that a reward model trained on these pointwise '
             'rewards can generalize from collected data to '
             'out-of-distribution data sampled by the policy. Recently,  '
             'Direct Preference Optimization (DPO) is proposed as an approach '
             'that bypass the second approximation and learn directly a policy '
             'from collected data without the reward modelling stage. However, '
             'DPO still heavily relies on the first approximation.',
 'title': 'Understanding Learning from Human Preferences',
 'url': 'https://deepmind.google/research/publications/54918/'}
2025-01-13 22:34:03,172 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/54918/>
{'abstract': 'The prevalent deployment for learning from human preferences '
             'through reinforcement learning (RLHF) relies\n'
             'on two important approximations: the first assumes that pairwise '
             'preferences can be substituted with pointwise rewards. The '
             'second assumes that a reward model trained on these pointwise '
             'rewards can generalize from collected data to '
             'out-of-distribution data sampled by the policy. Recently,  '
             'Direct Preference Optimization (DPO) is proposed as an approach '
             'that bypass the second approximation and learn directly a policy '
             'from collected data without the reward modelling stage. However, '
             'DPO still heavily relies on the first approximation.',
 'title': 'Understanding Learning from Human Preferences',
 'url': 'https://deepmind.google/research/publications/54918/'}
2025-01-13 22:34:03,211 - root - INFO - Scraped item: {'abstract': 'To understand the risks of a new AI system, we must understand '
             'what it can and cannot do.  To this end, we introduce a '
             'programme of new "dangerous capability" evaluations and pilot '
             'them on Gemini models. These evaluations cover five topics: (1) '
             'persuasion & deception; (2) cyber-security; (3) '
             'self-proliferation; (4) self-reasoning & self-modification; and '
             '(5) biological and nuclear risk. We do not find evidence of '
             'strong dangerous capabilities in the models we evaluated, but we '
             'flag early warning signs. Our goal is to help lay the groundwork '
             'for a rigorous science of dangerous capability evaluation, in '
             'preparation for future, more capable models.',
 'title': 'Evaluating Frontier Models for Dangerous Capabilities',
 'url': 'https://deepmind.google/research/publications/78150/'}
2025-01-13 22:34:03,223 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/78150/>
{'abstract': 'To understand the risks of a new AI system, we must understand '
             'what it can and cannot do.  To this end, we introduce a '
             'programme of new "dangerous capability" evaluations and pilot '
             'them on Gemini models. These evaluations cover five topics: (1) '
             'persuasion & deception; (2) cyber-security; (3) '
             'self-proliferation; (4) self-reasoning & self-modification; and '
             '(5) biological and nuclear risk. We do not find evidence of '
             'strong dangerous capabilities in the models we evaluated, but we '
             'flag early warning signs. Our goal is to help lay the groundwork '
             'for a rigorous science of dangerous capability evaluation, in '
             'preparation for future, more capable models.',
 'title': 'Evaluating Frontier Models for Dangerous Capabilities',
 'url': 'https://deepmind.google/research/publications/78150/'}
2025-01-13 22:34:03,263 - root - INFO - Scraped item: {'abstract': "In this paper, we investigate the use of `prosody' (the musical "
             'elements of speech) as a communicative signal for intuitive '
             'human-robot interaction interfaces. Our approach, rooted in '
             'Research through Design (RtD), examines the application of '
             'prosody in directing a quadruped robot navigation. We involved '
             'ten team members in an experiment to command a robot through an '
             'obstacle course using natural interaction. A human operator, '
             "serving as the robot's sensory and processing proxy, translated "
             'these interactions into navigation commands, effectively '
             'simulating an intuitive interface. During our analysis of '
             'interaction videos, where lexical and visual cues proved '
             'insufficient for accurate command interpretation, we turned to '
             'non-verbal auditory cues. Qualitative evidence suggests that '
             'participants intuitively relied on prosody to control the robot '
             'navigation. This paper discusses specific distinct prosodic '
             'constructs that emerged from our analysis and their functions. '
             'Our findings highlight prosody as a multifunctional '
             'communicative signal offering substantial potential for '
             'intuitive robotic interfaces.',
 'title': "Prosody for Intuitive Robotic Interface Design: It's Not What You "
          "Said, It's How You Said It",
 'url': 'https://deepmind.google/research/publications/74310/'}
2025-01-13 22:34:03,275 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/74310/>
{'abstract': "In this paper, we investigate the use of `prosody' (the musical "
             'elements of speech) as a communicative signal for intuitive '
             'human-robot interaction interfaces. Our approach, rooted in '
             'Research through Design (RtD), examines the application of '
             'prosody in directing a quadruped robot navigation. We involved '
             'ten team members in an experiment to command a robot through an '
             'obstacle course using natural interaction. A human operator, '
             "serving as the robot's sensory and processing proxy, translated "
             'these interactions into navigation commands, effectively '
             'simulating an intuitive interface. During our analysis of '
             'interaction videos, where lexical and visual cues proved '
             'insufficient for accurate command interpretation, we turned to '
             'non-verbal auditory cues. Qualitative evidence suggests that '
             'participants intuitively relied on prosody to control the robot '
             'navigation. This paper discusses specific distinct prosodic '
             'constructs that emerged from our analysis and their functions. '
             'Our findings highlight prosody as a multifunctional '
             'communicative signal offering substantial potential for '
             'intuitive robotic interfaces.',
 'title': "Prosody for Intuitive Robotic Interface Design: It's Not What You "
          "Said, It's How You Said It",
 'url': 'https://deepmind.google/research/publications/74310/'}
2025-01-13 22:34:03,522 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/41182/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,591 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/84915/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,671 - root - INFO - Scraped item: {'abstract': 'Incorporating expert demonstrations has empirically helped to '
             'improve the sample efficiency of reinforcement learning (RL). '
             'This paper quantifies theoretically to what extent this extra '
             "information reduces RL's sample complexity. In particular, we "
             'study the demonstration-regularized reinforcement learning that '
             'leverages the expert demonstrations by KL-regularization for a '
             'policy learned by behavior cloning. Our findings reveal that '
             'using NE expert demonstrations enables the identification of an '
             'optimal policy at a sample complexity of order '
             '\ue23b˜(Poly(S,A,H)/(\u03b52NE)) in finite and '
             '\ue23b˜(Poly(d,H)/(\u03b52NE)) in linear Markov decision processes, '
             'where \u03b5 is the target precision, H the horizon, A the number of '
             'action, S the number of states in the finite case and d the '
             'dimension of the feature space in the linear case. As a '
             'by-product, we provide tight convergence guarantees for the '
             'behaviour cloning procedure under general assumptions on the '
             'policy classes. Additionally, we establish that '
             'demonstration-regularized methods are provably efficient for '
             'reinforcement learning from human feedback (RLHF). In this '
             'respect, we provide theoretical evidence showing the benefits of '
             'KL-regularization for RLHF in tabular and linear MDPs. '
             'Interestingly, we avoid pessimism injection by employing '
             'computationally feasible regularization to handle reward '
             'estimation uncertainty, thus setting our approach apart from the '
             'prior works.',
 'title': 'Demonstration-Regularized RL',
 'url': 'https://deepmind.google/research/publications/41182/'}
2025-01-13 22:34:03,683 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/41182/>
{'abstract': 'Incorporating expert demonstrations has empirically helped to '
             'improve the sample efficiency of reinforcement learning (RL). '
             'This paper quantifies theoretically to what extent this extra '
             "information reduces RL's sample complexity. In particular, we "
             'study the demonstration-regularized reinforcement learning that '
             'leverages the expert demonstrations by KL-regularization for a '
             'policy learned by behavior cloning. Our findings reveal that '
             'using NE expert demonstrations enables the identification of an '
             'optimal policy at a sample complexity of order '
             '\ue23b˜(Poly(S,A,H)/(\u03b52NE)) in finite and '
             '\ue23b˜(Poly(d,H)/(\u03b52NE)) in linear Markov decision processes, '
             'where \u03b5 is the target precision, H the horizon, A the number of '
             'action, S the number of states in the finite case and d the '
             'dimension of the feature space in the linear case. As a '
             'by-product, we provide tight convergence guarantees for the '
             'behaviour cloning procedure under general assumptions on the '
             'policy classes. Additionally, we establish that '
             'demonstration-regularized methods are provably efficient for '
             'reinforcement learning from human feedback (RLHF). In this '
             'respect, we provide theoretical evidence showing the benefits of '
             'KL-regularization for RLHF in tabular and linear MDPs. '
             'Interestingly, we avoid pessimism injection by employing '
             'computationally feasible regularization to handle reward '
             'estimation uncertainty, thus setting our approach apart from the '
             'prior works.',
 'title': 'Demonstration-Regularized RL',
 'url': 'https://deepmind.google/research/publications/41182/'}
2025-01-13 22:34:03,736 - root - INFO - Scraped item: {'abstract': 'Progress in machine learning (ML) has been fueled by scaling '
             'neural network models.  This scaling has been enabled by ever '
             'more heroic feats of engineering, necessary for accommodating ML '
             'approaches that require high bandwidth communication between '
             'devices working in parallel.\n'
             'In this work, we propose a co-designed modular architecture and '
             'training approach for ML models, dubbed DIstributed PAth '
             'COmposition (DiPaCo).   During training, DiPaCo  distributes '
             'computation by paths through a set of shared modules.  Together '
             'with a Local-SGD inspired optimization (DiLoCo) that keeps '
             'modules in sync with drastically reduced communication,\n'
             'our approach enables training across poorly connected and '
             'potentially heterogeneous workers.\n'
             'At test time, only a single path needs to be executed for each '
             'input, without the need for any  model compression.  We\n'
             'consider this approach as a first prototype towards a new '
             'paradigm of large-scale learning, one that is less synchronous '
             'and more modular.\n'
             'Our experiments on the widely used C4 benchmark show that for '
             'the same amount of training steps but less wall-clock time, '
             'DiPaCo exceeds the performance of a 1B dense transformer '
             'language model using 256 paths of size 150M.',
 'title': 'DiPaCo: Distributed Path Composition',
 'url': 'https://deepmind.google/research/publications/84915/'}
2025-01-13 22:34:03,748 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/84915/>
{'abstract': 'Progress in machine learning (ML) has been fueled by scaling '
             'neural network models.  This scaling has been enabled by ever '
             'more heroic feats of engineering, necessary for accommodating ML '
             'approaches that require high bandwidth communication between '
             'devices working in parallel.\n'
             'In this work, we propose a co-designed modular architecture and '
             'training approach for ML models, dubbed DIstributed PAth '
             'COmposition (DiPaCo).   During training, DiPaCo  distributes '
             'computation by paths through a set of shared modules.  Together '
             'with a Local-SGD inspired optimization (DiLoCo) that keeps '
             'modules in sync with drastically reduced communication,\n'
             'our approach enables training across poorly connected and '
             'potentially heterogeneous workers.\n'
             'At test time, only a single path needs to be executed for each '
             'input, without the need for any  model compression.  We\n'
             'consider this approach as a first prototype towards a new '
             'paradigm of large-scale learning, one that is less synchronous '
             'and more modular.\n'
             'Our experiments on the widely used C4 benchmark show that for '
             'the same amount of training steps but less wall-clock time, '
             'DiPaCo exceeds the performance of a 1B dense transformer '
             'language model using 256 paths of size 150M.',
 'title': 'DiPaCo: Distributed Path Composition',
 'url': 'https://deepmind.google/research/publications/84915/'}
2025-01-13 22:34:03,755 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/85420/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,760 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/47848/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,793 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/15530/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:03,906 - root - INFO - Scraped item: {'abstract': 'Large language models (LLMs) often generate content that '
             'contains factual errors when responding to fact-seeking prompts '
             "on open-ended topics. To benchmark a model's long-form "
             'factuality in open domains, we first use GPT-4 to generate '
             'LongFact, a prompt set comprising thousands of questions '
             'spanning 38 topics. We then propose that LLM agents can be used '
             'as automated evaluators for long-form factuality through a '
             'method which we call Search-Augmented Factuality Evaluator '
             '(SAFE). SAFE utilizes an LLM to break down a long-form response '
             'into a set of individual facts and to evaluate the accuracy of '
             'each fact using a multi-step reasoning process comprising '
             'sending search queries to Google Search and determining whether '
             'a fact is supported by the search results. Furthermore, we '
             'propose extending F1 score as an aggregated metric for long-form '
             'factuality. To do so, we balance the percentage of supported '
             'facts in a response (precision) with the percentage of provided '
             "facts relative to a hyperparameter representing a user's "
             'preferred response length (recall).',
 'title': 'Long-form factuality in large language models',
 'url': 'https://deepmind.google/research/publications/85420/'}
2025-01-13 22:34:03,920 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/85420/>
{'abstract': 'Large language models (LLMs) often generate content that '
             'contains factual errors when responding to fact-seeking prompts '
             "on open-ended topics. To benchmark a model's long-form "
             'factuality in open domains, we first use GPT-4 to generate '
             'LongFact, a prompt set comprising thousands of questions '
             'spanning 38 topics. We then propose that LLM agents can be used '
             'as automated evaluators for long-form factuality through a '
             'method which we call Search-Augmented Factuality Evaluator '
             '(SAFE). SAFE utilizes an LLM to break down a long-form response '
             'into a set of individual facts and to evaluate the accuracy of '
             'each fact using a multi-step reasoning process comprising '
             'sending search queries to Google Search and determining whether '
             'a fact is supported by the search results. Furthermore, we '
             'propose extending F1 score as an aggregated metric for long-form '
             'factuality. To do so, we balance the percentage of supported '
             'facts in a response (precision) with the percentage of provided '
             "facts relative to a hyperparameter representing a user's "
             'preferred response length (recall).',
 'title': 'Long-form factuality in large language models',
 'url': 'https://deepmind.google/research/publications/85420/'}
2025-01-13 22:34:03,959 - root - INFO - Scraped item: {'abstract': 'Recent work has uncovered promising ways to extract '
             'well-calibrated confidence estimates from language models (LMs), '
             "where the model's confidence score reflects how likely it is to "
             'be correct. However, while LMs may appear well-calibrated over '
             'broad distributions, this often hides significant miscalibration '
             'within narrower slices (e.g., systemic over-confidence in math '
             'can balance out systemic under-confidence in history, yielding '
             'perfect calibration in aggregate). To attain well-calibrated '
             'confidence estimates for any slice of a distribution, we propose '
             'a new framework for few-shot slice-specific recalibration. '
             'Specifically, we train a recalibration model that takes in a few '
             'unlabeled examples from any given slice and predicts a curve '
             'that remaps confidence scores to be more accurate for that '
             'slice. Our trained model can recalibrate for arbitrary new '
             'slices, without using any labeled data from that slice. This '
             'enables us to identify domain-specific confidence thresholds '
             "above which the LM's predictions can be trusted, and below which "
             'it should abstain. Experiments show that our few-shot '
             'recalibrator consistently outperforms existing calibration '
             'methods, for instance improving calibration error for '
             'PaLM2-Large on MMLU by 16%, as compared to temperature scaling.',
 'title': 'Few-Shot Recalibration of Language Models',
 'url': 'https://deepmind.google/research/publications/47848/'}
2025-01-13 22:34:03,975 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/47848/>
{'abstract': 'Recent work has uncovered promising ways to extract '
             'well-calibrated confidence estimates from language models (LMs), '
             "where the model's confidence score reflects how likely it is to "
             'be correct. However, while LMs may appear well-calibrated over '
             'broad distributions, this often hides significant miscalibration '
             'within narrower slices (e.g., systemic over-confidence in math '
             'can balance out systemic under-confidence in history, yielding '
             'perfect calibration in aggregate). To attain well-calibrated '
             'confidence estimates for any slice of a distribution, we propose '
             'a new framework for few-shot slice-specific recalibration. '
             'Specifically, we train a recalibration model that takes in a few '
             'unlabeled examples from any given slice and predicts a curve '
             'that remaps confidence scores to be more accurate for that '
             'slice. Our trained model can recalibrate for arbitrary new '
             'slices, without using any labeled data from that slice. This '
             'enables us to identify domain-specific confidence thresholds '
             "above which the LM's predictions can be trusted, and below which "
             'it should abstain. Experiments show that our few-shot '
             'recalibrator consistently outperforms existing calibration '
             'methods, for instance improving calibration error for '
             'PaLM2-Large on MMLU by 16%, as compared to temperature scaling.',
 'title': 'Few-Shot Recalibration of Language Models',
 'url': 'https://deepmind.google/research/publications/47848/'}
2025-01-13 22:34:04,016 - root - INFO - Scraped item: {'abstract': 'Intrinsic motivation is a critical ingredient in reinforcement '
             'learning to enable progress when rewards are sparse. However, '
             'many existing approaches that measure the novelty of '
             'observations are brittle, or rely on restrictive assumptions '
             'about the environment which limit generality.\n'
             'We propose to decompose the exploration problem into two '
             'orthogonal sub-problems:\n'
             '(i) finding the right representation (metric) for exploration\n'
             '(ii) estimating densities in this representation space.',
 'title': 'Robust Exploration via Clustering-based Density Estimation',
 'url': 'https://deepmind.google/research/publications/15530/'}
2025-01-13 22:34:04,029 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/15530/>
{'abstract': 'Intrinsic motivation is a critical ingredient in reinforcement '
             'learning to enable progress when rewards are sparse. However, '
             'many existing approaches that measure the novelty of '
             'observations are brittle, or rely on restrictive assumptions '
             'about the environment which limit generality.\n'
             'We propose to decompose the exploration problem into two '
             'orthogonal sub-problems:\n'
             '(i) finding the right representation (metric) for exploration\n'
             '(ii) estimating densities in this representation space.',
 'title': 'Robust Exploration via Clustering-based Density Estimation',
 'url': 'https://deepmind.google/research/publications/15530/'}
2025-01-13 22:34:04,354 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49667/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:04,417 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/77946/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:04,424 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/77240/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:04,493 - root - INFO - Scraped item: {'abstract': 'While large language models (LLMs) often rely on finetuning to '
             'unlock their capabilities for downstream applications, our '
             'understanding on the inductive biases (especially the scaling '
             'properties) of different finetuning methods is still limited. To '
             'fill this gap, we conduct systematic experiments studying '
             'whether and how different scaling factors, including LLM model '
             'size, pretraining data size, new finetuning parameter size and '
             'finetuning data size, affect the finetuning performance. We '
             'consider two types of finetuning – full-model tuning (FMT) and '
             'parameter efficient tuning (PET, including prompt tuning and '
             'LoRA), and explore their scaling behaviors in the data-limited '
             'regime where the LLM model size substantially outweighs the '
             'finetuning data size. Based on two sets of pretrained bilingual '
             'LLMs from 1B to 16B and experiments on bilingual machine '
             'translation and multilingual summarization benchmarks, we find '
             'that 1) LLM finetuning follows a power-based multiplicative '
             'joint scaling law between finetuning data size and each other '
             'scaling factor; 2) LLM finetuning benefits more from LLM model '
             'scaling than pretraining data scaling, and PET parameter scaling '
             'is generally ineffective; and 3) the optimal finetuning method '
             'is highly task- and finetuning data-dependent.\n'
             'We hope our findings could shed light on understanding, '
             'selecting and developing LLM finetuning methods.',
 'title': 'When Scaling Meets LLM Finetuning: The Effect of Data, Model and '
          'Finetuning Method',
 'url': 'https://deepmind.google/research/publications/49667/'}
2025-01-13 22:34:04,508 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49667/>
{'abstract': 'While large language models (LLMs) often rely on finetuning to '
             'unlock their capabilities for downstream applications, our '
             'understanding on the inductive biases (especially the scaling '
             'properties) of different finetuning methods is still limited. To '
             'fill this gap, we conduct systematic experiments studying '
             'whether and how different scaling factors, including LLM model '
             'size, pretraining data size, new finetuning parameter size and '
             'finetuning data size, affect the finetuning performance. We '
             'consider two types of finetuning – full-model tuning (FMT) and '
             'parameter efficient tuning (PET, including prompt tuning and '
             'LoRA), and explore their scaling behaviors in the data-limited '
             'regime where the LLM model size substantially outweighs the '
             'finetuning data size. Based on two sets of pretrained bilingual '
             'LLMs from 1B to 16B and experiments on bilingual machine '
             'translation and multilingual summarization benchmarks, we find '
             'that 1) LLM finetuning follows a power-based multiplicative '
             'joint scaling law between finetuning data size and each other '
             'scaling factor; 2) LLM finetuning benefits more from LLM model '
             'scaling than pretraining data scaling, and PET parameter scaling '
             'is generally ineffective; and 3) the optimal finetuning method '
             'is highly task- and finetuning data-dependent.\n'
             'We hope our findings could shed light on understanding, '
             'selecting and developing LLM finetuning methods.',
 'title': 'When Scaling Meets LLM Finetuning: The Effect of Data, Model and '
          'Finetuning Method',
 'url': 'https://deepmind.google/research/publications/49667/'}
2025-01-13 22:34:04,553 - root - INFO - Scraped item: {'abstract': 'What are the root causes of hallucinations in large language '
             'models (LLMs)? We use Communication Complexity to prove that the '
             'Transformer layer is incapable of composing functions (e.g., '
             'identify a grandparent of a person in a genealogy) if the '
             'domains of the functions are large enough; we show through '
             'examples that this inability is already empirically present when '
             'the domains are quite small. We also point out that several '
             'mathematical tasks that are at the core of the so-called '
             'compositional tasks thought to be hard for LLMs are unlikely to '
             'be solvable by Transformers, for large enough instances and '
             'assuming that certain well accepted conjectures in the field of '
             'Computational Complexity are true.',
 'title': 'On Limitations of the Transformer Architecture',
 'url': 'https://deepmind.google/research/publications/77946/'}
2025-01-13 22:34:04,567 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/77946/>
{'abstract': 'What are the root causes of hallucinations in large language '
             'models (LLMs)? We use Communication Complexity to prove that the '
             'Transformer layer is incapable of composing functions (e.g., '
             'identify a grandparent of a person in a genealogy) if the '
             'domains of the functions are large enough; we show through '
             'examples that this inability is already empirically present when '
             'the domains are quite small. We also point out that several '
             'mathematical tasks that are at the core of the so-called '
             'compositional tasks thought to be hard for LLMs are unlikely to '
             'be solvable by Transformers, for large enough instances and '
             'assuming that certain well accepted conjectures in the field of '
             'Computational Complexity are true.',
 'title': 'On Limitations of the Transformer Architecture',
 'url': 'https://deepmind.google/research/publications/77946/'}
2025-01-13 22:34:04,572 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49969/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:04,611 - root - INFO - Scraped item: {'abstract': 'We address the problem of T-count optimization, i.e., minimizing '
             'the number of the most expensive gates in fault-tolerant quantum '
             'computation (namely, the T gates) that are needed to implement a '
             'given circuit. For that, we develop AlphaTensor-Quantum, a '
             'method based on deep reinforcement learning that exploits the '
             'relationship between optimizing T-count and tensor '
             'decomposition. Unlike existing methods for T-count optimization, '
             'AlphaTensor-Quantum can incorporate domain-specific knowledge '
             'about quantum computation and leverage gadgets, which '
             'significantly reduces the T-count of the optimized circuits. '
             'AlphaTensor-Quantum outperforms all existing methods for T-count '
             'optimization on a set of arithmetic benchmarks. Remarkably, it '
             'rediscovers an efficient multiplication algorithm akin to '
             "Karatsuba's method for multiplication in finite fields, and it "
             'finds the best human-designed solutions for relevant arithmetic '
             "computations used in Shor's algorithm and for quantum chemistry "
             'simulation. Thus, AlphaTensor-Quantum can save hundreds of hours '
             'of research by optimizing relevant quantum circuits in a fully '
             'automated way.',
 'title': 'AlphaTensor for Optimizing Quantum Computations',
 'url': 'https://deepmind.google/research/publications/77240/'}
2025-01-13 22:34:04,622 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/77240/>
{'abstract': 'We address the problem of T-count optimization, i.e., minimizing '
             'the number of the most expensive gates in fault-tolerant quantum '
             'computation (namely, the T gates) that are needed to implement a '
             'given circuit. For that, we develop AlphaTensor-Quantum, a '
             'method based on deep reinforcement learning that exploits the '
             'relationship between optimizing T-count and tensor '
             'decomposition. Unlike existing methods for T-count optimization, '
             'AlphaTensor-Quantum can incorporate domain-specific knowledge '
             'about quantum computation and leverage gadgets, which '
             'significantly reduces the T-count of the optimized circuits. '
             'AlphaTensor-Quantum outperforms all existing methods for T-count '
             'optimization on a set of arithmetic benchmarks. Remarkably, it '
             'rediscovers an efficient multiplication algorithm akin to '
             "Karatsuba's method for multiplication in finite fields, and it "
             'finds the best human-designed solutions for relevant arithmetic '
             "computations used in Shor's algorithm and for quantum chemistry "
             'simulation. Thus, AlphaTensor-Quantum can save hundreds of hours '
             'of research by optimizing relevant quantum circuits in a fully '
             'automated way.',
 'title': 'AlphaTensor for Optimizing Quantum Computations',
 'url': 'https://deepmind.google/research/publications/77240/'}
2025-01-13 22:34:04,641 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/59160/> (referer: https://deepmind.google/research/publications/?page=3)
2025-01-13 22:34:04,709 - root - INFO - Scraped item: {'abstract': 'We propose a new class of linear Transformers called '
             'FourierLearner-Transformers (FLTs), which incorporate a wide '
             'range of relative positional encoding mechanisms (RPEs). These '
             'include regular RPE techniques applied for nongeometric data, as '
             'well as novel RPEs operating on the sequences of tokens embedded '
             'in higher-dimensional Euclidean spaces (e.g. point clouds). FLTs '
             'construct the optimal RPE mechanism implicitly by learning its '
             'spectral representation. As opposed to other architectures '
             'combining efficient low-rank linear attention with RPEs, FLTs '
             'remain practical in terms of their memory usage and do not '
             'require additional assumptions about the structure of the '
             'RPE-mask. FLTs allow also for applying certain structural '
             'inductive bias techniques to specify masking strategies, e.g. '
             'they provide a way to learn the so-called local RPEs introduced '
             'in this paper and providing accuracy gains as compared with '
             'several other linear Transformers for language modeling. We also '
             'thoroughly tested FLTs on other data modalities and tasks, such '
             'as: image classification and 3D molecular modeling. For 3D-data '
             'FLTs are, to the best of our knowledge, the first Transformers '
             'architectures providing RPE-enhanced linear attention.',
 'title': 'Learning a Fourier Transform for Linear Relative Positional '
          'Encodings in Transformers',
 'url': 'https://deepmind.google/research/publications/49969/'}
2025-01-13 22:34:04,723 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49969/>
{'abstract': 'We propose a new class of linear Transformers called '
             'FourierLearner-Transformers (FLTs), which incorporate a wide '
             'range of relative positional encoding mechanisms (RPEs). These '
             'include regular RPE techniques applied for nongeometric data, as '
             'well as novel RPEs operating on the sequences of tokens embedded '
             'in higher-dimensional Euclidean spaces (e.g. point clouds). FLTs '
             'construct the optimal RPE mechanism implicitly by learning its '
             'spectral representation. As opposed to other architectures '
             'combining efficient low-rank linear attention with RPEs, FLTs '
             'remain practical in terms of their memory usage and do not '
             'require additional assumptions about the structure of the '
             'RPE-mask. FLTs allow also for applying certain structural '
             'inductive bias techniques to specify masking strategies, e.g. '
             'they provide a way to learn the so-called local RPEs introduced '
             'in this paper and providing accuracy gains as compared with '
             'several other linear Transformers for language modeling. We also '
             'thoroughly tested FLTs on other data modalities and tasks, such '
             'as: image classification and 3D molecular modeling. For 3D-data '
             'FLTs are, to the best of our knowledge, the first Transformers '
             'architectures providing RPE-enhanced linear attention.',
 'title': 'Learning a Fourier Transform for Linear Relative Positional '
          'Encodings in Transformers',
 'url': 'https://deepmind.google/research/publications/49969/'}
2025-01-13 22:34:04,787 - root - INFO - Scraped item: {'abstract': 'We introduce a framework for online learning from a single '
             'continuous video stream -- the way people and animals learn, '
             'without mini-batches, data augmentation or shuffling. This poses '
             'great challenges given the high correlation between consecutive '
             'video frames and there is very little prior work on it. Our '
             'framework allows us to do a first deep dive into the topic and '
             'includes a collection of streams and tasks composed from two '
             'existing video datasets, plus methodology for performance '
             'evaluation that considers both adaptation and generalization. We '
             'employ pixel-to-pixel modelling as a practical and flexible way '
             'to switch between pre-training and single-stream evaluation as '
             'well as between arbitrary tasks, without ever requiring changes '
             'to models and always using the same pixel loss. Equipped with '
             'this framework we obtained large single-stream learning gains '
             'from pre-training with a novel family of future prediction '
             'tasks, found that momentum hurts, and that the pace of weight '
             'updates matters. The combination of these insights leads to '
             'matching the performance of IID learning with batch size 1, when '
             'using the same architecture and without costly replay buffers. '
             'An overview of the paper is available online '
             'athttps://sites.google.com/view/one-stream-video.',
 'title': 'Learning from One Continuous Video Stream',
 'url': 'https://deepmind.google/research/publications/59160/'}
2025-01-13 22:34:04,800 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/59160/>
{'abstract': 'We introduce a framework for online learning from a single '
             'continuous video stream -- the way people and animals learn, '
             'without mini-batches, data augmentation or shuffling. This poses '
             'great challenges given the high correlation between consecutive '
             'video frames and there is very little prior work on it. Our '
             'framework allows us to do a first deep dive into the topic and '
             'includes a collection of streams and tasks composed from two '
             'existing video datasets, plus methodology for performance '
             'evaluation that considers both adaptation and generalization. We '
             'employ pixel-to-pixel modelling as a practical and flexible way '
             'to switch between pre-training and single-stream evaluation as '
             'well as between arbitrary tasks, without ever requiring changes '
             'to models and always using the same pixel loss. Equipped with '
             'this framework we obtained large single-stream learning gains '
             'from pre-training with a novel family of future prediction '
             'tasks, found that momentum hurts, and that the pace of weight '
             'updates matters. The combination of these insights leads to '
             'matching the performance of IID learning with batch size 1, when '
             'using the same architecture and without costly replay buffers. '
             'An overview of the paper is available online '
             'athttps://sites.google.com/view/one-stream-video.',
 'title': 'Learning from One Continuous Video Stream',
 'url': 'https://deepmind.google/research/publications/59160/'}
2025-01-13 22:34:04,821 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/60474/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:04,975 - root - INFO - Scraped item: {'abstract': 'We introduce Genie, the first generative interactive environment '
             'trained in an unsupervised manner from unlabelled Internet '
             'videos. The model can be prompted to generate an endless variety '
             'of action-controllable virtual worlds described through text, '
             'synthetic images, photographs, and even sketches. At 11B '
             'parameters, Genie can be considered a foundation world model. It '
             'is comprised of a spatiotemporal video tokenizer, an '
             'autoregressive dynamics model, and a simple and scalable latent '
             'action model. Genie enables users to act in the generated '
             'environments on a frame-by-frame basis despite training without '
             'any ground-truth action labels or other domain-specific '
             'requirements typically found in the world model literature. '
             'Further the resulting learned latent action space facilitates '
             'training agents to imitate behaviors from unseen videos, opening '
             'the path for training generalist agents of the future.',
 'title': 'Genie: Generative Interactive Environments',
 'url': 'https://deepmind.google/research/publications/60474/'}
2025-01-13 22:34:04,992 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/60474/>
{'abstract': 'We introduce Genie, the first generative interactive environment '
             'trained in an unsupervised manner from unlabelled Internet '
             'videos. The model can be prompted to generate an endless variety '
             'of action-controllable virtual worlds described through text, '
             'synthetic images, photographs, and even sketches. At 11B '
             'parameters, Genie can be considered a foundation world model. It '
             'is comprised of a spatiotemporal video tokenizer, an '
             'autoregressive dynamics model, and a simple and scalable latent '
             'action model. Genie enables users to act in the generated '
             'environments on a frame-by-frame basis despite training without '
             'any ground-truth action labels or other domain-specific '
             'requirements typically found in the world model literature. '
             'Further the resulting learned latent action space facilitates '
             'training agents to imitate behaviors from unseen videos, opening '
             'the path for training generalist agents of the future.',
 'title': 'Genie: Generative Interactive Environments',
 'url': 'https://deepmind.google/research/publications/60474/'}
2025-01-13 22:34:05,285 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/45424/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,315 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/64513/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,325 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/78451/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,328 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/46131/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,338 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/63200/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,461 - root - INFO - Scraped item: {'abstract': 'What is the best paradigm to recognize objects---discriminative '
             'inference (fast but potentially prone to shortcut learning) or '
             'using a generative model (slow but potentially more robust)? We '
             'build on recent advances in generative modeling that turn '
             'text-to-image models into classifiers. This allows us to study '
             'their behavior and to compare them against discriminative models '
             'and human psychophysical data.\n'
             'We report four intriguing emergent properties of diffusion-based '
             'generative classifiers: they show a record-breaking human-like '
             'shape bias (99% for Imagen), near human-level '
             'out-of-distribution accuracy, state-of-the-art alignment with '
             'human classification errors, and they understand certain '
             'perceptual illusions. Our results indicate that while the '
             'current dominant paradigm for modeling human object recognition '
             'is discriminative inference, zero-shot generative models '
             'approximate human object recognition data surprisingly well.',
 'title': 'Intriguing Properties of Generative Classifers',
 'url': 'https://deepmind.google/research/publications/45424/'}
2025-01-13 22:34:05,482 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/45424/>
{'abstract': 'What is the best paradigm to recognize objects---discriminative '
             'inference (fast but potentially prone to shortcut learning) or '
             'using a generative model (slow but potentially more robust)? We '
             'build on recent advances in generative modeling that turn '
             'text-to-image models into classifiers. This allows us to study '
             'their behavior and to compare them against discriminative models '
             'and human psychophysical data.\n'
             'We report four intriguing emergent properties of diffusion-based '
             'generative classifiers: they show a record-breaking human-like '
             'shape bias (99% for Imagen), near human-level '
             'out-of-distribution accuracy, state-of-the-art alignment with '
             'human classification errors, and they understand certain '
             'perceptual illusions. Our results indicate that while the '
             'current dominant paradigm for modeling human object recognition '
             'is discriminative inference, zero-shot generative models '
             'approximate human object recognition data surprisingly well.',
 'title': 'Intriguing Properties of Generative Classifers',
 'url': 'https://deepmind.google/research/publications/45424/'}
2025-01-13 22:34:05,521 - root - INFO - Scraped item: {'abstract': 'Learning from human feedback (LHF)—and in particular learning '
             'from pairwise preferences—has recently become a crucial '
             'ingredient in training large language models (LLMs), and has '
             'been the subject of much research. Most recent works frame it as '
             'a reinforcement learning problem, where a reward function is '
             'learned from pairwise preference data and the LLM is treated as '
             'a policy which is adapted to maximize the rewards, often under '
             'additional regularization constraints. We propose an alternative '
             'interpretation which centers on the generative process for '
             'pairwise preferences and treats LHF as a density estimation '
             'problem. We provide theoretical and empirical results showing '
             'that for a family of generative processes defined via preference '
             'behavior distribution equations, training a reward function on '
             "pairwise preferences effectively models an annotator's implicit "
             'preference distribution. Finally, we discuss and present '
             'findings on "annotator misspecification"—failure cases where '
             'wrong modeling assumptions are made about annotator behavior, '
             'resulting in poorly-adapted models—suggesting that approaches '
             'that learn from pairwise human preferences could have trouble '
             'learning from a population of annotators with diverse '
             'viewpoints.',
 'title': 'A density estimation perspective on learning from pairwise human '
          'preferences',
 'url': 'https://deepmind.google/research/publications/64513/'}
2025-01-13 22:34:05,535 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/64513/>
{'abstract': 'Learning from human feedback (LHF)—and in particular learning '
             'from pairwise preferences—has recently become a crucial '
             'ingredient in training large language models (LLMs), and has '
             'been the subject of much research. Most recent works frame it as '
             'a reinforcement learning problem, where a reward function is '
             'learned from pairwise preference data and the LLM is treated as '
             'a policy which is adapted to maximize the rewards, often under '
             'additional regularization constraints. We propose an alternative '
             'interpretation which centers on the generative process for '
             'pairwise preferences and treats LHF as a density estimation '
             'problem. We provide theoretical and empirical results showing '
             'that for a family of generative processes defined via preference '
             'behavior distribution equations, training a reward function on '
             "pairwise preferences effectively models an annotator's implicit "
             'preference distribution. Finally, we discuss and present '
             'findings on "annotator misspecification"—failure cases where '
             'wrong modeling assumptions are made about annotator behavior, '
             'resulting in poorly-adapted models—suggesting that approaches '
             'that learn from pairwise human preferences could have trouble '
             'learning from a population of annotators with diverse '
             'viewpoints.',
 'title': 'A density estimation perspective on learning from pairwise human '
          'preferences',
 'url': 'https://deepmind.google/research/publications/64513/'}
2025-01-13 22:34:05,572 - root - INFO - Scraped item: {'abstract': 'Over the broad landscape of experimental design, regression has '
             'been a powerful tool to accurately predict the outcome metrics '
             'of a system or model given a set of parameters, but has been '
             'traditionally restricted to methods which are only applicable to '
             'a specific task. In this paper, we propose OmniPred, a framework '
             'for training language models as universal end-to-end regressors '
             'over (x,y) evaluation data from diverse real world experiments. '
             'Using data sourced from Google Vizier, one of the largest '
             'blackbox optimization databases in the world, our extensive '
             'experiments demonstrate that through only textual '
             'representations of mathematical parameters and values, language '
             'models are capable of very precise numerical regression, and if '
             'given the opportunity to train over multiple tasks, can '
             'significantly outperform traditional regression models.',
 'title': 'OmniPred: Language Models as Universal Regressors',
 'url': 'https://deepmind.google/research/publications/78451/'}
2025-01-13 22:34:05,584 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/78451/>
{'abstract': 'Over the broad landscape of experimental design, regression has '
             'been a powerful tool to accurately predict the outcome metrics '
             'of a system or model given a set of parameters, but has been '
             'traditionally restricted to methods which are only applicable to '
             'a specific task. In this paper, we propose OmniPred, a framework '
             'for training language models as universal end-to-end regressors '
             'over (x,y) evaluation data from diverse real world experiments. '
             'Using data sourced from Google Vizier, one of the largest '
             'blackbox optimization databases in the world, our extensive '
             'experiments demonstrate that through only textual '
             'representations of mathematical parameters and values, language '
             'models are capable of very precise numerical regression, and if '
             'given the opportunity to train over multiple tasks, can '
             'significantly outperform traditional regression models.',
 'title': 'OmniPred: Language Models as Universal Regressors',
 'url': 'https://deepmind.google/research/publications/78451/'}
2025-01-13 22:34:05,620 - root - INFO - Scraped item: {'abstract': 'Model overconfidence and poor calibration are common in machine '
             'learning and difficult to account for when applying standard '
             'empirical risk minimization. In this work, we propose a novel '
             'method to alleviate these problems that we call odd-$k$-out '
             'learning (OKO), which minimizes the cross-entropy error for sets '
             'rather than for single examples. This naturally allows the model '
             'to capture correlations across data examples and achieves both '
             'better accuracy and calibration, especially in limited training '
             'data and class-imbalanced regimes. Perhaps surprisingly, OKO '
             'often yields better calibration even when training with hard '
             'labels and dropping any additional calibration parameter tuning, '
             'such as temperature scaling. We provide theoretical '
             'justification, establishing that OKO naturally yields better '
             'calibration, and provide extensive experimental analyses that '
             'corroborate our theoretical findings. We emphasize that OKO is a '
             'general framework that can be easily adapted to many settings '
             'and the trained model can be applied to single examples at '
             'inference time, without introducing significant run-time '
             'overhead or architecture changes.',
 'title': 'Set Learning for Accurate and Calibrated Models',
 'url': 'https://deepmind.google/research/publications/46131/'}
2025-01-13 22:34:05,633 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/46131/>
{'abstract': 'Model overconfidence and poor calibration are common in machine '
             'learning and difficult to account for when applying standard '
             'empirical risk minimization. In this work, we propose a novel '
             'method to alleviate these problems that we call odd-$k$-out '
             'learning (OKO), which minimizes the cross-entropy error for sets '
             'rather than for single examples. This naturally allows the model '
             'to capture correlations across data examples and achieves both '
             'better accuracy and calibration, especially in limited training '
             'data and class-imbalanced regimes. Perhaps surprisingly, OKO '
             'often yields better calibration even when training with hard '
             'labels and dropping any additional calibration parameter tuning, '
             'such as temperature scaling. We provide theoretical '
             'justification, establishing that OKO naturally yields better '
             'calibration, and provide extensive experimental analyses that '
             'corroborate our theoretical findings. We emphasize that OKO is a '
             'general framework that can be easily adapted to many settings '
             'and the trained model can be applied to single examples at '
             'inference time, without introducing significant run-time '
             'overhead or architecture changes.',
 'title': 'Set Learning for Accurate and Calibrated Models',
 'url': 'https://deepmind.google/research/publications/46131/'}
2025-01-13 22:34:05,674 - root - INFO - Scraped item: {'abstract': 'Vision foundation models are currently one of the main driving '
             'forces in computer vision research. However, transferring these '
             'models to new tasks involves expensive (full) finetuning. One '
             'efficient method is to cache features by processing a dataset '
             'through a pretrained model and subsequently train a small '
             'network on the cached features. How to effectively incorporate '
             'data augmentation on top of such cached features is an open '
             'question. In this paper, we extensively study frozen feature '
             'augmentation (FroFA) in the few-shot setting. We focus on the '
             'low-data regime as we assume to observe significant effects. Our '
             'study includes eighteen data augmentations, four network '
             'architectures, two large pretraining datasets and three transfer '
             'datasets. Our results indicate that some commonly used image '
             'data augmentations also transfer to the feature space.',
 'title': 'Frozen Feature Augmentation',
 'url': 'https://deepmind.google/research/publications/63200/'}
2025-01-13 22:34:05,686 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/63200/>
{'abstract': 'Vision foundation models are currently one of the main driving '
             'forces in computer vision research. However, transferring these '
             'models to new tasks involves expensive (full) finetuning. One '
             'efficient method is to cache features by processing a dataset '
             'through a pretrained model and subsequently train a small '
             'network on the cached features. How to effectively incorporate '
             'data augmentation on top of such cached features is an open '
             'question. In this paper, we extensively study frozen feature '
             'augmentation (FroFA) in the few-shot setting. We focus on the '
             'low-data regime as we assume to observe significant effects. Our '
             'study includes eighteen data augmentations, four network '
             'architectures, two large pretraining datasets and three transfer '
             'datasets. Our results indicate that some commonly used image '
             'data augmentations also transfer to the feature space.',
 'title': 'Frozen Feature Augmentation',
 'url': 'https://deepmind.google/research/publications/63200/'}
2025-01-13 22:34:05,693 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=5> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,759 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/72495/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,778 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/47444/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:05,808 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=5
2025-01-13 22:34:05,907 - root - INFO - Scraped item: {'abstract': 'Vision language models (VLMs) have shown impressive capabilities '
             'across a variety of tasks, from logical reasoning to visual '
             'understanding. This opens the door to richer interaction with '
             'the world, for example robotic control. However, VLMs produce '
             'only textual outputs, while robotic control and other spatial '
             'tasks require outputting continuous coordinates, actions, or '
             'trajectories. How can we enable VLMs to handle such settings '
             'without fine-tuning on task-specific data?',
 'title': 'PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for '
          'VLMs',
 'url': 'https://deepmind.google/research/publications/72495/'}
2025-01-13 22:34:05,920 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/72495/>
{'abstract': 'Vision language models (VLMs) have shown impressive capabilities '
             'across a variety of tasks, from logical reasoning to visual '
             'understanding. This opens the door to richer interaction with '
             'the world, for example robotic control. However, VLMs produce '
             'only textual outputs, while robotic control and other spatial '
             'tasks require outputting continuous coordinates, actions, or '
             'trajectories. How can we enable VLMs to handle such settings '
             'without fine-tuning on task-specific data?',
 'title': 'PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for '
          'VLMs',
 'url': 'https://deepmind.google/research/publications/72495/'}
2025-01-13 22:34:05,960 - root - INFO - Scraped item: {'abstract': 'Table-based reasoning with large language models is a promising '
             'direction to solve many table understanding tasks, such as '
             'table-based question answering and table-based fact '
             'verification. Chain-of-Thought and its alike approaches have '
             'demonstrated impressive performance by incorporating the '
             'reasoning chain in the form of textual context. However, it is '
             'still an open question how to properly involve tabular data in '
             'the reasoning chain for the table-based tasks. Inspired by '
             'nested queries in SQL development where temporary tables are '
             'used to store intermediate results, we propose Chain-of-Table, '
             'where we update the table iteratively to represent the complex '
             'reasoning chain. In our approach, the tabular context evolves as '
             'a sequence of operations generated by a large language model, '
             'where the generation of the latter operation is conditioned on '
             'the results of the previous operation. In this way, the '
             'constantly evolving table forms a chain, showing the reasoning '
             'process of the given problem. The result table carries rich '
             'information of the intermediate results so that large language '
             'models can skip the complex reasoning over the latent clues, '
             'directly aggregate relevant information from the result table, '
             'and come to the final prediction easily. Extensive experiments '
             'with two large language models show that Chain-of-Table '
             'surpasses competitive baselines and achieves the '
             'state-of-the-art performance in three well-known benchmark '
             'datasets (WikiTableQuestions, and FeTaQA, and TabFact).',
 'title': 'Chain-of-Table: Evolves Tables in the LLM Reasoning Chain for Table '
          'Understanding',
 'url': 'https://deepmind.google/research/publications/47444/'}
2025-01-13 22:34:05,972 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/47444/>
{'abstract': 'Table-based reasoning with large language models is a promising '
             'direction to solve many table understanding tasks, such as '
             'table-based question answering and table-based fact '
             'verification. Chain-of-Thought and its alike approaches have '
             'demonstrated impressive performance by incorporating the '
             'reasoning chain in the form of textual context. However, it is '
             'still an open question how to properly involve tabular data in '
             'the reasoning chain for the table-based tasks. Inspired by '
             'nested queries in SQL development where temporary tables are '
             'used to store intermediate results, we propose Chain-of-Table, '
             'where we update the table iteratively to represent the complex '
             'reasoning chain. In our approach, the tabular context evolves as '
             'a sequence of operations generated by a large language model, '
             'where the generation of the latter operation is conditioned on '
             'the results of the previous operation. In this way, the '
             'constantly evolving table forms a chain, showing the reasoning '
             'process of the given problem. The result table carries rich '
             'information of the intermediate results so that large language '
             'models can skip the complex reasoning over the latent clues, '
             'directly aggregate relevant information from the result table, '
             'and come to the final prediction easily. Extensive experiments '
             'with two large language models show that Chain-of-Table '
             'surpasses competitive baselines and achieves the '
             'state-of-the-art performance in three well-known benchmark '
             'datasets (WikiTableQuestions, and FeTaQA, and TabFact).',
 'title': 'Chain-of-Table: Evolves Tables in the LLM Reasoning Chain for Table '
          'Understanding',
 'url': 'https://deepmind.google/research/publications/47444/'}
2025-01-13 22:34:06,100 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/73709/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,216 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/44717/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,252 - root - INFO - Scraped item: {'abstract': 'Identifying how much a model ${\\widehat{p}}_{\\theta}(Y|X)$ '
             'knows about the\n'
             'stochastic real-world process $p(Y|X)$ it was trained on is '
             'important to ensure\n'
             'it avoids producing incorrect or "hallucinated" answers or '
             'taking unsafe\n'
             'actions. But this is difficult for generative models because '
             'probabilistic\n'
             'predictions do not distinguish between per-response noise '
             '(aleatoric\n'
             'uncertainty) and lack of knowledge about the process (epistemic '
             'uncertainty),\n'
             'and existing epistemic uncertainty quantification techniques '
             'tend to be\n'
             'overconfident when the model underfits. We propose a general '
             'strategy for\n'
             'teaching a model to both approximate $p(Y|X)$ and also estimate '
             'the remaining\n'
             'gaps between ${\\widehat{p}}_{\\theta}(Y|X)$ and $p(Y|X)$: train '
             'it to predict\n'
             'pairs of independent responses drawn from the true conditional '
             'distribution,\n'
             'allow it to "cheat" by observing one response while predicting '
             'the other, then\n'
             'measure how much it cheats. Remarkably, we prove that being good '
             'at cheating\n'
             '(i.e. cheating whenever it improves your prediction) is '
             'equivalent to being\n'
             'second-order calibrated, a principled extension of ordinary '
             'calibration that\n'
             'allows us to construct provably-correct frequentist confidence '
             'intervals for\n'
             '$p(Y|X)$ and detect incorrect responses with high probability. '
             'We demonstrate\n'
             'empirically that our approach accurately estimates how much '
             "models don't know\n"
             'across ambiguous image classification, (synthetic) language '
             'modeling, and\n'
             'partially-observable navigation tasks, outperforming existing '
             'techniques.',
 'title': "Experts Don't Cheat: Learning What You Don't Know by Predicting "
          'Pairs',
 'url': 'https://deepmind.google/research/publications/73709/'}
2025-01-13 22:34:06,268 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/73709/>
{'abstract': 'Identifying how much a model ${\\widehat{p}}_{\\theta}(Y|X)$ '
             'knows about the\n'
             'stochastic real-world process $p(Y|X)$ it was trained on is '
             'important to ensure\n'
             'it avoids producing incorrect or "hallucinated" answers or '
             'taking unsafe\n'
             'actions. But this is difficult for generative models because '
             'probabilistic\n'
             'predictions do not distinguish between per-response noise '
             '(aleatoric\n'
             'uncertainty) and lack of knowledge about the process (epistemic '
             'uncertainty),\n'
             'and existing epistemic uncertainty quantification techniques '
             'tend to be\n'
             'overconfident when the model underfits. We propose a general '
             'strategy for\n'
             'teaching a model to both approximate $p(Y|X)$ and also estimate '
             'the remaining\n'
             'gaps between ${\\widehat{p}}_{\\theta}(Y|X)$ and $p(Y|X)$: train '
             'it to predict\n'
             'pairs of independent responses drawn from the true conditional '
             'distribution,\n'
             'allow it to "cheat" by observing one response while predicting '
             'the other, then\n'
             'measure how much it cheats. Remarkably, we prove that being good '
             'at cheating\n'
             '(i.e. cheating whenever it improves your prediction) is '
             'equivalent to being\n'
             'second-order calibrated, a principled extension of ordinary '
             'calibration that\n'
             'allows us to construct provably-correct frequentist confidence '
             'intervals for\n'
             '$p(Y|X)$ and detect incorrect responses with high probability. '
             'We demonstrate\n'
             'empirically that our approach accurately estimates how much '
             "models don't know\n"
             'across ambiguous image classification, (synthetic) language '
             'modeling, and\n'
             'partially-observable navigation tasks, outperforming existing '
             'techniques.',
 'title': "Experts Don't Cheat: Learning What You Don't Know by Predicting "
          'Pairs',
 'url': 'https://deepmind.google/research/publications/73709/'}
2025-01-13 22:34:06,276 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/74917/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,280 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/70372/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,354 - root - INFO - Scraped item: {'abstract': 'This paper contributes a new approach for distributional '
             'reinforcement learning which elucidates a clean separation of '
             'transition structure and reward in the learning process. '
             'Analogous to how the successor representation (SR) describes the '
             'expected consequences of behaving according to a given policy, '
             'our distributional successor measure (SM) describes the '
             'distributional consequences of this behaviour. We formulate the '
             'distributional SM as a distribution over distributions and '
             'provide theory connecting it with distributional and model-based '
             'reinforcement learning. Moreover, we propose an algorithm that '
             'learns the distributional SM from data by minimizing a two-level '
             'maximum mean discrepancy. Key to our method are a number of '
             'algorithmic techniques that are independently valuable for '
             'learning generative models of state. As an illustration of the '
             'usefulness of the distributional SM, we show that it enables '
             'zero-shot risk-sensitive policy evaluation in a way that was not '
             'previously possible.',
 'title': 'A Distributional Analogue to the Successor Representation',
 'url': 'https://deepmind.google/research/publications/44717/'}
2025-01-13 22:34:06,366 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/44717/>
{'abstract': 'This paper contributes a new approach for distributional '
             'reinforcement learning which elucidates a clean separation of '
             'transition structure and reward in the learning process. '
             'Analogous to how the successor representation (SR) describes the '
             'expected consequences of behaving according to a given policy, '
             'our distributional successor measure (SM) describes the '
             'distributional consequences of this behaviour. We formulate the '
             'distributional SM as a distribution over distributions and '
             'provide theory connecting it with distributional and model-based '
             'reinforcement learning. Moreover, we propose an algorithm that '
             'learns the distributional SM from data by minimizing a two-level '
             'maximum mean discrepancy. Key to our method are a number of '
             'algorithmic techniques that are independently valuable for '
             'learning generative models of state. As an illustration of the '
             'usefulness of the distributional SM, we show that it enables '
             'zero-shot risk-sensitive policy evaluation in a way that was not '
             'previously possible.',
 'title': 'A Distributional Analogue to the Successor Representation',
 'url': 'https://deepmind.google/research/publications/44717/'}
2025-01-13 22:34:06,418 - root - INFO - Scraped item: {'abstract': 'Current Large Language Models (LLMs) are not only limited to '
             'some maximum context length, but also are not able to robustly '
             'consume long inputs. To address these limitations, we propose '
             'ReadAgent, an LLM agent system that increases effective context '
             'length up to 20x in our experiments. Inspired by how humans '
             'interactively read long documents, we implement ReadAgent as a '
             'simple prompting system that uses the advanced language '
             'capabilities of LLMs to (1) decide what content to store '
             'together in a memory episode, (2) compress those memory episodes '
             'into short episodic memories calledgist memories, and (3) take '
             'actions to look up passages in the original text if ReadAgent '
             'needs to remind itself of relevant details to complete a task. '
             'We evaluate ReadAgent against baselines using retrieval methods, '
             'using the original long contexts, and using the gist memories. '
             'These evaluations are performed on three long-document reading '
             'comprehension tasks: QuALITY, NarrativeQA, and QMSum. ReadAgent '
             'outperforms the baselines on all three tasks while extending the '
             'effective context window by 3-20x.',
 'title': 'A Human-Inspired Reading Agent with Gist Memory of Very Long '
          'Contexts',
 'url': 'https://deepmind.google/research/publications/74917/'}
2025-01-13 22:34:06,432 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/74917/>
{'abstract': 'Current Large Language Models (LLMs) are not only limited to '
             'some maximum context length, but also are not able to robustly '
             'consume long inputs. To address these limitations, we propose '
             'ReadAgent, an LLM agent system that increases effective context '
             'length up to 20x in our experiments. Inspired by how humans '
             'interactively read long documents, we implement ReadAgent as a '
             'simple prompting system that uses the advanced language '
             'capabilities of LLMs to (1) decide what content to store '
             'together in a memory episode, (2) compress those memory episodes '
             'into short episodic memories calledgist memories, and (3) take '
             'actions to look up passages in the original text if ReadAgent '
             'needs to remind itself of relevant details to complete a task. '
             'We evaluate ReadAgent against baselines using retrieval methods, '
             'using the original long contexts, and using the gist memories. '
             'These evaluations are performed on three long-document reading '
             'comprehension tasks: QuALITY, NarrativeQA, and QMSum. ReadAgent '
             'outperforms the baselines on all three tasks while extending the '
             'effective context window by 3-20x.',
 'title': 'A Human-Inspired Reading Agent with Gist Memory of Very Long '
          'Contexts',
 'url': 'https://deepmind.google/research/publications/74917/'}
2025-01-13 22:34:06,469 - root - INFO - Scraped item: {'abstract': 'We propose a new algorithm for model-based distributional '
             'reinforcement learning (RL), and prove that it is '
             'minimax-optimal for approximating return distributions with a '
             'generative model (up to logarithmic factors), resolving an open '
             'question of Zhang et al. (2023). Our analysis provides new '
             'theoretical results on categorical approaches to distributional '
             'RL, and also introduces a new distributional Bellman equation, '
             'the stochastic categorical CDF Bellman equation, which we expect '
             'to be of independent interest. We also provide an experimental '
             'study comparing several model-based distributional RL '
             'algorithms, with several takeaways for practitioners.',
 'title': 'Near-Minimax-Optimal Distributional RL with a Generative Model',
 'url': 'https://deepmind.google/research/publications/70372/'}
2025-01-13 22:34:06,482 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/70372/>
{'abstract': 'We propose a new algorithm for model-based distributional '
             'reinforcement learning (RL), and prove that it is '
             'minimax-optimal for approximating return distributions with a '
             'generative model (up to logarithmic factors), resolving an open '
             'question of Zhang et al. (2023). Our analysis provides new '
             'theoretical results on categorical approaches to distributional '
             'RL, and also introduces a new distributional Bellman equation, '
             'the stochastic categorical CDF Bellman equation, which we expect '
             'to be of independent interest. We also provide an experimental '
             'study comparing several model-based distributional RL '
             'algorithms, with several takeaways for practitioners.',
 'title': 'Near-Minimax-Optimal Distributional RL with a Generative Model',
 'url': 'https://deepmind.google/research/publications/70372/'}
2025-01-13 22:34:06,709 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/74007/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,763 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/75421/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,842 - root - INFO - Scraped item: {'abstract': 'Large language models (LLMs) have been shown to exhibit a wide '
             'range of capabilities, such as writing robot code from language '
             'commands -- enabling non-experts to direct robot behaviors, '
             'modify them based on feedback, or compose them to perform new '
             'tasks. However, these capabilities (driven by in-context '
             "learning) are limited to short-term interactions, where users' "
             'feedback remains relevant for only as long as it fits within the '
             'context size of the LLM, and can be forgotten over longer '
             'interactions. In this work, we investigate fine-tuning the robot '
             'code-writing LLMs, to remember their in-context interactions and '
             'improve their teachability i.e., how efficiently they adapt to '
             'human inputs (measured by average number of corrections before '
             'the user considers the task successful). Our key observation is '
             'that when human-robot interactions are formulated as a partially '
             'observable Markov decision process (in which human language '
             'inputs are observations, and robot code outputs are actions), '
             'then training an LLM to complete previous interactions can be '
             'viewed as training a transition dynamics model -- that can be '
             'combined with classic robotics techniques such as model '
             'predictive control (MPC) to discover shorter paths to success. '
             'This gives rise to Language Model Predictive Control (LMPC), a '
             'framework that fine-tunes PaLM 2 to improve its teachability on '
             '78 tasks across 5 robot embodiments -- improving non-expert '
             'teaching success rates of unseen tasks by 26.9% while reducing '
             'the average number of human corrections from 2.4 to 1.9. '
             'Experiments show that LMPC also produces strong meta-learners, '
             'improving the success rate of in-context learning new tasks on '
             'unseen robot embodiments and APIs by 31.5%. See videos, code, '
             'and demos athttps://robot-teaching.github.io/.',
 'title': 'Learning to Learn Faster from Human Feedback with Language Model '
          'Predictive Control',
 'url': 'https://deepmind.google/research/publications/74007/'}
2025-01-13 22:34:06,858 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/74007/>
{'abstract': 'Large language models (LLMs) have been shown to exhibit a wide '
             'range of capabilities, such as writing robot code from language '
             'commands -- enabling non-experts to direct robot behaviors, '
             'modify them based on feedback, or compose them to perform new '
             'tasks. However, these capabilities (driven by in-context '
             "learning) are limited to short-term interactions, where users' "
             'feedback remains relevant for only as long as it fits within the '
             'context size of the LLM, and can be forgotten over longer '
             'interactions. In this work, we investigate fine-tuning the robot '
             'code-writing LLMs, to remember their in-context interactions and '
             'improve their teachability i.e., how efficiently they adapt to '
             'human inputs (measured by average number of corrections before '
             'the user considers the task successful). Our key observation is '
             'that when human-robot interactions are formulated as a partially '
             'observable Markov decision process (in which human language '
             'inputs are observations, and robot code outputs are actions), '
             'then training an LLM to complete previous interactions can be '
             'viewed as training a transition dynamics model -- that can be '
             'combined with classic robotics techniques such as model '
             'predictive control (MPC) to discover shorter paths to success. '
             'This gives rise to Language Model Predictive Control (LMPC), a '
             'framework that fine-tunes PaLM 2 to improve its teachability on '
             '78 tasks across 5 robot embodiments -- improving non-expert '
             'teaching success rates of unseen tasks by 26.9% while reducing '
             'the average number of human corrections from 2.4 to 1.9. '
             'Experiments show that LMPC also produces strong meta-learners, '
             'improving the success rate of in-context learning new tasks on '
             'unseen robot embodiments and APIs by 31.5%. See videos, code, '
             'and demos athttps://robot-teaching.github.io/.',
 'title': 'Learning to Learn Faster from Human Feedback with Language Model '
          'Predictive Control',
 'url': 'https://deepmind.google/research/publications/74007/'}
2025-01-13 22:34:06,866 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/79663/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:06,902 - root - INFO - Scraped item: {'abstract': 'Large language models (LLMs) have accomplished remarkable '
             'reasoning performance in various domains. However, we observe '
             'that LLMs are surprisingly brittle to different premise orders, '
             'despite that such ordering does not alter the underlying task. '
             'In particular, we observe that LLMs achieve the best performance '
             'when the premise order aligns with the context required in '
             'intermediate reasoning steps. For example, in deductive '
             'reasoning tasks,  presenting the premises in the same order as '
             'the ground truth proof in the prompt (as opposed to random '
             "ordering) drastically increases the model's accuracy. We first "
             'examine the effect of premise ordering on deductive reasoning on '
             'a variety of LLMs, and our evaluation shows that even if the '
             'model performance is decent on the optimal order, permuting the '
             'premise order can cause a performance drop of over 30%. In '
             'addition, we introduce the R-GSM benchmark based on GSM8K to '
             'examine the ordering effect for math problem solving, and we '
             'again observe a significant accuracy decrease compared to the '
             'original GSM8K problems.',
 'title': 'Premise Order Matters in Reasoning with Large Language Models',
 'url': 'https://deepmind.google/research/publications/75421/'}
2025-01-13 22:34:06,918 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/75421/>
{'abstract': 'Large language models (LLMs) have accomplished remarkable '
             'reasoning performance in various domains. However, we observe '
             'that LLMs are surprisingly brittle to different premise orders, '
             'despite that such ordering does not alter the underlying task. '
             'In particular, we observe that LLMs achieve the best performance '
             'when the premise order aligns with the context required in '
             'intermediate reasoning steps. For example, in deductive '
             'reasoning tasks,  presenting the premises in the same order as '
             'the ground truth proof in the prompt (as opposed to random '
             "ordering) drastically increases the model's accuracy. We first "
             'examine the effect of premise ordering on deductive reasoning on '
             'a variety of LLMs, and our evaluation shows that even if the '
             'model performance is decent on the optimal order, permuting the '
             'premise order can cause a performance drop of over 30%. In '
             'addition, we introduce the R-GSM benchmark based on GSM8K to '
             'examine the ordering effect for math problem solving, and we '
             'again observe a significant accuracy decrease compared to the '
             'original GSM8K problems.',
 'title': 'Premise Order Matters in Reasoning with Large Language Models',
 'url': 'https://deepmind.google/research/publications/75421/'}
2025-01-13 22:34:07,047 - root - INFO - Scraped item: {'abstract': 'The advent of conversational agents with increasingly human-like '
             'behaviour throws old philosophical questions into new light. '
             'Does it, or could it, ever make sense to speak of AI agents '
             'built out of generative language models in terms of '
             'consciousness, given that they are "mere" simulacra of human '
             'behaviour, and that what they do can be seen as "merely" role '
             'play? Drawing on the later writing of Wittgenstein, this paper '
             'attempts to tackle this question while avoiding the pitfalls of '
             'dualistic thinking.',
 'title': 'Simulacra as Conscious Exotica',
 'url': 'https://deepmind.google/research/publications/79663/'}
2025-01-13 22:34:07,059 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/79663/>
{'abstract': 'The advent of conversational agents with increasingly human-like '
             'behaviour throws old philosophical questions into new light. '
             'Does it, or could it, ever make sense to speak of AI agents '
             'built out of generative language models in terms of '
             'consciousness, given that they are "mere" simulacra of human '
             'behaviour, and that what they do can be seen as "merely" role '
             'play? Drawing on the later writing of Wittgenstein, this paper '
             'attempts to tackle this question while avoiding the pitfalls of '
             'dualistic thinking.',
 'title': 'Simulacra as Conscious Exotica',
 'url': 'https://deepmind.google/research/publications/79663/'}
2025-01-13 22:34:07,066 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/24820/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,072 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/42394/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,179 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49666/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,213 - root - INFO - Scraped item: {'abstract': 'Neural Population Learning (NeuPL) represents diverse strategies '
             'in symmetric zero-sum games using a shared conditional neural '
             'network. We propose NeuPL-JPSRO, which extends this idea to '
             'n-player general-sum games and leverages the convergence '
             'guarantees of Joint Policy-Space Response Oracle (JPSRO). We '
             'show empirically that NeuPL-JPSRO converges to a Coarse '
             'Correlated Equilibrium (CCE) in several OpenSpiel games, as '
             'verified by analytical game solvers. We then deploy NeuPL-JPSRO '
             'to complex domains where JPSRO with independent RL becomes '
             'computationally impractical. We demonstrate how our approach '
             'enables adaptive coordination with co-players and transfer '
             'learning of skills in larger games. Our work shows that '
             'equilibrium convergent population learning can be implemented at '
             'scale and in generality, paving the way towards solving '
             'real-world games between heterogeneous players with mixed '
             'motives.',
 'title': 'Neural Population Learning beyond Symmetric Zero-Sum Games',
 'url': 'https://deepmind.google/research/publications/24820/'}
2025-01-13 22:34:07,225 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/24820/>
{'abstract': 'Neural Population Learning (NeuPL) represents diverse strategies '
             'in symmetric zero-sum games using a shared conditional neural '
             'network. We propose NeuPL-JPSRO, which extends this idea to '
             'n-player general-sum games and leverages the convergence '
             'guarantees of Joint Policy-Space Response Oracle (JPSRO). We '
             'show empirically that NeuPL-JPSRO converges to a Coarse '
             'Correlated Equilibrium (CCE) in several OpenSpiel games, as '
             'verified by analytical game solvers. We then deploy NeuPL-JPSRO '
             'to complex domains where JPSRO with independent RL becomes '
             'computationally impractical. We demonstrate how our approach '
             'enables adaptive coordination with co-players and transfer '
             'learning of skills in larger games. Our work shows that '
             'equilibrium convergent population learning can be implemented at '
             'scale and in generality, paving the way towards solving '
             'real-world games between heterogeneous players with mixed '
             'motives.',
 'title': 'Neural Population Learning beyond Symmetric Zero-Sum Games',
 'url': 'https://deepmind.google/research/publications/24820/'}
2025-01-13 22:34:07,263 - root - INFO - Scraped item: {'abstract': 'Meta-learning has emerged as a powerful approach to train neural '
             'networks to learn new tasks quickly from limited data. Broad '
             'exposure to different tasks leads to versatile representations '
             'enabling general problem solving. But, what are the limits of '
             'meta-learning? In this work, we explore the potential of '
             'amortizing the most powerful universal predictor, namely '
             'Solomonoff Induction (SI), into neural networks via leveraging '
             'meta-learning to its limits. We use Universal Turing Machines '
             '(UTMs) to generate training data used to expose networks to a '
             'broad range of patterns. We provide theoretical analysis of the '
             'UTM data generation processes and meta-training protocols. We '
             'conduct comprehensive experiments with neural architectures '
             '(e.g. LSTMs, Transformers) and algorithmic data generators of '
             'varying complexity and universality. Our results suggest that '
             'UTM data is a valuable resource for meta-learning, and that it '
             'can be used to train neural networks capable of learning '
             'universal prediction strategies.',
 'title': 'Learning Universal Predictors',
 'url': 'https://deepmind.google/research/publications/42394/'}
2025-01-13 22:34:07,276 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/42394/>
{'abstract': 'Meta-learning has emerged as a powerful approach to train neural '
             'networks to learn new tasks quickly from limited data. Broad '
             'exposure to different tasks leads to versatile representations '
             'enabling general problem solving. But, what are the limits of '
             'meta-learning? In this work, we explore the potential of '
             'amortizing the most powerful universal predictor, namely '
             'Solomonoff Induction (SI), into neural networks via leveraging '
             'meta-learning to its limits. We use Universal Turing Machines '
             '(UTMs) to generate training data used to expose networks to a '
             'broad range of patterns. We provide theoretical analysis of the '
             'UTM data generation processes and meta-training protocols. We '
             'conduct comprehensive experiments with neural architectures '
             '(e.g. LSTMs, Transformers) and algorithmic data generators of '
             'varying complexity and universality. Our results suggest that '
             'UTM data is a valuable resource for meta-learning, and that it '
             'can be used to train neural networks capable of learning '
             'universal prediction strategies.',
 'title': 'Learning Universal Predictors',
 'url': 'https://deepmind.google/research/publications/42394/'}
2025-01-13 22:34:07,282 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/57746/> (referer: https://deepmind.google/research/publications/?page=4)
2025-01-13 22:34:07,320 - root - INFO - Scraped item: {'abstract': 'It has long been hypothesised that causal reasoning plays a '
             'fundamental role in robust and general intelligence. However, it '
             'is not known if agents must learn causal models in order to '
             'generalise under distributional shifts, or if other inductive '
             'biases are sufficient. We answer this question, showing that any '
             'agent capable of satisfying a regret bound under a large set of '
             'distributional shifts must have learned an approximate causal '
             'model of the data generating process, which converges to the '
             'true causal model for optimal agents. We discuss the '
             'implications of this result for several research areas including '
             'transfer learning and causal inference.',
 'title': 'Robust agents learn causal world models',
 'url': 'https://deepmind.google/research/publications/49666/'}
2025-01-13 22:34:07,332 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49666/>
{'abstract': 'It has long been hypothesised that causal reasoning plays a '
             'fundamental role in robust and general intelligence. However, it '
             'is not known if agents must learn causal models in order to '
             'generalise under distributional shifts, or if other inductive '
             'biases are sufficient. We answer this question, showing that any '
             'agent capable of satisfying a regret bound under a large set of '
             'distributional shifts must have learned an approximate causal '
             'model of the data generating process, which converges to the '
             'true causal model for optimal agents. We discuss the '
             'implications of this result for several research areas including '
             'transfer learning and causal inference.',
 'title': 'Robust agents learn causal world models',
 'url': 'https://deepmind.google/research/publications/49666/'}
2025-01-13 22:34:07,429 - root - INFO - Scraped item: {'abstract': 'There is a growing interest in enhancing compiler optimizations '
             'with ML models. Yet compilers remain challenging environments '
             'for interacting with ML frameworks. Some optimizations require '
             'tightly coupled models and compiler internals, raising issues '
             'with modularity, performance and ML framework independence. '
             'Practical deployment and transparency for the end-user are also '
             'important concerns. We propose a library allowing ML model '
             'development within a traditional Python framework while enabling '
             'efficient, end-to-end integration with an optimizing compiler. '
             'We evaluate it on both research and production use cases, for '
             'training and inference, over four optimization problems.',
 'title': 'The Next 700 ML-Enabled Compiler Optimizations',
 'url': 'https://deepmind.google/research/publications/57746/'}
2025-01-13 22:34:07,441 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/57746/>
{'abstract': 'There is a growing interest in enhancing compiler optimizations '
             'with ML models. Yet compilers remain challenging environments '
             'for interacting with ML frameworks. Some optimizations require '
             'tightly coupled models and compiler internals, raising issues '
             'with modularity, performance and ML framework independence. '
             'Practical deployment and transparency for the end-user are also '
             'important concerns. We propose a library allowing ML model '
             'development within a traditional Python framework while enabling '
             'efficient, end-to-end integration with an optimizing compiler. '
             'We evaluate it on both research and production use cases, for '
             'training and inference, over four optimization problems.',
 'title': 'The Next 700 ML-Enabled Compiler Optimizations',
 'url': 'https://deepmind.google/research/publications/57746/'}
2025-01-13 22:34:07,530 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/45020/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,586 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/73001/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,624 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48253/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,680 - root - INFO - Scraped item: {'abstract': 'Bayesian optimization (BO) is a popular black-box function '
             'optimization method, which makes sequential decisions based on a '
             'Bayesian model, typically a Gaussian process (GP), for the '
             'function. To ensure the quality of the model, transfer learning '
             'approaches have been developed to automatically design GP priors '
             'by learning from data on "training" functions. These training '
             'functions are typically required to have the same domain as the '
             '"test" function (black-box function to be optimized). In this '
             'paper, we introduce MPHD, a model pre-training method on '
             'heterogeneous domains, which uses a neural net mapping from '
             'domain descriptions to specifications of a hierarchical GP. MPHD '
             'can be seamlessly integrated with BO to transfer knowledge '
             'across heterogeneous search spaces. Our theoretical and '
             'empirical results demonstrate the validity of MPHD and its '
             'superior performance on challenging black-box function '
             'optimization tasks.',
 'title': 'Transfer Learning for Bayesian Optimization on Heterogeneous Search '
          'Spaces',
 'url': 'https://deepmind.google/research/publications/45020/'}
2025-01-13 22:34:07,692 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/45020/>
{'abstract': 'Bayesian optimization (BO) is a popular black-box function '
             'optimization method, which makes sequential decisions based on a '
             'Bayesian model, typically a Gaussian process (GP), for the '
             'function. To ensure the quality of the model, transfer learning '
             'approaches have been developed to automatically design GP priors '
             'by learning from data on "training" functions. These training '
             'functions are typically required to have the same domain as the '
             '"test" function (black-box function to be optimized). In this '
             'paper, we introduce MPHD, a model pre-training method on '
             'heterogeneous domains, which uses a neural net mapping from '
             'domain descriptions to specifications of a hierarchical GP. MPHD '
             'can be seamlessly integrated with BO to transfer knowledge '
             'across heterogeneous search spaces. Our theoretical and '
             'empirical results demonstrate the validity of MPHD and its '
             'superior performance on challenging black-box function '
             'optimization tasks.',
 'title': 'Transfer Learning for Bayesian Optimization on Heterogeneous Search '
          'Spaces',
 'url': 'https://deepmind.google/research/publications/45020/'}
2025-01-13 22:34:07,732 - root - INFO - Scraped item: {'abstract': 'We present evidence of substantial benefit to efficient '
             'exploration in gathering human feedback to improve large '
             'language models.  In our experiments, an agent sequentially '
             'generates queries while fitting a reward model to the feedback '
             'received.  Our best-performing agent generates queries using '
             'double Thompson sampling, with uncertainty represented by an '
             'epistemic neural network.  Our results demonstrate that '
             'efficient exploration enables high levels of performance with '
             'far fewer queries.  Further, both uncertainty estimation and the '
             'choice of exploration scheme play critical roles.',
 'title': 'Exploration at Scale using Epistemic Neural Networks',
 'url': 'https://deepmind.google/research/publications/73001/'}
2025-01-13 22:34:07,744 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/73001/>
{'abstract': 'We present evidence of substantial benefit to efficient '
             'exploration in gathering human feedback to improve large '
             'language models.  In our experiments, an agent sequentially '
             'generates queries while fitting a reward model to the feedback '
             'received.  Our best-performing agent generates queries using '
             'double Thompson sampling, with uncertainty represented by an '
             'epistemic neural network.  Our results demonstrate that '
             'efficient exploration enables high levels of performance with '
             'far fewer queries.  Further, both uncertainty estimation and the '
             'choice of exploration scheme play critical roles.',
 'title': 'Exploration at Scale using Epistemic Neural Networks',
 'url': 'https://deepmind.google/research/publications/73001/'}
2025-01-13 22:34:07,749 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/64816/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:07,785 - root - INFO - Scraped item: {'abstract': 'We study the fractal structure of language, aiming to provide a '
             'precise formalism for quantifying several properties that may '
             'have been previously suspected but not  formally shown. We '
             'establish that language is: (1) self-similar, exhibiting '
             'complexities at all levels of granularity, with no particular '
             'characteristic granularity level or context length, and (2) '
             'long-range dependent (LRD), with tokens at any instant typically '
             'correlated with all subsequent tokens. Based on these findings, '
             'we argue that short-term patterns in language, such as in '
             'paragraphs, mirror the patterns seen in larger scopes, like '
             'entire documents. This may shed some light on how next-token '
             'prediction can lead to a comprehension of the structure of text '
             'at multiple levels of granularity, from words and clauses to '
             'broader contexts and intents. In addition, we demonstrate a '
             'connection between fractal parameters, such as the Hurst '
             'exponent, and scaling laws when varying the context length at '
             'inference time. We hope that these findings offer a fresh '
             'perspective on the nature of language and the mechanisms '
             'underlying the success of LLMs.',
 'title': 'Fractal Patterns May Unravel the Intelligence in Next-Token '
          'Prediction',
 'url': 'https://deepmind.google/research/publications/48253/'}
2025-01-13 22:34:07,799 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48253/>
{'abstract': 'We study the fractal structure of language, aiming to provide a '
             'precise formalism for quantifying several properties that may '
             'have been previously suspected but not  formally shown. We '
             'establish that language is: (1) self-similar, exhibiting '
             'complexities at all levels of granularity, with no particular '
             'characteristic granularity level or context length, and (2) '
             'long-range dependent (LRD), with tokens at any instant typically '
             'correlated with all subsequent tokens. Based on these findings, '
             'we argue that short-term patterns in language, such as in '
             'paragraphs, mirror the patterns seen in larger scopes, like '
             'entire documents. This may shed some light on how next-token '
             'prediction can lead to a comprehension of the structure of text '
             'at multiple levels of granularity, from words and clauses to '
             'broader contexts and intents. In addition, we demonstrate a '
             'connection between fractal parameters, such as the Hurst '
             'exponent, and scaling laws when varying the context length at '
             'inference time. We hope that these findings offer a fresh '
             'perspective on the nature of language and the mechanisms '
             'underlying the success of LLMs.',
 'title': 'Fractal Patterns May Unravel the Intelligence in Next-Token '
          'Prediction',
 'url': 'https://deepmind.google/research/publications/48253/'}
2025-01-13 22:34:07,894 - root - INFO - Scraped item: {'abstract': 'We introduce SELF-DISCOVER, a general framework for LLMs to '
             'self-discover and compose atomic reasoning modules such as '
             'critical thinking\n'
             'and step-by-step reasoning to tackle complex reasoning problems '
             'that are challenging for typical prompting methods e.g. '
             'Chain-of-Thought (CoT). Core to the framework is a self-discover '
             'process where LLMs select multiple atomic reasoning modules, and '
             'compose them into an explicit and task-unique reasoning '
             'structure for LLMs to follow during decoding, in sharp contrast '
             'to the implicit reasoning in CoT. SELF-DISCOVER substantially '
             'improves GPT-4 and PaLM-2’s performance on challenging reasoning '
             'benchmarks such as BigBench-Hard and Thinking4Doing, by as much '
             'as 30%. Furthermore, SELF-DISCOVER outperforms '
             'inference-intensive methods such as CoT-Self-Consistency and '
             'majority voting by more than 20% across 24 tasks on multiple '
             'LLMs, while requiring 10-40x fewer inference compute. Finally, '
             'the self-discovered reasoning structures by GPT-4 can also be '
             'applied to smaller models of Llama 2 to improving their '
             'reasoning capabilities, demonstrating generalization of the '
             'discovered reasoning structures.',
 'title': 'Large Language Models Self-Discover Reasoning Structures',
 'url': 'https://deepmind.google/research/publications/64816/'}
2025-01-13 22:34:07,908 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/64816/>
{'abstract': 'We introduce SELF-DISCOVER, a general framework for LLMs to '
             'self-discover and compose atomic reasoning modules such as '
             'critical thinking\n'
             'and step-by-step reasoning to tackle complex reasoning problems '
             'that are challenging for typical prompting methods e.g. '
             'Chain-of-Thought (CoT). Core to the framework is a self-discover '
             'process where LLMs select multiple atomic reasoning modules, and '
             'compose them into an explicit and task-unique reasoning '
             'structure for LLMs to follow during decoding, in sharp contrast '
             'to the implicit reasoning in CoT. SELF-DISCOVER substantially '
             'improves GPT-4 and PaLM-2’s performance on challenging reasoning '
             'benchmarks such as BigBench-Hard and Thinking4Doing, by as much '
             'as 30%. Furthermore, SELF-DISCOVER outperforms '
             'inference-intensive methods such as CoT-Self-Consistency and '
             'majority voting by more than 20% across 24 tasks on multiple '
             'LLMs, while requiring 10-40x fewer inference compute. Finally, '
             'the self-discovered reasoning structures by GPT-4 can also be '
             'applied to smaller models of Llama 2 to improving their '
             'reasoning capabilities, demonstrating generalization of the '
             'discovered reasoning structures.',
 'title': 'Large Language Models Self-Discover Reasoning Structures',
 'url': 'https://deepmind.google/research/publications/64816/'}
2025-01-13 22:34:08,192 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/67342/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:08,220 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/63907/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:08,332 - root - INFO - Scraped item: {'abstract': 'Game theory is the study of mathematical models of strategic '
             'interactions among rational agents. Language is a key medium of '
             'interaction for humans, though it has historically proven '
             'difficult to model dialogue and its strategic motivations '
             'mathematically. A suitable model of the players, strategies, and '
             'payoffs associated with linguistic interactions (i.e., a binding '
             'to the conventional symbolic logic of game theory) would enable '
             'existing game-theoretic algorithms to provide strategic '
             'solutions in the space of language. In other words, a binding '
             'could provide a route to computing stable, rational '
             'conversational strategies in dialogue. Large language models '
             '(LLMs) have arguably reached a point where their generative '
             'capabilities can enable realistic, human-like simulations of '
             'natural dialogue. By prompting them in various ways, we can '
             'steer their responses towards different output utterances. '
             'Leveraging the expressivity of natural language, LLMs can also '
             'help us quickly generate new dialogue scenarios, which are '
             'grounded in real world applications. In this work, we present '
             'one possible binding from dialogue to game theory as well as '
             'generalizations of existing equilibrium finding algorithms to '
             'this setting. In addition, by exploiting LLMs generation '
             'capabilities along with our proposed binding, we can synthesize '
             'a large repository of formally-defined games in which one can '
             'study and test game-theoretic solution concepts. We also '
             'demonstrate how one can combine LLM-driven game generation, '
             'game-theoretic solvers, and imitation learning to construct a '
             'process for improving the strategic capabilities of LLMs.',
 'title': 'States as Strings as Strategies: Steering Language Models with '
          'Game-Theoretic Solvers',
 'url': 'https://deepmind.google/research/publications/67342/'}
2025-01-13 22:34:08,347 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/67342/>
{'abstract': 'Game theory is the study of mathematical models of strategic '
             'interactions among rational agents. Language is a key medium of '
             'interaction for humans, though it has historically proven '
             'difficult to model dialogue and its strategic motivations '
             'mathematically. A suitable model of the players, strategies, and '
             'payoffs associated with linguistic interactions (i.e., a binding '
             'to the conventional symbolic logic of game theory) would enable '
             'existing game-theoretic algorithms to provide strategic '
             'solutions in the space of language. In other words, a binding '
             'could provide a route to computing stable, rational '
             'conversational strategies in dialogue. Large language models '
             '(LLMs) have arguably reached a point where their generative '
             'capabilities can enable realistic, human-like simulations of '
             'natural dialogue. By prompting them in various ways, we can '
             'steer their responses towards different output utterances. '
             'Leveraging the expressivity of natural language, LLMs can also '
             'help us quickly generate new dialogue scenarios, which are '
             'grounded in real world applications. In this work, we present '
             'one possible binding from dialogue to game theory as well as '
             'generalizations of existing equilibrium finding algorithms to '
             'this setting. In addition, by exploiting LLMs generation '
             'capabilities along with our proposed binding, we can synthesize '
             'a large repository of formally-defined games in which one can '
             'study and test game-theoretic solution concepts. We also '
             'demonstrate how one can combine LLM-driven game generation, '
             'game-theoretic solvers, and imitation learning to construct a '
             'process for improving the strategic capabilities of LLMs.',
 'title': 'States as Strings as Strategies: Steering Language Models with '
          'Game-Theoretic Solvers',
 'url': 'https://deepmind.google/research/publications/67342/'}
2025-01-13 22:34:08,388 - root - INFO - Scraped item: {'abstract': 'Despite their stellar performance on a wide range of tasks, '
             'including in-context tasks only revealed during inference, '
             'vanilla transformers and variants trained for next-token '
             'predictions (a) do not learn an explicit world model of their '
             'environment which can be flexibly queried and (b) cannot be used '
             'for planning or navigation. In this paper, we consider partially '
             "observed environments (POEs), where an agent's spatial position "
             'cannot be deterministically recovered from its observation, '
             'which makes planning hard. We introduce a transformer with '
             '(multiple) discrete bottleneck(s), TDB, whose latent codes learn '
             'a compressed representation of the observations. After training '
             'a TDB with an augmented objective on sequences of observations '
             'and actions, we extract interpretable cognitive maps of the '
             'environment from the active bottleneck(s) indices. These maps '
             'are then paired with an external solver to solve planning '
             'problems. First, we show that a TDB trained on POEs (a) retains '
             'the near-perfect predictive performance of a vanilla transformer '
             'or an LSTM while (b) solving shortest paths problems '
             'exponentially more efficiently. Second, a TDB extracts '
             'interpretable representations from text datasets, while reaching '
             'higher in-context accuracy than vanilla sequence models. '
             'Finally, in new POEs, a TDB (a) reaches near-perfect in-context '
             'accuracy, (b) learns accurate in-context cognitive maps (c) '
             'solves in-context planning problems.',
 'title': 'Learning Planning-compatible Cognitive Maps with Transformers in '
          'PartiallyObserved Environments',
 'url': 'https://deepmind.google/research/publications/63907/'}
2025-01-13 22:34:08,401 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/63907/>
{'abstract': 'Despite their stellar performance on a wide range of tasks, '
             'including in-context tasks only revealed during inference, '
             'vanilla transformers and variants trained for next-token '
             'predictions (a) do not learn an explicit world model of their '
             'environment which can be flexibly queried and (b) cannot be used '
             'for planning or navigation. In this paper, we consider partially '
             "observed environments (POEs), where an agent's spatial position "
             'cannot be deterministically recovered from its observation, '
             'which makes planning hard. We introduce a transformer with '
             '(multiple) discrete bottleneck(s), TDB, whose latent codes learn '
             'a compressed representation of the observations. After training '
             'a TDB with an augmented objective on sequences of observations '
             'and actions, we extract interpretable cognitive maps of the '
             'environment from the active bottleneck(s) indices. These maps '
             'are then paired with an external solver to solve planning '
             'problems. First, we show that a TDB trained on POEs (a) retains '
             'the near-perfect predictive performance of a vanilla transformer '
             'or an LSTM while (b) solving shortest paths problems '
             'exponentially more efficiently. Second, a TDB extracts '
             'interpretable representations from text datasets, while reaching '
             'higher in-context accuracy than vanilla sequence models. '
             'Finally, in new POEs, a TDB (a) reaches near-perfect in-context '
             'accuracy, (b) learns accurate in-context cognitive maps (c) '
             'solves in-context planning problems.',
 'title': 'Learning Planning-compatible Cognitive Maps with Transformers in '
          'PartiallyObserved Environments',
 'url': 'https://deepmind.google/research/publications/63907/'}
2025-01-13 22:34:08,540 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48050/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:08,585 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=6> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:08,686 - root - INFO - Scraped item: {'abstract': 'Knowledge distillation (KD) is widely used for compressing a '
             'teacher model to reduce its inference cost and memory footprint, '
             'by training a smaller student model. However, current KD methods '
             'for auto-regressive sequence models suffer from distribution '
             'mismatch between output sequences seen during training and those '
             'generated by the student upon deployment. To address this issue, '
             'we introduce Generalized Knowledge Distillation (GKD). Instead '
             'of solely relying on a fixed set of output sequences, GKD trains '
             'the student on its self-generated output sequences by leveraging '
             'feedback from the teacher on such sequences. Unlike supervised '
             'KD approaches, GKD also offers the flexibility to employ '
             'alternative divergence measures between the student and teacher, '
             'which can be useful when the student lacks the expressivity to '
             "mimic the teacher's distribution. Furthermore, GKD facilitates "
             'the seamless integration of distillation with RL fine-tuning '
             '(RLHF). We demonstrate the efficacy of GKD for distilling '
             'auto-regressive language models on summarization, translation, '
             'and arithmetic reasoning tasks.',
 'title': 'On-Policy Distillation of Language Models: Learning from '
          'Self-Generated Mistakes',
 'url': 'https://deepmind.google/research/publications/48050/'}
2025-01-13 22:34:08,700 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48050/>
{'abstract': 'Knowledge distillation (KD) is widely used for compressing a '
             'teacher model to reduce its inference cost and memory footprint, '
             'by training a smaller student model. However, current KD methods '
             'for auto-regressive sequence models suffer from distribution '
             'mismatch between output sequences seen during training and those '
             'generated by the student upon deployment. To address this issue, '
             'we introduce Generalized Knowledge Distillation (GKD). Instead '
             'of solely relying on a fixed set of output sequences, GKD trains '
             'the student on its self-generated output sequences by leveraging '
             'feedback from the teacher on such sequences. Unlike supervised '
             'KD approaches, GKD also offers the flexibility to employ '
             'alternative divergence measures between the student and teacher, '
             'which can be useful when the student lacks the expressivity to '
             "mimic the teacher's distribution. Furthermore, GKD facilitates "
             'the seamless integration of distillation with RL fine-tuning '
             '(RLHF). We demonstrate the efficacy of GKD for distilling '
             'auto-regressive language models on summarization, translation, '
             'and arithmetic reasoning tasks.',
 'title': 'On-Policy Distillation of Language Models: Learning from '
          'Self-Generated Mistakes',
 'url': 'https://deepmind.google/research/publications/48050/'}
2025-01-13 22:34:08,706 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=6
2025-01-13 22:34:08,729 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/67846/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:08,873 - root - INFO - Scraped item: {'abstract': 'As the AI community increasingly adopts large-scale models, it '
             'is crucial to develop general and flexible tools to integrate '
             'them. We introduce Gather-Attend-Scatter (GATS), a novel module '
             'that enables seamless combination of pretrained foundation '
             'models, both trainable and frozen, into larger multimodal '
             'networks. GATS empowers AI systems to process and generate '
             'information across multiple modalities at different rates. In '
             'contrast to traditional fine-tuning, GATS allows for the '
             'original component models to remain frozen, avoiding the risk of '
             'them losing important knowledge acquired during the pretraining '
             'phase. We demonstrate the utility and versatility of GATS with a '
             'few experiments across games, robotics, and multimodal '
             'input-output systems.',
 'title': 'GATS: Gather-Attend-Scatter',
 'url': 'https://deepmind.google/research/publications/67846/'}
2025-01-13 22:34:08,888 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/67846/>
{'abstract': 'As the AI community increasingly adopts large-scale models, it '
             'is crucial to develop general and flexible tools to integrate '
             'them. We introduce Gather-Attend-Scatter (GATS), a novel module '
             'that enables seamless combination of pretrained foundation '
             'models, both trainable and frozen, into larger multimodal '
             'networks. GATS empowers AI systems to process and generate '
             'information across multiple modalities at different rates. In '
             'contrast to traditional fine-tuning, GATS allows for the '
             'original component models to remain frozen, avoiding the risk of '
             'them losing important knowledge acquired during the pretraining '
             'phase. We demonstrate the utility and versatility of GATS with a '
             'few experiments across games, robotics, and multimodal '
             'input-output systems.',
 'title': 'GATS: Gather-Attend-Scatter',
 'url': 'https://deepmind.google/research/publications/67846/'}
2025-01-13 22:34:08,894 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/2504/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:08,924 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/24821/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,043 - root - INFO - Scraped item: {'abstract': 'Prefrontal cortex is crucial for learning and decision-making. '
             'Classic reinforcement learning (RL) theories centre on learning '
             'the expectation of potential rewarding outcomes and explain a '
             'wealth of neural data in prefrontal cortex. Distributional RL, '
             'on the other hand, learns the full distribution of rewarding '
             'outcomes and better explains dopamine responses. Here we show '
             'distributional RL also better explains prefrontal cortical '
             'responses, suggesting it is a ubiquitous mechanism for '
             'reward-guided learning.',
 'title': 'Distributional reinforcement learning in prefrontal cortex',
 'url': 'https://deepmind.google/research/publications/2504/'}
2025-01-13 22:34:09,056 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/2504/>
{'abstract': 'Prefrontal cortex is crucial for learning and decision-making. '
             'Classic reinforcement learning (RL) theories centre on learning '
             'the expectation of potential rewarding outcomes and explain a '
             'wealth of neural data in prefrontal cortex. Distributional RL, '
             'on the other hand, learns the full distribution of rewarding '
             'outcomes and better explains dopamine responses. Here we show '
             'distributional RL also better explains prefrontal cortical '
             'responses, suggesting it is a ubiquitous mechanism for '
             'reward-guided learning.',
 'title': 'Distributional reinforcement learning in prefrontal cortex',
 'url': 'https://deepmind.google/research/publications/2504/'}
2025-01-13 22:34:09,124 - root - INFO - Scraped item: {'abstract': 'We introduce the use of generative adversarial learning to '
             'compute equilibria in general game-theoretic settings, '
             'specifically the generalized Nash equilibrium (GNE) in '
             'pseudo-games, and its specific instantiation as the competitive '
             'equilibrium (CE) in Arrow-Debreu competitive economies. '
             "Pseudo-games are a generalization of games in which players' "
             'actions affect not only the payoffs of other players but also '
             'their feasible action spaces. Although the computation of GNE '
             'and CE is intractable in the worst-case, i.e., PPAD-hard, in '
             'practice, many applications only require solutions with high '
             'accuracy in expectation over a distribution of problem '
             'instances. We introduce Generative Adversarial Equilibrium '
             'Solvers (GAES): a family of generative adversarial neural '
             'networks that can learn GNE and CE from only a sample of problem '
             'instances. We provide computational and sample complexity bounds '
             'for Lipschitz-smooth function approximators in a large class of '
             'concave pseudo-games, and apply the framework to finding Nash '
             'equilibria in normal-form games, CE in Arrow-Debreu competitive '
             'economies, and GNE in an environmental economic model of the '
             'Kyoto mechanism.',
 'title': 'Generative Adversarial Equilibrium Solvers',
 'url': 'https://deepmind.google/research/publications/24821/'}
2025-01-13 22:34:09,139 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/24821/>
{'abstract': 'We introduce the use of generative adversarial learning to '
             'compute equilibria in general game-theoretic settings, '
             'specifically the generalized Nash equilibrium (GNE) in '
             'pseudo-games, and its specific instantiation as the competitive '
             'equilibrium (CE) in Arrow-Debreu competitive economies. '
             "Pseudo-games are a generalization of games in which players' "
             'actions affect not only the payoffs of other players but also '
             'their feasible action spaces. Although the computation of GNE '
             'and CE is intractable in the worst-case, i.e., PPAD-hard, in '
             'practice, many applications only require solutions with high '
             'accuracy in expectation over a distribution of problem '
             'instances. We introduce Generative Adversarial Equilibrium '
             'Solvers (GAES): a family of generative adversarial neural '
             'networks that can learn GNE and CE from only a sample of problem '
             'instances. We provide computational and sample complexity bounds '
             'for Lipschitz-smooth function approximators in a large class of '
             'concave pseudo-games, and apply the framework to finding Nash '
             'equilibria in normal-form games, CE in Arrow-Debreu competitive '
             'economies, and GNE in an environmental economic model of the '
             'Kyoto mechanism.',
 'title': 'Generative Adversarial Equilibrium Solvers',
 'url': 'https://deepmind.google/research/publications/24821/'}
2025-01-13 22:34:09,146 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/40173/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,155 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34213/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,293 - root - INFO - Scraped item: {'abstract': 'Normal-form games (NFGs) are fundamental subjects of game '
             'theoretic analysis that describe strategic interactions between '
             'players. While NFGs are typically represented as payoff tensors, '
             'any permutation of player actions describes an identical game. '
             'We proposeNfgTransformer, a general-purpose query-key-value '
             'architecture that exploits the equivariance inherent to this '
             'data modality. We show the efficacy of our approach in a range '
             'of downstream tasks, including equilibrium solving, '
             'deviation-gain estimation and ranking on synthetic and standard '
             'games. Beyond strong quantitative results, we show that our '
             'model internally developed a recognisable pattern of iterative '
             'equilibrium refinement when solving for a Nash Equilibrium in a '
             'suite of GAMUT games. We hope our work can serves as an '
             'effective bridge to bring scalable learning techniques to game '
             'theoretic analysis.',
 'title': 'NfgTransformer: Equivariant Representation Learning for Normal-form '
          'Games',
 'url': 'https://deepmind.google/research/publications/40173/'}
2025-01-13 22:34:09,307 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/40173/>
{'abstract': 'Normal-form games (NFGs) are fundamental subjects of game '
             'theoretic analysis that describe strategic interactions between '
             'players. While NFGs are typically represented as payoff tensors, '
             'any permutation of player actions describes an identical game. '
             'We proposeNfgTransformer, a general-purpose query-key-value '
             'architecture that exploits the equivariance inherent to this '
             'data modality. We show the efficacy of our approach in a range '
             'of downstream tasks, including equilibrium solving, '
             'deviation-gain estimation and ranking on synthetic and standard '
             'games. Beyond strong quantitative results, we show that our '
             'model internally developed a recognisable pattern of iterative '
             'equilibrium refinement when solving for a Nash Equilibrium in a '
             'suite of GAMUT games. We hope our work can serves as an '
             'effective bridge to bring scalable learning techniques to game '
             'theoretic analysis.',
 'title': 'NfgTransformer: Equivariant Representation Learning for Normal-form '
          'Games',
 'url': 'https://deepmind.google/research/publications/40173/'}
2025-01-13 22:34:09,344 - root - INFO - Scraped item: {'abstract': 'We propose the first loss function for approximate Nash '
             'equilibria of normal-form games that is amenable to unbiased '
             'Monte Carlo estimation. This construction allows us to deploy '
             'standard non-convex stochastic optimization techniques for '
             'approximating Nash equilibria, resulting in novel algorithms '
             'with provable guarantees. We complement our theoretical analysis '
             'with experiments demonstrating that stochastic gradient descent '
             'can outperform previous state-of-the-art approaches.',
 'title': 'Approximating Nash Equilibria in Normal-Form Games via Stochastic '
          'Optimization',
 'url': 'https://deepmind.google/research/publications/34213/'}
2025-01-13 22:34:09,357 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34213/>
{'abstract': 'We propose the first loss function for approximate Nash '
             'equilibria of normal-form games that is amenable to unbiased '
             'Monte Carlo estimation. This construction allows us to deploy '
             'standard non-convex stochastic optimization techniques for '
             'approximating Nash equilibria, resulting in novel algorithms '
             'with provable guarantees. We complement our theoretical analysis '
             'with experiments demonstrating that stochastic gradient descent '
             'can outperform previous state-of-the-art approaches.',
 'title': 'Approximating Nash Equilibria in Normal-Form Games via Stochastic '
          'Optimization',
 'url': 'https://deepmind.google/research/publications/34213/'}
2025-01-13 22:34:09,362 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/51081/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,511 - root - INFO - Scraped item: {'abstract': 'We present Direct Reward Fine-Tuning (DRaFT), a simple and '
             'effective method for fine-tuning diffusion models to maximize '
             'differentiable reward functions, such as scores from human '
             'preference models. We first show that it is possible to '
             'backpropagate the reward function gradient through the full '
             'sampling procedure, and that doing so achieves strong '
             'performance on a variety of rewards, outperforming reinforcement '
             'learning-based approaches. We then propose more efficient '
             'variants of DRaFT: DRaFT-K, which truncates backpropagation to '
             'only the last K steps of sampling, and DRaFT-LV, which obtains '
             'lower-variance gradient estimates for the case when K=1. We show '
             'that our methods work well for a variety of reward functions and '
             'can be used to substantially improve the aesthetic quality of '
             'images generated by Stable Diffusion 1.4. Finally, we draw '
             'connections between our approach and prior work, providing a '
             'unifying perspective on the design space of gradient-based '
             'fine-tuning algorithms.',
 'title': 'Directly Fine-Tuning Diffusion Models on Differentiable Rewards',
 'url': 'https://deepmind.google/research/publications/51081/'}
2025-01-13 22:34:09,523 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/51081/>
{'abstract': 'We present Direct Reward Fine-Tuning (DRaFT), a simple and '
             'effective method for fine-tuning diffusion models to maximize '
             'differentiable reward functions, such as scores from human '
             'preference models. We first show that it is possible to '
             'backpropagate the reward function gradient through the full '
             'sampling procedure, and that doing so achieves strong '
             'performance on a variety of rewards, outperforming reinforcement '
             'learning-based approaches. We then propose more efficient '
             'variants of DRaFT: DRaFT-K, which truncates backpropagation to '
             'only the last K steps of sampling, and DRaFT-LV, which obtains '
             'lower-variance gradient estimates for the case when K=1. We show '
             'that our methods work well for a variety of reward functions and '
             'can be used to substantially improve the aesthetic quality of '
             'images generated by Stable Diffusion 1.4. Finally, we draw '
             'connections between our approach and prior work, providing a '
             'unifying perspective on the design space of gradient-based '
             'fine-tuning algorithms.',
 'title': 'Directly Fine-Tuning Diffusion Models on Differentiable Rewards',
 'url': 'https://deepmind.google/research/publications/51081/'}
2025-01-13 22:34:09,529 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/66535/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,538 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/68048/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,611 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/52797/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,668 - root - INFO - Scraped item: {'abstract': 'Training large language models requires substantial '
             'computational resources. As models keep scaling, it is crucial '
             'to leverage distributed computation resources that might be even '
             'geographically distant from each other. Due to the latency and '
             'heterogeneity of these computation devices, it is natural to '
             'consider Local Stochastic Gradient Descent (localSGD) (e.g., '
             'each device performs more than one update per communication) and '
             'asynchronous training (the server updates the global parameter '
             'vector as soon as a worker has completed its local updates). '
             'This work presents an initial study on asynchronous localSGD for '
             'language modeling. We conduct a comprehensive investigation by '
             'examining how worker heterogeneity, model size, number of '
             'workers, and optimizer could impact the learning performance. We '
             'identified that a key hurdle of applying asynchronous localSGD '
             'in language modeling is the application of momentum acceleration '
             'on the server side when worker gradients are staled. In this '
             'setting, asynchronous localSGD takes more iterations to converge '
             'than its synchronous counterpart despite updating the global '
             'parameters more frequently. To mitigate this optimization '
             'challenge, we propose a novel method that utilizes a delayed '
             "Nesterov momentum update and adjusts the workers' local training "
             'steps based on their computation speed. This approach, evaluated '
             'with models up to 150M parameters on the C4 dataset, not only '
             'matches the performance of synchronous localSGD in terms of '
             'perplexity per update step but also surpasses it significantly '
             'in terms of wall clock time. For the convenience of future '
             'research and quick prototyping of new ideas, we also make '
             'available a toy framework that replicates the observed  '
             'optimization challenges on a mixture of mixtures of Gaussians. '
             'We hope this work can bring new insights and tools to facilitate '
             'future discovery of more efficient language model optimizers.',
 'title': 'Asynchronous Local-SGD Training forLanguage Modeling',
 'url': 'https://deepmind.google/research/publications/66535/'}
2025-01-13 22:34:09,700 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/66535/>
{'abstract': 'Training large language models requires substantial '
             'computational resources. As models keep scaling, it is crucial '
             'to leverage distributed computation resources that might be even '
             'geographically distant from each other. Due to the latency and '
             'heterogeneity of these computation devices, it is natural to '
             'consider Local Stochastic Gradient Descent (localSGD) (e.g., '
             'each device performs more than one update per communication) and '
             'asynchronous training (the server updates the global parameter '
             'vector as soon as a worker has completed its local updates). '
             'This work presents an initial study on asynchronous localSGD for '
             'language modeling. We conduct a comprehensive investigation by '
             'examining how worker heterogeneity, model size, number of '
             'workers, and optimizer could impact the learning performance. We '
             'identified that a key hurdle of applying asynchronous localSGD '
             'in language modeling is the application of momentum acceleration '
             'on the server side when worker gradients are staled. In this '
             'setting, asynchronous localSGD takes more iterations to converge '
             'than its synchronous counterpart despite updating the global '
             'parameters more frequently. To mitigate this optimization '
             'challenge, we propose a novel method that utilizes a delayed '
             "Nesterov momentum update and adjusts the workers' local training "
             'steps based on their computation speed. This approach, evaluated '
             'with models up to 150M parameters on the C4 dataset, not only '
             'matches the performance of synchronous localSGD in terms of '
             'perplexity per update step but also surpasses it significantly '
             'in terms of wall clock time. For the convenience of future '
             'research and quick prototyping of new ideas, we also make '
             'available a toy framework that replicates the observed  '
             'optimization challenges on a mixture of mixtures of Gaussians. '
             'We hope this work can bring new insights and tools to facilitate '
             'future discovery of more efficient language model optimizers.',
 'title': 'Asynchronous Local-SGD Training forLanguage Modeling',
 'url': 'https://deepmind.google/research/publications/66535/'}
2025-01-13 22:34:09,742 - root - INFO - Scraped item: {'abstract': 'This work introduces E3x, a software package for building neural '
             'networks that are equivariant with respect to the Euclidean '
             'group E(3), consisting of translations, rotations, and '
             'reflections of three-dimensional space. Compared to ordinary '
             'neural networks, E(3)-equivariant models promise benefits '
             'whenever input and/or output data are quantities associated with '
             'three-dimensional objects. This is because the numeric values of '
             'such quantities (e.g. positions) typically depend on the chosen '
             'coordinate system. Under transformations of the reference frame, '
             'the values change predictably, but the underlying rules can be '
             'difficult to learn for ordinary machine learning models. With '
             'built-in E(3)-equivariance, neural networks are guaranteed to '
             'satisfy the relevant transformation rules exactly, resulting in '
             'superior data efficiency and accuracy.',
 'title': 'E3x: E(3)-Equivariant Deep Learning Made Easy',
 'url': 'https://deepmind.google/research/publications/68048/'}
2025-01-13 22:34:09,754 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/68048/>
{'abstract': 'This work introduces E3x, a software package for building neural '
             'networks that are equivariant with respect to the Euclidean '
             'group E(3), consisting of translations, rotations, and '
             'reflections of three-dimensional space. Compared to ordinary '
             'neural networks, E(3)-equivariant models promise benefits '
             'whenever input and/or output data are quantities associated with '
             'three-dimensional objects. This is because the numeric values of '
             'such quantities (e.g. positions) typically depend on the chosen '
             'coordinate system. Under transformations of the reference frame, '
             'the values change predictably, but the underlying rules can be '
             'difficult to learn for ordinary machine learning models. With '
             'built-in E(3)-equivariance, neural networks are guaranteed to '
             'satisfy the relevant transformation rules exactly, resulting in '
             'superior data efficiency and accuracy.',
 'title': 'E3x: E(3)-Equivariant Deep Learning Made Easy',
 'url': 'https://deepmind.google/research/publications/68048/'}
2025-01-13 22:34:09,790 - root - INFO - Scraped item: {'abstract': 'We study the problem of Bayesian fixed-budget best-arm '
             'identification (BAI) in structured bandits. We propose an '
             'algorithm that uses fixed allocations based on the prior '
             'information and the structure of the environment. We provide '
             'theoretical bounds on its performance across diverse models, '
             'including the first prior-dependent upper bounds for linear and '
             'hierarchical BAI. Our key contribution is introducing new proof '
             'methods that result in tighter bounds for multi-armed BAI '
             'compared to existing methods. We extensively compare our '
             'approach to other fixed-budget BAI methods, demonstrating its '
             'consistent and robust performance in various settings. Our work '
             'improves our understanding of Bayesian fixed-budget BAI in '
             'structured bandits and highlights the effectiveness of our '
             'approach in practical scenarios.',
 'title': 'Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm '
          'Identification in Structured Bandits',
 'url': 'https://deepmind.google/research/publications/52797/'}
2025-01-13 22:34:09,802 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/52797/>
{'abstract': 'We study the problem of Bayesian fixed-budget best-arm '
             'identification (BAI) in structured bandits. We propose an '
             'algorithm that uses fixed allocations based on the prior '
             'information and the structure of the environment. We provide '
             'theoretical bounds on its performance across diverse models, '
             'including the first prior-dependent upper bounds for linear and '
             'hierarchical BAI. Our key contribution is introducing new proof '
             'methods that result in tighter bounds for multi-armed BAI '
             'compared to existing methods. We extensively compare our '
             'approach to other fixed-budget BAI methods, demonstrating its '
             'consistent and robust performance in various settings. Our work '
             'improves our understanding of Bayesian fixed-budget BAI in '
             'structured bandits and highlights the effectiveness of our '
             'approach in practical scenarios.',
 'title': 'Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm '
          'Identification in Structured Bandits',
 'url': 'https://deepmind.google/research/publications/52797/'}
2025-01-13 22:34:09,808 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/79057/> (referer: https://deepmind.google/research/publications/?page=5)
2025-01-13 22:34:09,942 - root - INFO - Scraped item: {'abstract': 'Most transformer-based video encoders are limited to short '
             'temporal contexts due to their quadratic complexity. While '
             'various attempts have been made to extend this context, this has '
             'often come at the cost of both conceptual and computational '
             'complexity. We propose to instead re-purpose existing '
             'pre-trained video transformers by simply fine-tuning them to '
             'attend to memories derived non-parametrically from past '
             'activations. By leveraging redundancy reduction, our '
             'memory-consolidated vision transformer (MC-ViT) effortlessly '
             'extends its context far into the past and exhibits excellent '
             'scaling behavior when learning from longer videos. In doing so, '
             'MC-ViT sets a new state-of-the-art in long-context video '
             'understanding on EgoSchema, Perception Test, and Diving48, '
             'outperforming methods that benefit from orders of magnitude more '
             'parameters.',
 'title': 'Memory Consolidation Enables Long-Context Video Understanding',
 'url': 'https://deepmind.google/research/publications/79057/'}
2025-01-13 22:34:09,954 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/79057/>
{'abstract': 'Most transformer-based video encoders are limited to short '
             'temporal contexts due to their quadratic complexity. While '
             'various attempts have been made to extend this context, this has '
             'often come at the cost of both conceptual and computational '
             'complexity. We propose to instead re-purpose existing '
             'pre-trained video transformers by simply fine-tuning them to '
             'attend to memories derived non-parametrically from past '
             'activations. By leveraging redundancy reduction, our '
             'memory-consolidated vision transformer (MC-ViT) effortlessly '
             'extends its context far into the past and exhibits excellent '
             'scaling behavior when learning from longer videos. In doing so, '
             'MC-ViT sets a new state-of-the-art in long-context video '
             'understanding on EgoSchema, Perception Test, and Diving48, '
             'outperforming methods that benefit from orders of magnitude more '
             'parameters.',
 'title': 'Memory Consolidation Enables Long-Context Video Understanding',
 'url': 'https://deepmind.google/research/publications/79057/'}
2025-01-13 22:34:09,976 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/35122/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,114 - root - INFO - Scraped item: {'abstract': 'In-context learning (ICL) is one of the most powerful and most '
             'unexpected capabilities to emerge in recent transformer-based '
             'large language models (LLMs). Yet the mechanisms that underlie '
             'it are poorly understood. In this paper, we demonstrate that '
             'comparable ICL capabilities can be acquired by an alternative '
             'sequence prediction learning method using clone-structured '
             'causal graphs (CSCGs). Moreover, a key property of CSCGs is '
             'that, unlike transformer-based LLMs, they are {\\em '
             'interpretable}, which considerably simplifies the task of '
             'explaining how ICL works. Specifically, we show that it uses a '
             'combination of (a) learning template (schema) circuits for '
             'pattern completion, (b) retrieving relevant templates in a '
             'context-sensitive manner, and (c) rebinding of novel tokens to '
             'appropriate slots in the templates. We go on to marshall '
             'evidence for the hypothesis that similar mechanisms underlie ICL '
             'in LLMs. For example, we find that, with CSCGs as with LLMs, '
             'different capabilities emerge at different levels of '
             'overparameterization, suggesting that overparameterization helps '
             'in learning more complex template (schema) circuits. By showing '
             'how ICL can be achieved with small models and datasets, we open '
             'up a path to novel architectures, and take a vital step towards '
             'a more general understanding of the mechanics behind this '
             'important capability.',
 'title': 'Schema-learning and rebinding as mechanisms of in-context learning '
          'and emergence',
 'url': 'https://deepmind.google/research/publications/35122/'}
2025-01-13 22:34:10,128 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/35122/>
{'abstract': 'In-context learning (ICL) is one of the most powerful and most '
             'unexpected capabilities to emerge in recent transformer-based '
             'large language models (LLMs). Yet the mechanisms that underlie '
             'it are poorly understood. In this paper, we demonstrate that '
             'comparable ICL capabilities can be acquired by an alternative '
             'sequence prediction learning method using clone-structured '
             'causal graphs (CSCGs). Moreover, a key property of CSCGs is '
             'that, unlike transformer-based LLMs, they are {\\em '
             'interpretable}, which considerably simplifies the task of '
             'explaining how ICL works. Specifically, we show that it uses a '
             'combination of (a) learning template (schema) circuits for '
             'pattern completion, (b) retrieving relevant templates in a '
             'context-sensitive manner, and (c) rebinding of novel tokens to '
             'appropriate slots in the templates. We go on to marshall '
             'evidence for the hypothesis that similar mechanisms underlie ICL '
             'in LLMs. For example, we find that, with CSCGs as with LLMs, '
             'different capabilities emerge at different levels of '
             'overparameterization, suggesting that overparameterization helps '
             'in learning more complex template (schema) circuits. By showing '
             'how ICL can be achieved with small models and datasets, we open '
             'up a path to novel architectures, and take a vital step towards '
             'a more general understanding of the mechanics behind this '
             'important capability.',
 'title': 'Schema-learning and rebinding as mechanisms of in-context learning '
          'and emergence',
 'url': 'https://deepmind.google/research/publications/35122/'}
2025-01-13 22:34:10,203 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/33708/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,267 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/84309/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,345 - root - INFO - Scraped item: {'abstract': 'Deep neural networks have reached human-level performance on '
             'many computer vision tasks. However, the objectives used to '
             'train these networks enforce only that similar images are '
             'embedded at similar locations in the representation space, and '
             'do not directly constrain the global structure of the resulting '
             'space. Here, we explore the impact of supervising this global '
             'structure by linearly aligning it with human similarity '
             'judgments. We find that a naive approach leads to large changes '
             'in local representational structure that harm downstream '
             'performance. Thus, we propose a novel method that aligns the '
             'global structure of representations while preserving their local '
             'structure. This global-local transform considerably improves '
             'accuracy across a variety of few-shot learning and anomaly '
             'detection tasks. Our results indicate that human visual '
             'representations are globally organized in a way that facilitates '
             'learning from few examples, and incorporating this global '
             'structure into neural network representations improves '
             'performance on downstream tasks.',
 'title': 'Improving neural network representations using human similarity '
          'judgments',
 'url': 'https://deepmind.google/research/publications/33708/'}
2025-01-13 22:34:10,359 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/33708/>
{'abstract': 'Deep neural networks have reached human-level performance on '
             'many computer vision tasks. However, the objectives used to '
             'train these networks enforce only that similar images are '
             'embedded at similar locations in the representation space, and '
             'do not directly constrain the global structure of the resulting '
             'space. Here, we explore the impact of supervising this global '
             'structure by linearly aligning it with human similarity '
             'judgments. We find that a naive approach leads to large changes '
             'in local representational structure that harm downstream '
             'performance. Thus, we propose a novel method that aligns the '
             'global structure of representations while preserving their local '
             'structure. This global-local transform considerably improves '
             'accuracy across a variety of few-shot learning and anomaly '
             'detection tasks. Our results indicate that human visual '
             'representations are globally organized in a way that facilitates '
             'learning from few examples, and incorporating this global '
             'structure into neural network representations improves '
             'performance on downstream tasks.',
 'title': 'Improving neural network representations using human similarity '
          'judgments',
 'url': 'https://deepmind.google/research/publications/33708/'}
2025-01-13 22:34:10,408 - root - INFO - Scraped item: {'abstract': 'Multi-vector retrieval models such as ColBERT [Khattab and '
             'Zaharia, 2020] allow token-level interactions between queries '
             'and documents, and hence achieve state of the art on many '
             'information retrieval benchmarks. However, their non-linear '
             'scoring function cannot be scaled to millions of documents, '
             'necessitating a three-stage process for inference: retrieving '
             'initial candidates via token retrieval, accessing all token '
             'vectors, and scoring the initial candidate documents. The '
             'non-linear scoring function is applied over all token vectors of '
             'each candidate document, making the inference process '
             'complicated and slow. In this paper, we aim to simplify the '
             'multi-vector retrieval by rethinking the role of token '
             'retrieval. We present XTR, ConteXtualized Token Retriever, which '
             'introduces a simple, yet novel, objective function that '
             'encourages the model to retrieve the most important document '
             'tokens first. The improvement to token retrieval allows XTR to '
             'rank candidates only using the retrieved tokens rather than all '
             'tokens in the document, and enables a newly designed scoring '
             'stage that is two-to-three orders of magnitude\n'
             'cheaper than that of ColBERT. On the popular BEIR benchmark, XTR '
             'advances\n'
             'the state-of-the-art by 2.8 nDCG@10 without any distillation. '
             'Detailed analysis\n'
             'confirms our decision to revisit the token retrieval stage, as '
             'XTR demonstrates\n'
             'much better recall of the token retrieval stage compared to '
             'ColBERT.',
 'title': 'Rethinking the Role of Token Retrieval in  Multi-Vector Retrieval',
 'url': 'https://deepmind.google/research/publications/84309/'}
2025-01-13 22:34:10,422 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/84309/>
{'abstract': 'Multi-vector retrieval models such as ColBERT [Khattab and '
             'Zaharia, 2020] allow token-level interactions between queries '
             'and documents, and hence achieve state of the art on many '
             'information retrieval benchmarks. However, their non-linear '
             'scoring function cannot be scaled to millions of documents, '
             'necessitating a three-stage process for inference: retrieving '
             'initial candidates via token retrieval, accessing all token '
             'vectors, and scoring the initial candidate documents. The '
             'non-linear scoring function is applied over all token vectors of '
             'each candidate document, making the inference process '
             'complicated and slow. In this paper, we aim to simplify the '
             'multi-vector retrieval by rethinking the role of token '
             'retrieval. We present XTR, ConteXtualized Token Retriever, which '
             'introduces a simple, yet novel, objective function that '
             'encourages the model to retrieve the most important document '
             'tokens first. The improvement to token retrieval allows XTR to '
             'rank candidates only using the retrieved tokens rather than all '
             'tokens in the document, and enables a newly designed scoring '
             'stage that is two-to-three orders of magnitude\n'
             'cheaper than that of ColBERT. On the popular BEIR benchmark, XTR '
             'advances\n'
             'the state-of-the-art by 2.8 nDCG@10 without any distillation. '
             'Detailed analysis\n'
             'confirms our decision to revisit the token retrieval stage, as '
             'XTR demonstrates\n'
             'much better recall of the token retrieval stage compared to '
             'ColBERT.',
 'title': 'Rethinking the Role of Token Retrieval in  Multi-Vector Retrieval',
 'url': 'https://deepmind.google/research/publications/84309/'}
2025-01-13 22:34:10,429 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/33809/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,434 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48254/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,580 - root - INFO - Scraped item: {'abstract': 'Large language models have shown tremendous performance in a '
             'variety of tasks.  In-context learning is seen as one of the '
             'main contributors to their success. Previous work has '
             'demonstrated that in-context learning can even solve non-trivial '
             'tasks such as supervised and reinforcement learning. We expand '
             'on this line of work by investigating the effect of in context '
             'learning when the context is presented in a sequential manner.  '
             'We find that the sequential presentation of related tasks leads '
             'to better in-context learning performance, thereby revealing '
             'that in-context learning can be used to create better in-context '
             'learning algorithms. We coin this phenomenon '
             '\\emph{meta-in-context learning}. Multiple experiments reveal '
             'that meta-in-context learning adaptively modifies a large '
             "language model's priors over latent variables and that it "
             'adjusts its learning strategies. Finally, we extend our approach '
             'to a benchmark of real-world regression problems where we '
             'observe competitive performance to traditional learning '
             'algorithms. Taken together, our work improves our understanding '
             'of in-context learning and paves the way toward adapting large '
             'language models to the environment they are applied purely '
             'through meta-in-context learning rather than traditional '
             'fine-tuning.',
 'title': 'Meta-in-context learning in large language models',
 'url': 'https://deepmind.google/research/publications/33809/'}
2025-01-13 22:34:10,595 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/33809/>
{'abstract': 'Large language models have shown tremendous performance in a '
             'variety of tasks.  In-context learning is seen as one of the '
             'main contributors to their success. Previous work has '
             'demonstrated that in-context learning can even solve non-trivial '
             'tasks such as supervised and reinforcement learning. We expand '
             'on this line of work by investigating the effect of in context '
             'learning when the context is presented in a sequential manner.  '
             'We find that the sequential presentation of related tasks leads '
             'to better in-context learning performance, thereby revealing '
             'that in-context learning can be used to create better in-context '
             'learning algorithms. We coin this phenomenon '
             '\\emph{meta-in-context learning}. Multiple experiments reveal '
             'that meta-in-context learning adaptively modifies a large '
             "language model's priors over latent variables and that it "
             'adjusts its learning strategies. Finally, we extend our approach '
             'to a benchmark of real-world regression problems where we '
             'observe competitive performance to traditional learning '
             'algorithms. Taken together, our work improves our understanding '
             'of in-context learning and paves the way toward adapting large '
             'language models to the environment they are applied purely '
             'through meta-in-context learning rather than traditional '
             'fine-tuning.',
 'title': 'Meta-in-context learning in large language models',
 'url': 'https://deepmind.google/research/publications/33809/'}
2025-01-13 22:34:10,636 - root - INFO - Scraped item: {'abstract': 'We introduce a machine learning approach to determining the '
             'transition rates of silicon atoms on graphene (a lattice of '
             'carbon atoms), when stimulated by the electron beam of a '
             'scanning transmission electron microscope. Our learned rates are '
             'then applied to guide a single silicon atom throughout the '
             'lattice to pre-determined target destinations. We present '
             'sensitivity and accuracy analyses that demonstrate the '
             'generality of our approach.',
 'title': 'Learning Silicon Dopant Transitions in Graphene using Scanning '
          'Transmission Electron Microscopy',
 'url': 'https://deepmind.google/research/publications/48254/'}
2025-01-13 22:34:10,647 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48254/>
{'abstract': 'We introduce a machine learning approach to determining the '
             'transition rates of silicon atoms on graphene (a lattice of '
             'carbon atoms), when stimulated by the electron beam of a '
             'scanning transmission electron microscope. Our learned rates are '
             'then applied to guide a single silicon atom throughout the '
             'lattice to pre-determined target destinations. We present '
             'sensitivity and accuracy analyses that demonstrate the '
             'generality of our approach.',
 'title': 'Learning Silicon Dopant Transitions in Graphene using Scanning '
          'Transmission Electron Microscopy',
 'url': 'https://deepmind.google/research/publications/48254/'}
2025-01-13 22:34:10,652 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/66937/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,682 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34617/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,795 - root - INFO - Scraped item: {'abstract': 'We show that existing unsupervised methods on large language '
             'model (LLM) activations do not discover knowledge -- instead '
             'they seem to discover whatever feature of the activations is '
             'most prominent. The idea behind unsupervised knowledge '
             'elicitation is that knowledge satisfies a consistency structure, '
             'which can be used to discover knowledge. We first prove '
             'theoretically that arbitrary features (not just knowledge) '
             'satisfy the consistency structure of a particular leading '
             'unsupervised knowledge-elicitation method, contrast-consistent '
             'search (Burns et al., 2023). We then present a series of '
             'experiments showing  settings in which unsupervised methods '
             'result in classifiers that do not predict knowledge, but instead '
             'predict a different prominent feature. We conclude that existing '
             'unsupervised methods for discovering latent knowledge are '
             'insufficient, and we contribute sanity checks to apply to '
             'evaluating future knowledge elicitation methods. Conceptually, '
             'we hypothesise that the identification issues explored here, '
             "e.g. distinguishing a model's knowledge from that of a simulated "
             "character's, will persist for future unsupervised methods.",
 'title': 'Challenges with unsupervised LLM knowledge discovery',
 'url': 'https://deepmind.google/research/publications/66937/'}
2025-01-13 22:34:10,808 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/66937/>
{'abstract': 'We show that existing unsupervised methods on large language '
             'model (LLM) activations do not discover knowledge -- instead '
             'they seem to discover whatever feature of the activations is '
             'most prominent. The idea behind unsupervised knowledge '
             'elicitation is that knowledge satisfies a consistency structure, '
             'which can be used to discover knowledge. We first prove '
             'theoretically that arbitrary features (not just knowledge) '
             'satisfy the consistency structure of a particular leading '
             'unsupervised knowledge-elicitation method, contrast-consistent '
             'search (Burns et al., 2023). We then present a series of '
             'experiments showing  settings in which unsupervised methods '
             'result in classifiers that do not predict knowledge, but instead '
             'predict a different prominent feature. We conclude that existing '
             'unsupervised methods for discovering latent knowledge are '
             'insufficient, and we contribute sanity checks to apply to '
             'evaluating future knowledge elicitation methods. Conceptually, '
             'we hypothesise that the identification issues explored here, '
             "e.g. distinguishing a model's knowledge from that of a simulated "
             "character's, will persist for future unsupervised methods.",
 'title': 'Challenges with unsupervised LLM knowledge discovery',
 'url': 'https://deepmind.google/research/publications/66937/'}
2025-01-13 22:34:10,847 - root - INFO - Scraped item: {'abstract': 'We define an optimal preconditioning for the Langevin diffusion '
             'by analytically optimizing the expected squared jumped distance. '
             'This yields as the optimal preconditioning an inverse Fisher '
             'information covariance matrix, where the covariance matrix is '
             'computed as the outer product of log target gradients averaged '
             'under the target. We apply this result to the Metropolis '
             'adjusted Langevin algorithm (MALA) and derive a computationally '
             'efficient adaptive MCMC scheme that learns the preconditioning '
             'from the history of gradients produced as the algorithm runs. We '
             'show in several experiments that the proposed algorithm is very '
             'robust in high dimensions and significantly outperforms other '
             'methods, including a closely related adaptive MALA scheme that '
             'learns the preconditioning with standard adaptive MCMC as well '
             'as the position-dependent Riemannian manifold MALA sampler.',
 'title': 'Optimal Preconditioning and Fisher Adaptive Langevin Sampling',
 'url': 'https://deepmind.google/research/publications/34617/'}
2025-01-13 22:34:10,860 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34617/>
{'abstract': 'We define an optimal preconditioning for the Langevin diffusion '
             'by analytically optimizing the expected squared jumped distance. '
             'This yields as the optimal preconditioning an inverse Fisher '
             'information covariance matrix, where the covariance matrix is '
             'computed as the outer product of log target gradients averaged '
             'under the target. We apply this result to the Metropolis '
             'adjusted Langevin algorithm (MALA) and derive a computationally '
             'efficient adaptive MCMC scheme that learns the preconditioning '
             'from the history of gradients produced as the algorithm runs. We '
             'show in several experiments that the proposed algorithm is very '
             'robust in high dimensions and significantly outperforms other '
             'methods, including a closely related adaptive MALA scheme that '
             'learns the preconditioning with standard adaptive MCMC as well '
             'as the position-dependent Riemannian manifold MALA sampler.',
 'title': 'Optimal Preconditioning and Fisher Adaptive Langevin Sampling',
 'url': 'https://deepmind.google/research/publications/34617/'}
2025-01-13 22:34:10,865 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/33910/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:10,926 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=7> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:11,042 - root - INFO - Scraped item: {'abstract': 'In a standard view of the reinforcement learning problem, an '
             'agent’s goal is to efficiently identify a policy that maximizes '
             'long-term reward. However, this perspective is based on a '
             'restricted view of learning as finding a solution, rather than '
             'treating learning as endless adaptation. In contrast, continual '
             'reinforcement learning refers to the setting in which the best '
             'agents never stop learning. Despite the importance of continual '
             'reinforcement learning, the community lacks a simple definition '
             'of the problem that highlights its commitments and makes its '
             'primary concepts precise and clear. To this end, this paper is '
             'dedicated to carefully defining the continual reinforcement '
             'learning problem. We formalize the notion of agents that "never '
             'stop learning" through a new mathematical language for analyzing '
             'and cataloging agents. Using this new language, we define a '
             'continual learning agent as one that can be understood as '
             'carrying out an implicit search process indefinitely, and '
             'continual reinforcement learning as the setting in which the '
             'best agents are all continual learning agents. We provide two '
             'motivating examples, illustrating that traditional views of '
             'multi-task reinforcement learning and continual supervised '
             'learning are special cases of our definition. Collectively, '
             'these definitions and perspectives formalize many intuitive '
             'concepts at the heart of learning, and open new research '
             'pathways surrounding continual learning agents.',
 'title': 'A Definition of Continual Reinforcement Learning',
 'url': 'https://deepmind.google/research/publications/33910/'}
2025-01-13 22:34:11,057 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/33910/>
{'abstract': 'In a standard view of the reinforcement learning problem, an '
             'agent’s goal is to efficiently identify a policy that maximizes '
             'long-term reward. However, this perspective is based on a '
             'restricted view of learning as finding a solution, rather than '
             'treating learning as endless adaptation. In contrast, continual '
             'reinforcement learning refers to the setting in which the best '
             'agents never stop learning. Despite the importance of continual '
             'reinforcement learning, the community lacks a simple definition '
             'of the problem that highlights its commitments and makes its '
             'primary concepts precise and clear. To this end, this paper is '
             'dedicated to carefully defining the continual reinforcement '
             'learning problem. We formalize the notion of agents that "never '
             'stop learning" through a new mathematical language for analyzing '
             'and cataloging agents. Using this new language, we define a '
             'continual learning agent as one that can be understood as '
             'carrying out an implicit search process indefinitely, and '
             'continual reinforcement learning as the setting in which the '
             'best agents are all continual learning agents. We provide two '
             'motivating examples, illustrating that traditional views of '
             'multi-task reinforcement learning and continual supervised '
             'learning are special cases of our definition. Collectively, '
             'these definitions and perspectives formalize many intuitive '
             'concepts at the heart of learning, and open new research '
             'pathways surrounding continual learning agents.',
 'title': 'A Definition of Continual Reinforcement Learning',
 'url': 'https://deepmind.google/research/publications/33910/'}
2025-01-13 22:34:11,063 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=7
2025-01-13 22:34:11,425 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/32698/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:11,577 - root - INFO - Scraped item: {'abstract': 'In-context learning—the ability to configure a model’s behavior '
             'with different prompts—has revolutionized the field of natural '
             'language processing, alleviating the need for task-specific '
             'models and paving the way for generalist models capable of '
             'assisting with any query. Computer vision, in contrast, has '
             'largely stayed in the former regime: specialized decoders and '
             'finetuning protocols are generally required to perform dense '
             'tasks such as semantic segmentation and depth estimation. In '
             'this work we explore a simple mechanism for in-context learning '
             'of such scene understanding tasks: nearest neighbor retrieval '
             'from a prompt of annotated features. We propose a new '
             'pretraining protocol—leveraging attention within and across '
             'images—which yields representations particularly useful in this '
             'regime. The resulting Hummingbird model, suitably prompted, '
             'performs various scene understanding tasks without modification '
             'while approaching the performance of specialists that have been '
             'finetuned for each task. Moreover, Hummingbird can be configured '
             'to perform new tasks much more efficiently than finetuned '
             'models, raising the possibility of scene understanding in the '
             'interactive assistant regime.',
 'title': 'Towards In-context Scene Understanding',
 'url': 'https://deepmind.google/research/publications/32698/'}
2025-01-13 22:34:11,588 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/32698/>
{'abstract': 'In-context learning—the ability to configure a model’s behavior '
             'with different prompts—has revolutionized the field of natural '
             'language processing, alleviating the need for task-specific '
             'models and paving the way for generalist models capable of '
             'assisting with any query. Computer vision, in contrast, has '
             'largely stayed in the former regime: specialized decoders and '
             'finetuning protocols are generally required to perform dense '
             'tasks such as semantic segmentation and depth estimation. In '
             'this work we explore a simple mechanism for in-context learning '
             'of such scene understanding tasks: nearest neighbor retrieval '
             'from a prompt of annotated features. We propose a new '
             'pretraining protocol—leveraging attention within and across '
             'images—which yields representations particularly useful in this '
             'regime. The resulting Hummingbird model, suitably prompted, '
             'performs various scene understanding tasks without modification '
             'while approaching the performance of specialists that have been '
             'finetuned for each task. Moreover, Hummingbird can be configured '
             'to perform new tasks much more efficiently than finetuned '
             'models, raising the possibility of scene understanding in the '
             'interactive assistant regime.',
 'title': 'Towards In-context Scene Understanding',
 'url': 'https://deepmind.google/research/publications/32698/'}
2025-01-13 22:34:11,659 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/82693/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:11,674 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/33709/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:11,718 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34719/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:11,808 - root - INFO - Scraped item: {'abstract': 'Search is an important technique in program synthesis that '
             'allows for adaptive strategies such as focusing on particular '
             'search directions based on execution results. Several prior '
             'works have demonstrated that neural models are effective at '
             'guiding program synthesis searches. However, a common drawback '
             'of those approaches is the inability to handle iterative loops, '
             'higher-order functions, or lambda functions, thus limiting prior '
             'neural searches from synthesizing longer and more general '
             'programs. We address this gap by designing a search algorithm '
             'called LambdaBeam that can construct arbitrary lambda functions '
             'that compose operations within a given DSL. We create semantic '
             'vector representations of the execution behavior of the lambda '
             'functions and train a neural policy network to choose which '
             'lambdas to construct during search, and pass them as arguments '
             'to higher-order functions to perform looping computations. Our '
             'experiments show that LambdaBeam outperforms neural, symbolic, '
             'and LLM-based techniques in an integer list manipulation domain.',
 'title': 'LambdaBeam: Neural Program Search with Higher-Order Functions and '
          'Lambdas',
 'url': 'https://deepmind.google/research/publications/82693/'}
2025-01-13 22:34:11,822 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/82693/>
{'abstract': 'Search is an important technique in program synthesis that '
             'allows for adaptive strategies such as focusing on particular '
             'search directions based on execution results. Several prior '
             'works have demonstrated that neural models are effective at '
             'guiding program synthesis searches. However, a common drawback '
             'of those approaches is the inability to handle iterative loops, '
             'higher-order functions, or lambda functions, thus limiting prior '
             'neural searches from synthesizing longer and more general '
             'programs. We address this gap by designing a search algorithm '
             'called LambdaBeam that can construct arbitrary lambda functions '
             'that compose operations within a given DSL. We create semantic '
             'vector representations of the execution behavior of the lambda '
             'functions and train a neural policy network to choose which '
             'lambdas to construct during search, and pass them as arguments '
             'to higher-order functions to perform looping computations. Our '
             'experiments show that LambdaBeam outperforms neural, symbolic, '
             'and LLM-based techniques in an integer list manipulation domain.',
 'title': 'LambdaBeam: Neural Program Search with Higher-Order Functions and '
          'Lambdas',
 'url': 'https://deepmind.google/research/publications/82693/'}
2025-01-13 22:34:11,864 - root - INFO - Scraped item: {'abstract': 'What can be learned about causality and experimentation from '
             'passive data? This question is salient given recent successes of '
             'passively-trained language models in interactive domains such as '
             'tool use. Passive learning is inherently limited. However, we '
             'show that purely passive learning can in fact allow an agent to '
             'learn generalizable strategies for determining and using causal '
             'structures, as long as the agent can intervene at test time.\n'
             'We formally illustrate that learning a strategy of first '
             'experimenting, then seeking goals, can allow generalization from '
             'passive learning in principle. We then show empirically that '
             'agents trained via imitation on expert data can indeed '
             'generalize at test time to infer and use causal links which are '
             'never present in the training data; these agents can also '
             'generalize experimentation strategies to novel variable sets '
             'never observed in training. We then show that strategies for '
             'causal intervention and exploitation can be generalized from '
             'passive data even in a more complex environment with '
             'high-dimensional observations, with the support of natural '
             'language explanations. Explanations can even allow passive '
             'learners to generalize out-of-distribution from '
             'perfectly-confounded training data. Finally, we show that '
             'language models, trained only on passive next-word prediction, '
             'can generalize causal intervention strategies from a few-shot '
             'prompt containing explanations and reasoning. These results '
             'highlight the surprising power of passive learning of active '
             'causal strategies, and have implications for understanding the '
             'behaviors and capabilities of language models.',
 'title': 'Passive learning of active causal strategies in agents and language '
          'models',
 'url': 'https://deepmind.google/research/publications/33709/'}
2025-01-13 22:34:11,877 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/33709/>
{'abstract': 'What can be learned about causality and experimentation from '
             'passive data? This question is salient given recent successes of '
             'passively-trained language models in interactive domains such as '
             'tool use. Passive learning is inherently limited. However, we '
             'show that purely passive learning can in fact allow an agent to '
             'learn generalizable strategies for determining and using causal '
             'structures, as long as the agent can intervene at test time.\n'
             'We formally illustrate that learning a strategy of first '
             'experimenting, then seeking goals, can allow generalization from '
             'passive learning in principle. We then show empirically that '
             'agents trained via imitation on expert data can indeed '
             'generalize at test time to infer and use causal links which are '
             'never present in the training data; these agents can also '
             'generalize experimentation strategies to novel variable sets '
             'never observed in training. We then show that strategies for '
             'causal intervention and exploitation can be generalized from '
             'passive data even in a more complex environment with '
             'high-dimensional observations, with the support of natural '
             'language explanations. Explanations can even allow passive '
             'learners to generalize out-of-distribution from '
             'perfectly-confounded training data. Finally, we show that '
             'language models, trained only on passive next-word prediction, '
             'can generalize causal intervention strategies from a few-shot '
             'prompt containing explanations and reasoning. These results '
             'highlight the surprising power of passive learning of active '
             'causal strategies, and have implications for understanding the '
             'behaviors and capabilities of language models.',
 'title': 'Passive learning of active causal strategies in agents and language '
          'models',
 'url': 'https://deepmind.google/research/publications/33709/'}
2025-01-13 22:34:11,916 - root - INFO - Scraped item: {'abstract': 'In Reinforcement learning (RL) an agent acts so as to maximize '
             'its return under uncertainty. It is natural to apply Bayesian '
             'probabilistic inference to the uncertain parameters and, since '
             'the goal of the agent is to find the optimal policy, a relevant '
             'object of study is the posterior probability of optimality for '
             "each state-action. Previous work on `RL as inference' has "
             'equipped the agent with a surrogate potential in order to '
             'estimate this quantity, however the approximation can be '
             'arbitrarily poor, leading to algorithms that do not perform well '
             'in practice. In this work, we rigorously analyze how the '
             'posterior probability of optimality flows through the Markov '
             'decision process (MDP) and show that sampling according to this '
             'probability yields a guaranteed Bayesian regret bound. In '
             'practice computing this probability is intractable, so we derive '
             'a variational Bayesian approximation yielding a tractable convex '
             'optimization problem and show that the resulting policy also '
             'satisfies a Bayesian regret bound. We call our approach VAPOR '
             'and show that it has deep connections to Thompson sampling, '
             'K-learning, information theory, and maximum entropy exploration.',
 'title': 'Probabilistic Inference in Reinforcement Learning Done Right',
 'url': 'https://deepmind.google/research/publications/34719/'}
2025-01-13 22:34:11,929 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34719/>
{'abstract': 'In Reinforcement learning (RL) an agent acts so as to maximize '
             'its return under uncertainty. It is natural to apply Bayesian '
             'probabilistic inference to the uncertain parameters and, since '
             'the goal of the agent is to find the optimal policy, a relevant '
             'object of study is the posterior probability of optimality for '
             "each state-action. Previous work on `RL as inference' has "
             'equipped the agent with a surrogate potential in order to '
             'estimate this quantity, however the approximation can be '
             'arbitrarily poor, leading to algorithms that do not perform well '
             'in practice. In this work, we rigorously analyze how the '
             'posterior probability of optimality flows through the Markov '
             'decision process (MDP) and show that sampling according to this '
             'probability yields a guaranteed Bayesian regret bound. In '
             'practice computing this probability is intractable, so we derive '
             'a variational Bayesian approximation yielding a tractable convex '
             'optimization problem and show that the resulting policy also '
             'satisfies a Bayesian regret bound. We call our approach VAPOR '
             'and show that it has deep connections to Thompson sampling, '
             'K-learning, information theory, and maximum entropy exploration.',
 'title': 'Probabilistic Inference in Reinforcement Learning Done Right',
 'url': 'https://deepmind.google/research/publications/34719/'}
2025-01-13 22:34:12,289 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/31486/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:12,378 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34921/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:12,431 - root - INFO - Scraped item: {'abstract': 'The past few years have seen impressive progress in the '
             'development of deep generative models capable of producing '
             'high-dimensional, complex, and photo-realistic data. However, '
             'current methods for evaluating such models remain incomplete: '
             'standard likelihood-based metrics do not always apply and rarely '
             'correlate with perceptual fidelity, while sample-based metrics, '
             'such as FID, are insensitive to overfitting, i.e., inability to '
             'generalize beyond the training set. To address these '
             'limitations, we propose a new metric called the Feature '
             'Likelihood Divergence (FLD), a parametric sample-based score '
             'that uses density estimation to provide a comprehensive '
             'trichotomic evaluation accounting for novelty (i.e., different '
             'from the training samples), fidelity, and diversity of generated '
             'samples. We empirically demonstrate the ability of FLD to '
             'identify specific overfitting problem cases, where previously '
             'proposed metrics fail. We also extensively evaluate FLD on '
             'various image datasets and model classes, demonstrating its '
             'ability to match intuitions of previous metrics like FID while '
             'offering a more comprehensive evaluation of generative models. '
             'Code is available athttps://github.com/marcojira/fld.',
 'title': 'Feature Likelihood Divergence: Evaluating the Generalization of '
          'Generative Models Using Samples',
 'url': 'https://deepmind.google/research/publications/31486/'}
2025-01-13 22:34:12,445 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/31486/>
{'abstract': 'The past few years have seen impressive progress in the '
             'development of deep generative models capable of producing '
             'high-dimensional, complex, and photo-realistic data. However, '
             'current methods for evaluating such models remain incomplete: '
             'standard likelihood-based metrics do not always apply and rarely '
             'correlate with perceptual fidelity, while sample-based metrics, '
             'such as FID, are insensitive to overfitting, i.e., inability to '
             'generalize beyond the training set. To address these '
             'limitations, we propose a new metric called the Feature '
             'Likelihood Divergence (FLD), a parametric sample-based score '
             'that uses density estimation to provide a comprehensive '
             'trichotomic evaluation accounting for novelty (i.e., different '
             'from the training samples), fidelity, and diversity of generated '
             'samples. We empirically demonstrate the ability of FLD to '
             'identify specific overfitting problem cases, where previously '
             'proposed metrics fail. We also extensively evaluate FLD on '
             'various image datasets and model classes, demonstrating its '
             'ability to match intuitions of previous metrics like FID while '
             'offering a more comprehensive evaluation of generative models. '
             'Code is available athttps://github.com/marcojira/fld.',
 'title': 'Feature Likelihood Divergence: Evaluating the Generalization of '
          'Generative Models Using Samples',
 'url': 'https://deepmind.google/research/publications/31486/'}
2025-01-13 22:34:12,452 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/26234/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:12,523 - root - INFO - Scraped item: {'abstract': 'We consider online reinforcement learning (RL) in episodic '
             'Markov decision processes (MDPs) under the linear '
             '$q^\\pi$-realizability assumption, where it is assumed that the '
             'action-values of all policies can be  expressed as linear '
             'functions of state-action features. This class is known to be '
             'more general than  linear MDPs, where the transition kernel and '
             'the reward function are assumed to be linear functions of the '
             'feature vectors. As our first contribution, we show that the '
             'difference between the two classes is the presence of states in '
             'linearly $q^\\pi$-realizable MDPs where for any policy, all the '
             'actions have  approximately equal values, and skipping over '
             'these states by following an arbitrarily fixed policy in those '
             'states transforms the problem to a linear MDP. Based on this '
             'observation, we derive a novel (computationally inefficient) '
             'learning algorithm for linearly $q^\\pi$-realizable MDPs that '
             'simultaneously learns what states should be skipped over and '
             'runs another learning algorithm on the linear MDP hidden in the '
             'problem. The method returns an $\\epsilon$-optimal policy after '
             '$\\text{polylog}(H, d)/\\epsilon^2$ interactions with the MDP, '
             'where $H$ is the time horizon and $d$ is the dimension of the '
             'feature vectors, giving the first polynomial-sample-complexity '
             'online RL algorithm for this setting. The results are proved for '
             'the misspecified case, where the sample complexity is shown to '
             'degrade gracefully with the misspecification error.',
 'title': 'Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in '
          'Linear MDPs If You Learn What to Ignore',
 'url': 'https://deepmind.google/research/publications/34921/'}
2025-01-13 22:34:12,538 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34921/>
{'abstract': 'We consider online reinforcement learning (RL) in episodic '
             'Markov decision processes (MDPs) under the linear '
             '$q^\\pi$-realizability assumption, where it is assumed that the '
             'action-values of all policies can be  expressed as linear '
             'functions of state-action features. This class is known to be '
             'more general than  linear MDPs, where the transition kernel and '
             'the reward function are assumed to be linear functions of the '
             'feature vectors. As our first contribution, we show that the '
             'difference between the two classes is the presence of states in '
             'linearly $q^\\pi$-realizable MDPs where for any policy, all the '
             'actions have  approximately equal values, and skipping over '
             'these states by following an arbitrarily fixed policy in those '
             'states transforms the problem to a linear MDP. Based on this '
             'observation, we derive a novel (computationally inefficient) '
             'learning algorithm for linearly $q^\\pi$-realizable MDPs that '
             'simultaneously learns what states should be skipped over and '
             'runs another learning algorithm on the linear MDP hidden in the '
             'problem. The method returns an $\\epsilon$-optimal policy after '
             '$\\text{polylog}(H, d)/\\epsilon^2$ interactions with the MDP, '
             'where $H$ is the time horizon and $d$ is the dimension of the '
             'feature vectors, giving the first polynomial-sample-complexity '
             'online RL algorithm for this setting. The results are proved for '
             'the misspecified case, where the sample complexity is shown to '
             'degrade gracefully with the misspecification error.',
 'title': 'Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in '
          'Linear MDPs If You Learn What to Ignore',
 'url': 'https://deepmind.google/research/publications/34921/'}
2025-01-13 22:34:12,603 - root - INFO - Scraped item: {'abstract': 'Deep reinforcement learning has shown lots of success in closed, '
             'well-defined domains such as games (Chess, Go, StarCraft). The '
             'next frontier is real-world scenarios, where setups are numerous '
             'and varied. For this, agents need to learn the underlying '
             'environment dynamics, so as to robustly generalise to conditions '
             'that differ from those they were trained on. Model-based '
             'reinforcement learning algorithms, such as MuZero or Dreamer, '
             'aim to accomplish this by learning a world model. However, '
             'leveraging a world model has not yet consistently shown greater '
             'generalisation capabilities compared to model-free alternatives. '
             'In this work, we propose improving the data efficiency and '
             'generalisation capabilities of MuZero by explicitly '
             'incorporating the symmetries of the environment in its '
             'world-model architecture. We prove that, so long as the neural '
             'networks used by MuZero are equivariant to a particular symmetry '
             "group acting on the environment, the entirety of MuZero's "
             'action-selection algorithm will also be equivariant to that '
             'group. As such, Equivariant MuZero is guaranteed to behave '
             'symmetrically in symmetrically-transformed states, and will '
             'hence be more data-efficient when learning its world models. We '
             'evaluate Equivariant MuZero on procedurally-generated MiniPacman '
             'and on Chaser from the ProcGen suite: training on a set of '
             'mazes, and then testing on unseen rotated versions, '
             'demonstrating the benefits of equivariance. We verify that our '
             'improvements hold even when only some of the components of '
             'Equivariant MuZero obey strict equivariance, which highlights '
             'the robustness of our construction.',
 'title': 'Equivariant MuZero',
 'url': 'https://deepmind.google/research/publications/26234/'}
2025-01-13 22:34:12,617 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/26234/>
{'abstract': 'Deep reinforcement learning has shown lots of success in closed, '
             'well-defined domains such as games (Chess, Go, StarCraft). The '
             'next frontier is real-world scenarios, where setups are numerous '
             'and varied. For this, agents need to learn the underlying '
             'environment dynamics, so as to robustly generalise to conditions '
             'that differ from those they were trained on. Model-based '
             'reinforcement learning algorithms, such as MuZero or Dreamer, '
             'aim to accomplish this by learning a world model. However, '
             'leveraging a world model has not yet consistently shown greater '
             'generalisation capabilities compared to model-free alternatives. '
             'In this work, we propose improving the data efficiency and '
             'generalisation capabilities of MuZero by explicitly '
             'incorporating the symmetries of the environment in its '
             'world-model architecture. We prove that, so long as the neural '
             'networks used by MuZero are equivariant to a particular symmetry '
             "group acting on the environment, the entirety of MuZero's "
             'action-selection algorithm will also be equivariant to that '
             'group. As such, Equivariant MuZero is guaranteed to behave '
             'symmetrically in symmetrically-transformed states, and will '
             'hence be more data-efficient when learning its world models. We '
             'evaluate Equivariant MuZero on procedurally-generated MiniPacman '
             'and on Chaser from the ProcGen suite: training on a set of '
             'mazes, and then testing on unseen rotated versions, '
             'demonstrating the benefits of equivariance. We verify that our '
             'improvements hold even when only some of the components of '
             'Equivariant MuZero obey strict equivariance, which highlights '
             'the robustness of our construction.',
 'title': 'Equivariant MuZero',
 'url': 'https://deepmind.google/research/publications/26234/'}
2025-01-13 22:34:12,783 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48151/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:12,792 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/18457/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:12,927 - root - INFO - Scraped item: {'abstract': 'Large foundation models that incorporate language, vision, and '
             'more recently actions have revolutionized the ability to harness '
             'internet scale data to learn knowledge and reasoning for '
             'everyday tasks. In this paper we show how existing foundation '
             'models can be used to scale up the deployment of operational '
             'robots incompletely unseen scenarios with minimal human '
             'supervision.  We refer to this system as AutoRT, which runs on '
             'over 50 robots across multiple buildings, collecting 77k real '
             'robot episodes via both teleoperation and autonomously moving '
             'robots. Such “in-the-wild” data is significantly more diverse '
             'than previous robotic datasets collected in robot lab settings, '
             'and improves robotics policies when used in co-fine-tuning.  '
             'When combined with vision, large language models can propose '
             'novel instructions based on their environment and reason about '
             'autonomy tradeoffs and safety without finetuning, allowing '
             'orchestration of large scale robot fleets.  We further show how '
             'introducing LLMs and VLMs into data collection creates new forms '
             'of interaction for steering robot agents to collect more diverse '
             'data or data for specific settings.',
 'title': 'AutoRT: Embodied Foundation Models for Large Scale Orchestration of '
          'Robotic Agents',
 'url': 'https://deepmind.google/research/publications/48151/'}
2025-01-13 22:34:12,942 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48151/>
{'abstract': 'Large foundation models that incorporate language, vision, and '
             'more recently actions have revolutionized the ability to harness '
             'internet scale data to learn knowledge and reasoning for '
             'everyday tasks. In this paper we show how existing foundation '
             'models can be used to scale up the deployment of operational '
             'robots incompletely unseen scenarios with minimal human '
             'supervision.  We refer to this system as AutoRT, which runs on '
             'over 50 robots across multiple buildings, collecting 77k real '
             'robot episodes via both teleoperation and autonomously moving '
             'robots. Such “in-the-wild” data is significantly more diverse '
             'than previous robotic datasets collected in robot lab settings, '
             'and improves robotics policies when used in co-fine-tuning.  '
             'When combined with vision, large language models can propose '
             'novel instructions based on their environment and reason about '
             'autonomy tradeoffs and safety without finetuning, allowing '
             'orchestration of large scale robot fleets.  We further show how '
             'introducing LLMs and VLMs into data collection creates new forms '
             'of interaction for steering robot agents to collect more diverse '
             'data or data for specific settings.',
 'title': 'AutoRT: Embodied Foundation Models for Large Scale Orchestration of '
          'Robotic Agents',
 'url': 'https://deepmind.google/research/publications/48151/'}
2025-01-13 22:34:12,983 - root - INFO - Scraped item: {'abstract': 'Automated content filtering and moderation is an important tool '
             'that allows online platforms to build striving user communities '
             'that facilitate cooperation and prevent abuse.\n'
             'Unfortunately, resourceful actors try to bypass automated '
             'filters in a bid to post content that violate platform policies '
             'and codes of conduct.\n'
             'To reach this goal, these malicious actors obfuscate policy '
             'violating content to prevent machine learning models from '
             'reaching the correct decision.\n'
             'In this paper, we invite researchers to tackle this specific '
             'issue and present a new image benchmark.\n'
             'This benchmark, based on ImageNet, simulates the type of '
             'obfuscations created by malicious actors.\n'
             'It goes beyond ImageNet-C and ImageNet-C-Bar by proposing '
             'general, drastic, adversarial modifications that preserve the '
             'original content intent.\n'
             'It aims to tackle a more common adversarial threat than the one '
             'considered by Lp-norm bounded adversaries.\n'
             'Our hope is that this benchmark will encourage researchers to '
             'test their models and methods and try to find new approaches '
             'that are more robust to these obfuscations.',
 'title': 'Benchmarking Robustness to Adversarial Image Obfuscations',
 'url': 'https://deepmind.google/research/publications/18457/'}
2025-01-13 22:34:12,995 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/18457/>
{'abstract': 'Automated content filtering and moderation is an important tool '
             'that allows online platforms to build striving user communities '
             'that facilitate cooperation and prevent abuse.\n'
             'Unfortunately, resourceful actors try to bypass automated '
             'filters in a bid to post content that violate platform policies '
             'and codes of conduct.\n'
             'To reach this goal, these malicious actors obfuscate policy '
             'violating content to prevent machine learning models from '
             'reaching the correct decision.\n'
             'In this paper, we invite researchers to tackle this specific '
             'issue and present a new image benchmark.\n'
             'This benchmark, based on ImageNet, simulates the type of '
             'obfuscations created by malicious actors.\n'
             'It goes beyond ImageNet-C and ImageNet-C-Bar by proposing '
             'general, drastic, adversarial modifications that preserve the '
             'original content intent.\n'
             'It aims to tackle a more common adversarial threat than the one '
             'considered by Lp-norm bounded adversaries.\n'
             'Our hope is that this benchmark will encourage researchers to '
             'test their models and methods and try to find new approaches '
             'that are more robust to these obfuscations.',
 'title': 'Benchmarking Robustness to Adversarial Image Obfuscations',
 'url': 'https://deepmind.google/research/publications/18457/'}
2025-01-13 22:34:13,002 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/60675/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:13,145 - root - INFO - Scraped item: {'abstract': 'Recent work transfers large-scale image-to-text models to the '
             'video domain via shallow late temporal fusion while keeping the '
             'image encoder frozen. In contrast, we train video-first '
             'encoders, plug them into a frozen LM, and demonstrate that '
             'utilizing joint space-time attention yields improvements on '
             'benchmarks with strong temporal dependencies (e.g., YouCook2, '
             'VATEX). However, we expose two limitations to the approach: (1) '
             'decreased spatial capabilities, likely due to noisy '
             'video-language alignments and (2) higher memory consumption, '
             'bottlenecking the number of frames that can be processed. To '
             'mitigate the memory bottleneck, we systematically analyze ways '
             'to improve memory efficiency for training video-first encoders '
             'including input sampling, parameter-efficient image-to-video '
             'adaptation, and factorized attention. Surprisingly, just masking '
             'large portions of the video (up to 75%) proves to be the most '
             'robust way to scale encoders to videos up to 4.3 minutes at 1 '
             'fps rate. Our simple approach for training long video-to-text '
             'models, which account for less than 1B parameters, is able to '
             'outperform the popular paradigm of using a strong LLM as '
             'information aggregator over segment-based information on '
             'benchmarks with long range temporal dependencies (YouCook2, '
             'EgoSchema).',
 'title': 'A Simple Recipe for Contrastively Pre-training Video-First Encoders '
          'Beyond 16 Frames',
 'url': 'https://deepmind.google/research/publications/60675/'}
2025-01-13 22:34:13,159 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/60675/>
{'abstract': 'Recent work transfers large-scale image-to-text models to the '
             'video domain via shallow late temporal fusion while keeping the '
             'image encoder frozen. In contrast, we train video-first '
             'encoders, plug them into a frozen LM, and demonstrate that '
             'utilizing joint space-time attention yields improvements on '
             'benchmarks with strong temporal dependencies (e.g., YouCook2, '
             'VATEX). However, we expose two limitations to the approach: (1) '
             'decreased spatial capabilities, likely due to noisy '
             'video-language alignments and (2) higher memory consumption, '
             'bottlenecking the number of frames that can be processed. To '
             'mitigate the memory bottleneck, we systematically analyze ways '
             'to improve memory efficiency for training video-first encoders '
             'including input sampling, parameter-efficient image-to-video '
             'adaptation, and factorized attention. Surprisingly, just masking '
             'large portions of the video (up to 75%) proves to be the most '
             'robust way to scale encoders to videos up to 4.3 minutes at 1 '
             'fps rate. Our simple approach for training long video-to-text '
             'models, which account for less than 1B parameters, is able to '
             'outperform the popular paradigm of using a strong LLM as '
             'information aggregator over segment-based information on '
             'benchmarks with long range temporal dependencies (YouCook2, '
             'EgoSchema).',
 'title': 'A Simple Recipe for Contrastively Pre-training Video-First Encoders '
          'Beyond 16 Frames',
 'url': 'https://deepmind.google/research/publications/60675/'}
2025-01-13 22:34:13,212 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/22598/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:13,249 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/35829/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:13,361 - root - INFO - Scraped item: {'abstract': 'We introduce a learned weather simulator—called '
             '“GraphCast”—which outperforms the most accurate operational '
             'medium-range weather forecasting system in the world. GraphCast '
             'operates on a0.25°latitude-longitude grid, and uses graph neural '
             'networks and a novel high-resolution multi-scale mesh '
             'representation, to autoregressively predict the 10-day temporal '
             'trajectories of 227 key dynamic variables that represent the '
             'state of the atmosphere, at 6-hour time intervals. Our results '
             'show GraphCast is significantly more accurate than the European '
             'Centre for Medium-Range Weather Forecasts (ECMWF)’s '
             'deterministic forecasting system, “HRES”, on89.3%of the 2760 '
             'target variables and lead times we evaluated. It also '
             'outperforms the most accurate previous machine learning weather '
             'forecasting model on98.8%of the 252 targets it reported. '
             'GraphCast is orders of magnitude faster than ECMWF’s operational '
             'systems, and can generate a 10-day forecast (35 gigabytes on '
             'disk) in under 60 seconds on Cloud TPU hardware. Together these '
             'results represent a key step forward in improving weather '
             'modeling with machine learning, open new opportunities for fast, '
             'accurate forecasting, and help realize the promise of '
             'machine-learning based simulation in the physical sciences.',
 'title': 'GraphCast: Learned Global Weather Forecasting',
 'url': 'https://deepmind.google/research/publications/22598/'}
2025-01-13 22:34:13,376 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/22598/>
{'abstract': 'We introduce a learned weather simulator—called '
             '“GraphCast”—which outperforms the most accurate operational '
             'medium-range weather forecasting system in the world. GraphCast '
             'operates on a0.25°latitude-longitude grid, and uses graph neural '
             'networks and a novel high-resolution multi-scale mesh '
             'representation, to autoregressively predict the 10-day temporal '
             'trajectories of 227 key dynamic variables that represent the '
             'state of the atmosphere, at 6-hour time intervals. Our results '
             'show GraphCast is significantly more accurate than the European '
             'Centre for Medium-Range Weather Forecasts (ECMWF)’s '
             'deterministic forecasting system, “HRES”, on89.3%of the 2760 '
             'target variables and lead times we evaluated. It also '
             'outperforms the most accurate previous machine learning weather '
             'forecasting model on98.8%of the 252 targets it reported. '
             'GraphCast is orders of magnitude faster than ECMWF’s operational '
             'systems, and can generate a 10-day forecast (35 gigabytes on '
             'disk) in under 60 seconds on Cloud TPU hardware. Together these '
             'results represent a key step forward in improving weather '
             'modeling with machine learning, open new opportunities for fast, '
             'accurate forecasting, and help realize the promise of '
             'machine-learning based simulation in the physical sciences.',
 'title': 'GraphCast: Learned Global Weather Forecasting',
 'url': 'https://deepmind.google/research/publications/22598/'}
2025-01-13 22:34:13,417 - root - INFO - Scraped item: {'abstract': 'The ability to leverage heterogeneous robotic experience from '
             'different robots and tasks to quickly master novel skills and '
             'embodiments has the potential to transform robot learning. '
             'Inspired by recent advances in foundation models for vision and '
             'language, we propose a foundation agent for robotic '
             'manipulation. This agent, namedRoboCat, is a visual '
             'goal-conditioned decision transformer capable of consuming '
             'multi-embodiment action-labelled visual experience. This data '
             'spans a large repertoire of motor control skills from simulated '
             'and real robotic arms with varying sets of observations and '
             'actions. With RoboCat, we demonstrate the ability to generalise '
             'to new tasks and robots, both zero-shot as well as through '
             'adaptation using only 100--1000 examples for the target task. We '
             'also show how a trained model itself can be used to generate '
             'data for subsequent training iterations, thus providing a basic '
             'building block for an autonomous improvement loop. We '
             "investigate the agent's capabilities, with large-scale "
             'evaluations both in simulation and on three different real robot '
             'embodiments. We find that as we grow and diversify its training '
             'data, RoboCat not only shows signs of cross-task transfer, but '
             'also becomes more efficient at adapting to new tasks.',
 'title': 'RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation',
 'url': 'https://deepmind.google/research/publications/35829/'}
2025-01-13 22:34:13,430 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/35829/>
{'abstract': 'The ability to leverage heterogeneous robotic experience from '
             'different robots and tasks to quickly master novel skills and '
             'embodiments has the potential to transform robot learning. '
             'Inspired by recent advances in foundation models for vision and '
             'language, we propose a foundation agent for robotic '
             'manipulation. This agent, namedRoboCat, is a visual '
             'goal-conditioned decision transformer capable of consuming '
             'multi-embodiment action-labelled visual experience. This data '
             'spans a large repertoire of motor control skills from simulated '
             'and real robotic arms with varying sets of observations and '
             'actions. With RoboCat, we demonstrate the ability to generalise '
             'to new tasks and robots, both zero-shot as well as through '
             'adaptation using only 100--1000 examples for the target task. We '
             'also show how a trained model itself can be used to generate '
             'data for subsequent training iterations, thus providing a basic '
             'building block for an autonomous improvement loop. We '
             "investigate the agent's capabilities, with large-scale "
             'evaluations both in simulation and on three different real robot '
             'embodiments. We find that as we grow and diversify its training '
             'data, RoboCat not only shows signs of cross-task transfer, but '
             'also becomes more efficient at adapting to new tasks.',
 'title': 'RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation',
 'url': 'https://deepmind.google/research/publications/35829/'}
2025-01-13 22:34:13,455 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/82492/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:13,509 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/68149/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:13,521 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/63604/> (referer: https://deepmind.google/research/publications/?page=6)
2025-01-13 22:34:13,637 - root - INFO - Scraped item: {'abstract': 'Reliable automatic evaluation of summarization systems is '
             'challenging due to the multifaceted and subjective nature of the '
             'task. This is especially the case for languages other than '
             'English, where human evaluations are scarce. In this work, we '
             'introduce SEAHORSE, a dataset for multilingual, multifaceted '
             'summarization evaluation. SEAHORSE consists of 96K summaries '
             'with human ratings along 6 dimensions of text quality: '
             'comprehensibility, repetition, grammar, attribution, main ideas, '
             'and conciseness, covering 6 languages, 9 systems, and 4 '
             'datasets. As a result of its size and scope, SEAHORSE can serve '
             'both as a benchmark to evaluate learnt metrics, as well as a '
             'large-scale resource for training such metrics. We show that '
             'metrics trained with SEAHORSE achieve strong performance on the '
             'out-of-domain meta-evaluation benchmarks TRUE (Honovich et al., '
             '2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE '
             'dataset and metrics publicly available for future research on '
             'multilingual and multifaceted summarization evaluation.',
 'title': 'SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization '
          'Evaluation',
 'url': 'https://deepmind.google/research/publications/82492/'}
2025-01-13 22:34:13,652 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/82492/>
{'abstract': 'Reliable automatic evaluation of summarization systems is '
             'challenging due to the multifaceted and subjective nature of the '
             'task. This is especially the case for languages other than '
             'English, where human evaluations are scarce. In this work, we '
             'introduce SEAHORSE, a dataset for multilingual, multifaceted '
             'summarization evaluation. SEAHORSE consists of 96K summaries '
             'with human ratings along 6 dimensions of text quality: '
             'comprehensibility, repetition, grammar, attribution, main ideas, '
             'and conciseness, covering 6 languages, 9 systems, and 4 '
             'datasets. As a result of its size and scope, SEAHORSE can serve '
             'both as a benchmark to evaluate learnt metrics, as well as a '
             'large-scale resource for training such metrics. We show that '
             'metrics trained with SEAHORSE achieve strong performance on the '
             'out-of-domain meta-evaluation benchmarks TRUE (Honovich et al., '
             '2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE '
             'dataset and metrics publicly available for future research on '
             'multilingual and multifaceted summarization evaluation.',
 'title': 'SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization '
          'Evaluation',
 'url': 'https://deepmind.google/research/publications/82492/'}
2025-01-13 22:34:13,693 - root - INFO - Scraped item: {'abstract': 'A probabilistic weather forecast is critical for '
             'decision-making, from the everyday to preparation for extreme '
             'events. Forecasts of the joint distribution of weather '
             'trajectories via spatio-temporally coherent ensembles have '
             'further importance: they provide a powerful tool for '
             'decision-making in complex and high-impact domains including '
             'energy system planning, transportation routing, flood '
             'forecasting and more. State-of-the-art ML forecast models for '
             'medium-range weather, however, are largely trained to produce '
             'deterministic forecasts which lose physical consistency at '
             'longer lead times. We introduce GenCast, a ML-based generative '
             'model for ensemble weather forecasting, trained from reanalysis '
             'data. It forecasts ensembles of trajectories for hundreds of '
             'weather variables, up to 15 days at 1 degree resolution '
             'globally, using under TC secs per ensemble member. We show that '
             'GenCast is more skilful than ENS, a top operational ensemble '
             'forecast, for TC% of TC verification targets, while maintaining '
             'good calibration and physically consistent power spectra.',
 'title': 'GenCast: learning skillful ensemble forecasting of medium-range '
          'weather',
 'url': 'https://deepmind.google/research/publications/68149/'}
2025-01-13 22:34:13,706 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/68149/>
{'abstract': 'A probabilistic weather forecast is critical for '
             'decision-making, from the everyday to preparation for extreme '
             'events. Forecasts of the joint distribution of weather '
             'trajectories via spatio-temporally coherent ensembles have '
             'further importance: they provide a powerful tool for '
             'decision-making in complex and high-impact domains including '
             'energy system planning, transportation routing, flood '
             'forecasting and more. State-of-the-art ML forecast models for '
             'medium-range weather, however, are largely trained to produce '
             'deterministic forecasts which lose physical consistency at '
             'longer lead times. We introduce GenCast, a ML-based generative '
             'model for ensemble weather forecasting, trained from reanalysis '
             'data. It forecasts ensembles of trajectories for hundreds of '
             'weather variables, up to 15 days at 1 degree resolution '
             'globally, using under TC secs per ensemble member. We show that '
             'GenCast is more skilful than ENS, a top operational ensemble '
             'forecast, for TC% of TC verification targets, while maintaining '
             'good calibration and physically consistent power spectra.',
 'title': 'GenCast: learning skillful ensemble forecasting of medium-range '
          'weather',
 'url': 'https://deepmind.google/research/publications/68149/'}
2025-01-13 22:34:13,742 - root - INFO - Scraped item: {'abstract': 'While methods for monocular depth estimation have made '
             'significant strides on standard benchmarks, zero-shot metric '
             'depth estimation remains unsolved. Challenges include the joint '
             'modeling of indoor and outdoor scenes, which often exhibit '
             'significantly different distributions of RGB and depth, and the '
             'depth-scale ambiguity due to unknown camera intrinsics. Recent '
             'work has proposed specialized multi-head architectures for '
             'jointly modeling indoor and outdoor scenes. In contrast, we '
             'advocate a generic, task-agnostic diffusion model, with several '
             'advancements such as log-scale depth parameterization to enable '
             'joint modeling of indoor and outdoor scenes, conditioning on the '
             'field-of-view (FOV) to handle scale ambiguity and synthetically '
             'augmenting FOV during training to generalize beyond the limited '
             'camera intrinsics in training datasets. Furthermore, by '
             'employing a more diverse training mixture than is common, and an '
             'efficient diffusion parameterization, our method, DMD (Diffusion '
             'for Metric Depth) achieves a 25% reduction in relative error '
             '(REL) on zero-shot indoor and 33% reduction on zero-shot outdoor '
             'datasets over the current SOTA using only a small number of '
             'denoising steps.',
 'title': 'Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion '
          'Model',
 'url': 'https://deepmind.google/research/publications/63604/'}
2025-01-13 22:34:13,753 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/63604/>
{'abstract': 'While methods for monocular depth estimation have made '
             'significant strides on standard benchmarks, zero-shot metric '
             'depth estimation remains unsolved. Challenges include the joint '
             'modeling of indoor and outdoor scenes, which often exhibit '
             'significantly different distributions of RGB and depth, and the '
             'depth-scale ambiguity due to unknown camera intrinsics. Recent '
             'work has proposed specialized multi-head architectures for '
             'jointly modeling indoor and outdoor scenes. In contrast, we '
             'advocate a generic, task-agnostic diffusion model, with several '
             'advancements such as log-scale depth parameterization to enable '
             'joint modeling of indoor and outdoor scenes, conditioning on the '
             'field-of-view (FOV) to handle scale ambiguity and synthetically '
             'augmenting FOV during training to generalize beyond the limited '
             'camera intrinsics in training datasets. Furthermore, by '
             'employing a more diverse training mixture than is common, and an '
             'efficient diffusion parameterization, our method, DMD (Diffusion '
             'for Metric Depth) achieves a 25% reduction in relative error '
             '(REL) on zero-shot indoor and 33% reduction on zero-shot outdoor '
             'datasets over the current SOTA using only a small number of '
             'denoising steps.',
 'title': 'Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion '
          'Model',
 'url': 'https://deepmind.google/research/publications/63604/'}
2025-01-13 22:34:13,759 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/81988/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:13,903 - root - INFO - Scraped item: {'abstract': 'In Chinese studies, understanding the nuanced traits of '
             'historical figures, often not explicitly evident in biographical '
             'data, has been a key interest. However, identifying these traits '
             'can be challenging due to the need for domain expertise, '
             'specialist knowledge, and context-specific insights, making the '
             'process time-consuming and difficult to scale. Our focus on '
             'studying officials from China’s Ming Dynasty is no exception. To '
             'tackle this challenge, we propose MingOfficial, a large-scale '
             'multi-modal dataset consisting of both structured (career '
             'records, annotated personnel types) and text (historical texts) '
             'data for 9,376 officials. We further couple the dataset with a a '
             'graph neural network (GNN) to combine both modalities in order '
             'to allow investigation of social structures and provide features '
             'to boost down-stream tasks. Experiments show that our proposed '
             'MingOfficial could enable exploratory analysis of official '
             'identities, and also significantly boost performance in tasks '
             'such as identifying nuance identities (e.g. civil officials '
             'holding military power) from 24.6% to 98.2% F1 score in hold-out '
             'test set. By making MingOfficial publicly available (see main '
             'text for the URL) as both a dataset and an interactive tool, we '
             'aim to stimulate further research into the role of social '
             'context and representation learning in identifying individual '
             'characteristics, and hope to provide inspiration for '
             'computational approaches in other fields beyond Chinese studies.',
 'title': 'MingOfficial: A Ming Official Career Dataset and a Historical '
          'Context-Aware Representation Learning Framework',
 'url': 'https://deepmind.google/research/publications/81988/'}
2025-01-13 22:34:13,918 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/81988/>
{'abstract': 'In Chinese studies, understanding the nuanced traits of '
             'historical figures, often not explicitly evident in biographical '
             'data, has been a key interest. However, identifying these traits '
             'can be challenging due to the need for domain expertise, '
             'specialist knowledge, and context-specific insights, making the '
             'process time-consuming and difficult to scale. Our focus on '
             'studying officials from China’s Ming Dynasty is no exception. To '
             'tackle this challenge, we propose MingOfficial, a large-scale '
             'multi-modal dataset consisting of both structured (career '
             'records, annotated personnel types) and text (historical texts) '
             'data for 9,376 officials. We further couple the dataset with a a '
             'graph neural network (GNN) to combine both modalities in order '
             'to allow investigation of social structures and provide features '
             'to boost down-stream tasks. Experiments show that our proposed '
             'MingOfficial could enable exploratory analysis of official '
             'identities, and also significantly boost performance in tasks '
             'such as identifying nuance identities (e.g. civil officials '
             'holding military power) from 24.6% to 98.2% F1 score in hold-out '
             'test set. By making MingOfficial publicly available (see main '
             'text for the URL) as both a dataset and an interactive tool, we '
             'aim to stimulate further research into the role of social '
             'context and representation learning in identifying individual '
             'characteristics, and hope to provide inspiration for '
             'computational approaches in other fields beyond Chinese studies.',
 'title': 'MingOfficial: A Ming Official Career Dataset and a Historical '
          'Context-Aware Representation Learning Framework',
 'url': 'https://deepmind.google/research/publications/81988/'}
2025-01-13 22:34:14,126 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/25830/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:14,215 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/82087/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:14,269 - root - INFO - Scraped item: {'abstract': 'In both cognitive science and computer science, intelligence has '
             'traditionally been viewed solipsistically, as a property of '
             'unitary agents devoid of social context. Yet converging evidence '
             'in behavior, neuroscience and evolution shows that natural '
             'intelligence emerged at multiple scales in networks of '
             'interacting agents. For those interested in reverse-engineering '
             'intelligence, these findings suggest constraints on the space of '
             'workable algorithms. Recent breakthroughs in artificial '
             'intelligence (AI) run parallel to these findings, with specific '
             'population structures enabling agents to master complex '
             'strategic games like Capture-The-Flag and StarCraft II. We posit '
             'that moving beyond a solipsistic view of agency will benefit '
             'both cognitive science and machine learning: understanding '
             'intelligence demands a multi-agent context.',
 'title': 'No agent is an island:  A social path to human-like artificial '
          'intelligence',
 'url': 'https://deepmind.google/research/publications/25830/'}
2025-01-13 22:34:14,283 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/25830/>
{'abstract': 'In both cognitive science and computer science, intelligence has '
             'traditionally been viewed solipsistically, as a property of '
             'unitary agents devoid of social context. Yet converging evidence '
             'in behavior, neuroscience and evolution shows that natural '
             'intelligence emerged at multiple scales in networks of '
             'interacting agents. For those interested in reverse-engineering '
             'intelligence, these findings suggest constraints on the space of '
             'workable algorithms. Recent breakthroughs in artificial '
             'intelligence (AI) run parallel to these findings, with specific '
             'population structures enabling agents to master complex '
             'strategic games like Capture-The-Flag and StarCraft II. We posit '
             'that moving beyond a solipsistic view of agency will benefit '
             'both cognitive science and machine learning: understanding '
             'intelligence demands a multi-agent context.',
 'title': 'No agent is an island:  A social path to human-like artificial '
          'intelligence',
 'url': 'https://deepmind.google/research/publications/25830/'}
2025-01-13 22:34:14,354 - root - INFO - Scraped item: {'abstract': 'Spatial reasoning is a fundamental building block of human '
             'cognition, used in representing, grounding, and reasoning about '
             'physical and abstract concepts. We propose a novel benchmark '
             'focused on assessing inferential properties of statements with '
             'spatial prepositions. The benchmark includes original datasets '
             'in English and Romanian and aims to probe the limits of '
             'reasoning about spatial relations in large language models. We '
             'use prompt engineering to study the performance of two families '
             'of large language models, PaLM and GPT-3, on our benchmark. Our '
             'results show considerable variability in the performance of '
             'smaller and larger models, as well as across prompts and '
             'languages. However, none of the models reaches human '
             'performance.',
 'title': 'A Benchmark for Reasoning with Spatial Prepositions',
 'url': 'https://deepmind.google/research/publications/82087/'}
2025-01-13 22:34:14,365 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/82087/>
{'abstract': 'Spatial reasoning is a fundamental building block of human '
             'cognition, used in representing, grounding, and reasoning about '
             'physical and abstract concepts. We propose a novel benchmark '
             'focused on assessing inferential properties of statements with '
             'spatial prepositions. The benchmark includes original datasets '
             'in English and Romanian and aims to probe the limits of '
             'reasoning about spatial relations in large language models. We '
             'use prompt engineering to study the performance of two families '
             'of large language models, PaLM and GPT-3, on our benchmark. Our '
             'results show considerable variability in the performance of '
             'smaller and larger models, as well as across prompts and '
             'languages. However, none of the models reaches human '
             'performance.',
 'title': 'A Benchmark for Reasoning with Spatial Prepositions',
 'url': 'https://deepmind.google/research/publications/82087/'}
2025-01-13 22:34:14,393 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50575/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:14,431 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/44213/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:14,542 - root - INFO - Scraped item: {'abstract': 'Replaying data is a principal mechanism underlying the stability '
             'and data effi-ciency  of  off-policy  reinforcement  learning  '
             '(RL)  experiments.   We  present  aneffective  yet  simple  '
             'framework  to  extend  the  use  of  replay  data  across  '
             'experi-ments,  minimally adapting the RL engineering workflow '
             'for sizeable improve-ments in controller performance.  At its '
             'core, Replay across Experiments (RaE)involves reusing experience '
             'from previous experiments to improve exploration,bootstrap '
             'learning and ultimately obtain stronger performance.  We '
             'empiricallydemonstrate the robustness and benefits of our '
             'approach on a number of RL algo-rithms and challenging control '
             'domains spanning both locomotion and manipu-lation including '
             'sparsely rewarded tasks with egocentric vision. Furthermore, '
             'wedemonstrate how RaE can be leveraged in settings with '
             'available existing offlinedatasets to achieve state-of-the-art '
             'performance.   Finally,  through various abla-tions we '
             'demonstrate the robustness of our approach to the underlying '
             'algorithm,quality and amount of data available and various '
             'hyperparameter choices.',
 'title': 'Replay Across Experiments',
 'url': 'https://deepmind.google/research/publications/50575/'}
2025-01-13 22:34:14,601 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50575/>
{'abstract': 'Replaying data is a principal mechanism underlying the stability '
             'and data effi-ciency  of  off-policy  reinforcement  learning  '
             '(RL)  experiments.   We  present  aneffective  yet  simple  '
             'framework  to  extend  the  use  of  replay  data  across  '
             'experi-ments,  minimally adapting the RL engineering workflow '
             'for sizeable improve-ments in controller performance.  At its '
             'core, Replay across Experiments (RaE)involves reusing experience '
             'from previous experiments to improve exploration,bootstrap '
             'learning and ultimately obtain stronger performance.  We '
             'empiricallydemonstrate the robustness and benefits of our '
             'approach on a number of RL algo-rithms and challenging control '
             'domains spanning both locomotion and manipu-lation including '
             'sparsely rewarded tasks with egocentric vision. Furthermore, '
             'wedemonstrate how RaE can be leveraged in settings with '
             'available existing offlinedatasets to achieve state-of-the-art '
             'performance.   Finally,  through various abla-tions we '
             'demonstrate the robustness of our approach to the underlying '
             'algorithm,quality and amount of data available and various '
             'hyperparameter choices.',
 'title': 'Replay Across Experiments',
 'url': 'https://deepmind.google/research/publications/50575/'}
2025-01-13 22:34:14,610 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=8> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:14,668 - root - INFO - Scraped item: {'abstract': 'We introduce SODA, a self-supervised diffusion model, explored '
             'for the purpose of representation learning. The model '
             'incorporates a conditional visual encoder, which distills an '
             'input image into a compact representation, that, in turn, guides '
             "the generation of novel views of the input's content. We show "
             'that imposing a tight bottleneck between the visual encoder and '
             'the denoising decoder, in the form of a sole embedding through '
             'which they can communicate, turns diffusion models into strong '
             'and efficient representation learners, capable of capturing and '
             "predicting images' semantic properties in an unsupervised "
             'manner, as we demonstrate by attaining high performance on '
             'varied classification, reconstruction and synthesis tasks over a '
             'wide array of datasets ranging from CelebA to ShapeNet to '
             "ImageNet. Further investigation of the model's generative "
             'qualities reveals the disentangled nature of its emerging latent '
             'space, which serves as an effective interface to control and '
             'manipulate the produced outputs, so to create diverse views and '
             'variations. All in all, we aim to shed light on the exciting and '
             'promising potential of diffusion models, not only for image '
             'generation, but also for learning rich and robust '
             'representations.',
 'title': 'SODA: Bottleneck Diffusion Models for Representation Learning',
 'url': 'https://deepmind.google/research/publications/44213/'}
2025-01-13 22:34:14,681 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/44213/>
{'abstract': 'We introduce SODA, a self-supervised diffusion model, explored '
             'for the purpose of representation learning. The model '
             'incorporates a conditional visual encoder, which distills an '
             'input image into a compact representation, that, in turn, guides '
             "the generation of novel views of the input's content. We show "
             'that imposing a tight bottleneck between the visual encoder and '
             'the denoising decoder, in the form of a sole embedding through '
             'which they can communicate, turns diffusion models into strong '
             'and efficient representation learners, capable of capturing and '
             "predicting images' semantic properties in an unsupervised "
             'manner, as we demonstrate by attaining high performance on '
             'varied classification, reconstruction and synthesis tasks over a '
             'wide array of datasets ranging from CelebA to ShapeNet to '
             "ImageNet. Further investigation of the model's generative "
             'qualities reveals the disentangled nature of its emerging latent '
             'space, which serves as an effective interface to control and '
             'manipulate the produced outputs, so to create diverse views and '
             'variations. All in all, we aim to shed light on the exciting and '
             'promising potential of diffusion models, not only for image '
             'generation, but also for learning rich and robust '
             'representations.',
 'title': 'SODA: Bottleneck Diffusion Models for Representation Learning',
 'url': 'https://deepmind.google/research/publications/44213/'}
2025-01-13 22:34:14,737 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=8
2025-01-13 22:34:14,881 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34920/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:14,908 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/64717/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,022 - root - INFO - Scraped item: {'abstract': 'The emergence of powerful pre-trained AI systems with '
             'super-human capabilities across a diverse and ever-increasing '
             'set of complex domains has raised  a critical challenge for AI '
             'safety as tasks can become too complicated for humans to judge '
             'directly.\n'
             'AI safety via debate [Irving et al. 2018] is a notable proposal '
             'in this direction with the goal of pitting the power of such AI '
             'models against each other until the (mis)-alignment '
             'identification problem is broken down into a manageable '
             'sub-task. While the promise of this approach is clear, the '
             'original framework was based on the assumption that the honest '
             'strategy\n'
             'is able to simulatedeterministicAI systems for '
             'anexponentialnumber of steps, limiting its applicability. In '
             'this paper, we show how to address these challenges by designing '
             'a new set of debate protocols where the honest strategy can '
             'always succeed using a simulation of apolynomialnumber of steps, '
             'whilst being able to verify the alignment ofstochasticAI '
             'systems, even when the dishonest strategy is allowed to use '
             'exponentially many simulation steps.',
 'title': 'Scalable AI Safety via Doubly-Efficient Debate',
 'url': 'https://deepmind.google/research/publications/34920/'}
2025-01-13 22:34:15,035 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34920/>
{'abstract': 'The emergence of powerful pre-trained AI systems with '
             'super-human capabilities across a diverse and ever-increasing '
             'set of complex domains has raised  a critical challenge for AI '
             'safety as tasks can become too complicated for humans to judge '
             'directly.\n'
             'AI safety via debate [Irving et al. 2018] is a notable proposal '
             'in this direction with the goal of pitting the power of such AI '
             'models against each other until the (mis)-alignment '
             'identification problem is broken down into a manageable '
             'sub-task. While the promise of this approach is clear, the '
             'original framework was based on the assumption that the honest '
             'strategy\n'
             'is able to simulatedeterministicAI systems for '
             'anexponentialnumber of steps, limiting its applicability. In '
             'this paper, we show how to address these challenges by designing '
             'a new set of debate protocols where the honest strategy can '
             'always succeed using a simulation of apolynomialnumber of steps, '
             'whilst being able to verify the alignment ofstochasticAI '
             'systems, even when the dishonest strategy is allowed to use '
             'exponentially many simulation steps.',
 'title': 'Scalable AI Safety via Doubly-Efficient Debate',
 'url': 'https://deepmind.google/research/publications/34920/'}
2025-01-13 22:34:15,041 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/61281/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,082 - root - INFO - Scraped item: {'abstract': 'Agent-based modeling has been around for decades, and applied '
             'widely across the social and natural sciences. The scope of this '
             'research method is now poised to grow dramatically as it absorbs '
             'the new affordances provided by Large Language Models (LLM)s. '
             'Generative Agent-Based Models (GABM) are not just classic '
             'Agent-Based Models (ABM)s where the agents talk to one another. '
             'Rather, GABMs are constructed using an LLM to apply common sense '
             'to situations, act "reasonably", recall common semantic '
             'knowledge, produce API calls to control digital technologies '
             'like apps, and communicate both within the simulation and to '
             'researchers viewing it from the outside. Here we present '
             'Concordia, a library to facilitate constructing and working with '
             'GABMs. Concordia makes it easy to construct language-mediated '
             'simulations of physically- or digitally-grounded environments. '
             'Concordia agents produce their behavior using a flexible '
             'component system which mediates between two fundamental '
             'operations: LLM calls and associative memory retrieval. A '
             'special agent called the Game Master (GM), which was inspired by '
             'tabletop role-playing games, is responsible for simulating the '
             'environment where the agents interact. Agents take actions by '
             'describing what they want to do in natural language. The GM then '
             'translates their actions into appropriate implementations. In a '
             'simulated physical world, the GM checks the physical '
             'plausibility of agent actions and describes their effects. In '
             'digital environments simulating technologies such as apps and '
             'services, the GM may handle API calls to integrate with external '
             'tools such as general AI assistants (e.g., Bard, ChatGPT), and '
             'digital apps (e.g., Calendar, Email, Search, etc.). Concordia '
             'was designed to support a wide array of applications both in '
             'scientific research and for evaluating performance of real '
             'digital services by simulating users and/or generating synthetic '
             'data.',
 'title': 'Generative agent-based modeling with actions grounded in physical, '
          'social, or digital space using Concordia',
 'url': 'https://deepmind.google/research/publications/64717/'}
2025-01-13 22:34:15,095 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/64717/>
{'abstract': 'Agent-based modeling has been around for decades, and applied '
             'widely across the social and natural sciences. The scope of this '
             'research method is now poised to grow dramatically as it absorbs '
             'the new affordances provided by Large Language Models (LLM)s. '
             'Generative Agent-Based Models (GABM) are not just classic '
             'Agent-Based Models (ABM)s where the agents talk to one another. '
             'Rather, GABMs are constructed using an LLM to apply common sense '
             'to situations, act "reasonably", recall common semantic '
             'knowledge, produce API calls to control digital technologies '
             'like apps, and communicate both within the simulation and to '
             'researchers viewing it from the outside. Here we present '
             'Concordia, a library to facilitate constructing and working with '
             'GABMs. Concordia makes it easy to construct language-mediated '
             'simulations of physically- or digitally-grounded environments. '
             'Concordia agents produce their behavior using a flexible '
             'component system which mediates between two fundamental '
             'operations: LLM calls and associative memory retrieval. A '
             'special agent called the Game Master (GM), which was inspired by '
             'tabletop role-playing games, is responsible for simulating the '
             'environment where the agents interact. Agents take actions by '
             'describing what they want to do in natural language. The GM then '
             'translates their actions into appropriate implementations. In a '
             'simulated physical world, the GM checks the physical '
             'plausibility of agent actions and describes their effects. In '
             'digital environments simulating technologies such as apps and '
             'services, the GM may handle API calls to integrate with external '
             'tools such as general AI assistants (e.g., Bard, ChatGPT), and '
             'digital apps (e.g., Calendar, Email, Search, etc.). Concordia '
             'was designed to support a wide array of applications both in '
             'scientific research and for evaluating performance of real '
             'digital services by simulating users and/or generating synthetic '
             'data.',
 'title': 'Generative agent-based modeling with actions grounded in physical, '
          'social, or digital space using Concordia',
 'url': 'https://deepmind.google/research/publications/64717/'}
2025-01-13 22:34:15,102 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50879/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,118 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/63806/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,192 - root - INFO - Scraped item: {'abstract': 'We present an innovative approach to infer semantic concepts '
             'from input images using a pre-trained image diffusion model. '
             'Traditionally employed for generating images, we repurpose this '
             'model to learn semantically consistent key points across diverse '
             'image datasets. Our method involves adding noise to the input '
             'image, simulating the denoising process, and subsequently '
             'extracting the attention maps. From these attention maps, we '
             'select the k sharpest ones, subjecting them to further '
             'sharpening to enhance precision. Additionally, we introduce an '
             'equivariance constraint ensuring that the learned key points '
             'remain consistent even under various image transformations. '
             'Notably, our approach demonstrates superior performance over '
             'competing methods, particularly excelling in non-aligned data, '
             'showcasing its potential in accurately identifying and retaining '
             'semantically meaningful key points across images.',
 'title': 'Unsupervised Keypoints with Stable Diffusion',
 'url': 'https://deepmind.google/research/publications/61281/'}
2025-01-13 22:34:15,204 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/61281/>
{'abstract': 'We present an innovative approach to infer semantic concepts '
             'from input images using a pre-trained image diffusion model. '
             'Traditionally employed for generating images, we repurpose this '
             'model to learn semantically consistent key points across diverse '
             'image datasets. Our method involves adding noise to the input '
             'image, simulating the denoising process, and subsequently '
             'extracting the attention maps. From these attention maps, we '
             'select the k sharpest ones, subjecting them to further '
             'sharpening to enhance precision. Additionally, we introduce an '
             'equivariance constraint ensuring that the learned key points '
             'remain consistent even under various image transformations. '
             'Notably, our approach demonstrates superior performance over '
             'competing methods, particularly excelling in non-aligned data, '
             'showcasing its potential in accurately identifying and retaining '
             'semantically meaningful key points across images.',
 'title': 'Unsupervised Keypoints with Stable Diffusion',
 'url': 'https://deepmind.google/research/publications/61281/'}
2025-01-13 22:34:15,244 - root - INFO - Scraped item: {'abstract': 'Self-consistency with chain-of-thought prompting (CoT) has '
             'demonstrated remarkable performance gain on various reasoning '
             'tasks, by utilizing multiple reasoning paths sampled by the '
             'model. However, self-consistency relies on the answer extraction '
             'process to aggregate multiple solutions, which is not applicable '
             'to free-form answers. In this work, we propose Universal '
             'Self-Consistency (USC), which leverages the large language model '
             '(LLM) to select the most consistent solution among multiple '
             'candidates. We evaluate USC on a variety of benchmarks, '
             'including mathematical reasoning, long-context summarization, '
             'and open-ended question answering. On mathematical reasoning '
             'benchmarks including GSM8K and MATH, USC matches the standard '
             'self-consistency performance without requiring the answer '
             'formats to be similar. Meanwhile, USC consistently improves the '
             'performance over greedy decoding on open-ended generation tasks.',
 'title': 'Universal Self-Consistency with Large Language Models',
 'url': 'https://deepmind.google/research/publications/50879/'}
2025-01-13 22:34:15,256 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50879/>
{'abstract': 'Self-consistency with chain-of-thought prompting (CoT) has '
             'demonstrated remarkable performance gain on various reasoning '
             'tasks, by utilizing multiple reasoning paths sampled by the '
             'model. However, self-consistency relies on the answer extraction '
             'process to aggregate multiple solutions, which is not applicable '
             'to free-form answers. In this work, we propose Universal '
             'Self-Consistency (USC), which leverages the large language model '
             '(LLM) to select the most consistent solution among multiple '
             'candidates. We evaluate USC on a variety of benchmarks, '
             'including mathematical reasoning, long-context summarization, '
             'and open-ended question answering. On mathematical reasoning '
             'benchmarks including GSM8K and MATH, USC matches the standard '
             'self-consistency performance without requiring the answer '
             'formats to be similar. Meanwhile, USC consistently improves the '
             'performance over greedy decoding on open-ended generation tasks.',
 'title': 'Universal Self-Consistency with Large Language Models',
 'url': 'https://deepmind.google/research/publications/50879/'}
2025-01-13 22:34:15,299 - root - INFO - Scraped item: {'abstract': 'Existing algorithms for reinforcement learning from human '
             'feedback (RLHF) can incentivize responses at odds with '
             'preferences because they are based on models that assume '
             'independence of irrelevant alternatives (IIA).  The perverse '
             'incentives induced by IIA hinder innovations on query formats '
             'and learning algorithms.',
 'title': 'RLHF and IIA: Perverse Incentives',
 'url': 'https://deepmind.google/research/publications/63806/'}
2025-01-13 22:34:15,310 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/63806/>
{'abstract': 'Existing algorithms for reinforcement learning from human '
             'feedback (RLHF) can incentivize responses at odds with '
             'preferences because they are based on models that assume '
             'independence of irrelevant alternatives (IIA).  The perverse '
             'incentives induced by IIA hinder innovations on query formats '
             'and learning algorithms.',
 'title': 'RLHF and IIA: Perverse Incentives',
 'url': 'https://deepmind.google/research/publications/63806/'}
2025-01-13 22:34:15,469 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/61180/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,610 - root - INFO - Scraped item: {'abstract': 'We show how Neural Field training can be accelerated by '
             'efficiently choosing where to sample. While Neural Fields have '
             'recently become popular, it is often trained by uniformly '
             'randomly sampling the training domain, or through handcrafted '
             'heuristics. In this work, we show that improved convergence and '
             'final training quality can be achieved by smarter sampling. '
             'Specifically, we propose a sampling scheme based on Langevin '
             'Monte-Carlo sampling that focuses our training samples in the '
             'domain where it actually matters.',
 'title': 'Accelerating Neural Field Training via Langevin Monte-Carlo '
          'Sampling',
 'url': 'https://deepmind.google/research/publications/61180/'}
2025-01-13 22:34:15,621 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/61180/>
{'abstract': 'We show how Neural Field training can be accelerated by '
             'efficiently choosing where to sample. While Neural Fields have '
             'recently become popular, it is often trained by uniformly '
             'randomly sampling the training domain, or through handcrafted '
             'heuristics. In this work, we show that improved convergence and '
             'final training quality can be achieved by smarter sampling. '
             'Specifically, we propose a sampling scheme based on Langevin '
             'Monte-Carlo sampling that focuses our training samples in the '
             'domain where it actually matters.',
 'title': 'Accelerating Neural Field Training via Langevin Monte-Carlo '
          'Sampling',
 'url': 'https://deepmind.google/research/publications/61180/'}
2025-01-13 22:34:15,795 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/49871/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,799 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/53605/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,867 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/37041/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,903 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/42395/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:15,988 - root - INFO - Scraped item: {'abstract': 'We revisit dynamic evaluation, the idea of online adapting the '
             'parameters of a language model with gradient descent on a given '
             'sequence of test tokens.\n'
             'While it is generally known that adapting the parameters at '
             'test-time improves the overall predictive performance, we pay '
             'particular attention to the\n'
             'speed of adaptation (in terms of sample efficiency) and '
             'computational overhead for performing gradient computation and '
             'parameter updates.',
 'title': 'Revisiting Dynamic Evaluation:Online Adaptation for LLMs',
 'url': 'https://deepmind.google/research/publications/49871/'}
2025-01-13 22:34:16,000 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/49871/>
{'abstract': 'We revisit dynamic evaluation, the idea of online adapting the '
             'parameters of a language model with gradient descent on a given '
             'sequence of test tokens.\n'
             'While it is generally known that adapting the parameters at '
             'test-time improves the overall predictive performance, we pay '
             'particular attention to the\n'
             'speed of adaptation (in terms of sample efficiency) and '
             'computational overhead for performing gradient computation and '
             'parameter updates.',
 'title': 'Revisiting Dynamic Evaluation:Online Adaptation for LLMs',
 'url': 'https://deepmind.google/research/publications/49871/'}
2025-01-13 22:34:16,044 - root - INFO - Scraped item: {'abstract': 'We study the problem of planning under model uncertainty in an '
             'online meta-reinforcement learning (RL) setting where an agent '
             'is presented with a sequence of related tasks with limited '
             'interactions per task. The agent can use its experience in each '
             'task \\emph{and} across tasks to estimate both the transition '
             'model and the distribution over tasks. We propose an algorithm '
             'to meta-learn the underlying relatedness across tasks, utilize '
             'it to plan in each task, and upper-bound the regret of the '
             'planning loss. Our bound suggests that the average regret over '
             'tasks decreases as the number of tasks increases and as the '
             'tasks are more similar. In the classical single-task setting, it '
             'is known that the planning horizon should depend on the '
             "estimated model's accuracy, that is, on the number of samples "
             'within task. We generalize this finding to meta-RL and study '
             'this dependence of planning horizon on the number of tasks. '
             'Based on our theoretical findings, we derive heuristics for '
             'selecting slowly increasing discount factors, and validate its '
             'significance empirically.',
 'title': 'POMRL: No-Regret Learning-to-Plan with IncreasingHorizons',
 'url': 'https://deepmind.google/research/publications/53605/'}
2025-01-13 22:34:16,055 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/53605/>
{'abstract': 'We study the problem of planning under model uncertainty in an '
             'online meta-reinforcement learning (RL) setting where an agent '
             'is presented with a sequence of related tasks with limited '
             'interactions per task. The agent can use its experience in each '
             'task \\emph{and} across tasks to estimate both the transition '
             'model and the distribution over tasks. We propose an algorithm '
             'to meta-learn the underlying relatedness across tasks, utilize '
             'it to plan in each task, and upper-bound the regret of the '
             'planning loss. Our bound suggests that the average regret over '
             'tasks decreases as the number of tasks increases and as the '
             'tasks are more similar. In the classical single-task setting, it '
             'is known that the planning horizon should depend on the '
             "estimated model's accuracy, that is, on the number of samples "
             'within task. We generalize this finding to meta-RL and study '
             'this dependence of planning horizon on the number of tasks. '
             'Based on our theoretical findings, we derive heuristics for '
             'selecting slowly increasing discount factors, and validate its '
             'significance empirically.',
 'title': 'POMRL: No-Regret Learning-to-Plan with IncreasingHorizons',
 'url': 'https://deepmind.google/research/publications/53605/'}
2025-01-13 22:34:16,062 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/83506/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:16,103 - root - INFO - Scraped item: {'abstract': 'Semantic segmentation datasets often exhibit two types of '
             'imbalance: class imbalance, where some classes appear more '
             'frequently than others and size imbalance, where some objects '
             'occupy more pixels than others. This causes traditional '
             'evaluation metrics to be biased towards majority classes (e.g. '
             'overall pixel-wise accuracy) and large objects (e.g. mean '
             'pixel-wise accuracy and per-dataset mean intersection over '
             'union). To address these shortcomings, we propose the use of '
             'fine-grained mIoUs along with corresponding worst-case metrics, '
             'thereby offering a more holistic evaluation of segmentation '
             'techniques. These fine-grained metrics offer less bias towards '
             'large objects, richer statistical information, and valuable '
             'insights into model and dataset auditing. Furthermore, we '
             'undertake an extensive benchmark study, where we train and '
             'evaluate 15 modern neural networks with the proposed metrics on '
             '12 diverse natural and aerial segmentation datasets. Our '
             'benchmark study highlights the necessity of not basing '
             'evaluations on a single metric and confirms that fine-grained '
             'mIoUs reduce the bias towards large objects. Moreover, we '
             'identify the crucial role played by architecture designs and '
             'loss functions, which lead to best practices in optimizing '
             'fine-grained metrics. The code is available '
             'athttps://github.com/zifuwanggg/JDTLosses.',
 'title': 'Optimization and Evaluation of Fine-grained Jaccard Indexes for '
          'Semantic Segmentation',
 'url': 'https://deepmind.google/research/publications/37041/'}
2025-01-13 22:34:16,114 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/37041/>
{'abstract': 'Semantic segmentation datasets often exhibit two types of '
             'imbalance: class imbalance, where some classes appear more '
             'frequently than others and size imbalance, where some objects '
             'occupy more pixels than others. This causes traditional '
             'evaluation metrics to be biased towards majority classes (e.g. '
             'overall pixel-wise accuracy) and large objects (e.g. mean '
             'pixel-wise accuracy and per-dataset mean intersection over '
             'union). To address these shortcomings, we propose the use of '
             'fine-grained mIoUs along with corresponding worst-case metrics, '
             'thereby offering a more holistic evaluation of segmentation '
             'techniques. These fine-grained metrics offer less bias towards '
             'large objects, richer statistical information, and valuable '
             'insights into model and dataset auditing. Furthermore, we '
             'undertake an extensive benchmark study, where we train and '
             'evaluate 15 modern neural networks with the proposed metrics on '
             '12 diverse natural and aerial segmentation datasets. Our '
             'benchmark study highlights the necessity of not basing '
             'evaluations on a single metric and confirms that fine-grained '
             'mIoUs reduce the bias towards large objects. Moreover, we '
             'identify the crucial role played by architecture designs and '
             'loss functions, which lead to best practices in optimizing '
             'fine-grained metrics. The code is available '
             'athttps://github.com/zifuwanggg/JDTLosses.',
 'title': 'Optimization and Evaluation of Fine-grained Jaccard Indexes for '
          'Semantic Segmentation',
 'url': 'https://deepmind.google/research/publications/37041/'}
2025-01-13 22:34:16,154 - root - INFO - Scraped item: {'abstract': 'We propose a novel algorithmic framework for distributional '
             'reinforcement learn-ing,  based  on  learning  '
             'finite-dimensional  mean  embeddings  of  return  '
             'distribu-tions. We derive several new algorithms for dynamic '
             'programming and temporal-difference learning based on this '
             'framework, provide asymptotic convergence the-ory, and examine '
             'the empirical performance of the algorithms on a suite of '
             'tabulartasks.   Further,  we show that this approach can be '
             'straightforwardly combinedwith deep reinforcement learning, and '
             'obtain a new deep RL agent that improvesover baseline '
             'distributional approaches on the Arcade Learning Environment.',
 'title': 'Distributional Bellman Operators over Mean-embeddings',
 'url': 'https://deepmind.google/research/publications/42395/'}
2025-01-13 22:34:16,165 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/42395/>
{'abstract': 'We propose a novel algorithmic framework for distributional '
             'reinforcement learn-ing,  based  on  learning  '
             'finite-dimensional  mean  embeddings  of  return  '
             'distribu-tions. We derive several new algorithms for dynamic '
             'programming and temporal-difference learning based on this '
             'framework, provide asymptotic convergence the-ory, and examine '
             'the empirical performance of the algorithms on a suite of '
             'tabulartasks.   Further,  we show that this approach can be '
             'straightforwardly combinedwith deep reinforcement learning, and '
             'obtain a new deep RL agent that improvesover baseline '
             'distributional approaches on the Arcade Learning Environment.',
 'title': 'Distributional Bellman Operators over Mean-embeddings',
 'url': 'https://deepmind.google/research/publications/42395/'}
2025-01-13 22:34:16,204 - root - INFO - Scraped item: {'abstract': 'Understanding which concepts models can and cannot represent has '
             'been fundamental to many tasks: from effective and responsible '
             'use of models to detecting out of distribution data. We '
             'introduce Gaussian process probes (GPP), a unified and simple '
             'framework for probing and measuring uncertainty about concepts '
             'represented by models. As a Bayesian extension of linear probing '
             'methods, GPP asks what kind of distribution over classifiers (of '
             'concepts) is induced by the model. This distribution can be used '
             'to measure both what the model represents and how confident the '
             'probe is about what the model represents. GPP can be applied to '
             'any pre-trained model with vector representations of inputs '
             '(e.g., activations). It does not require access to training '
             'data, gradients, or the architecture. We validate GPP on '
             'datasets containing both synthetic and real images. Our '
             "experiments show it can (1) probe a model's representations of "
             'concepts even with a very small number of examples, (2) '
             'accurately measure both epistemic uncertainty (how confident the '
             'probe is) and aleatory uncertainty (how fuzzy the concepts are '
             'to the model), and (3) detect out of distribution data using '
             'those uncertainty measures as well as classic methods do. By '
             'using Gaussian processes to expand what probing can offer, GPP '
             'provides a data-efficient, versatile and uncertainty-aware tool '
             'for understanding and evaluating the capabilities of machine '
             'learning models.',
 'title': 'Gaussian Process Probes (GPP) for Uncertainty-Aware Probing',
 'url': 'https://deepmind.google/research/publications/83506/'}
2025-01-13 22:34:16,215 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/83506/>
{'abstract': 'Understanding which concepts models can and cannot represent has '
             'been fundamental to many tasks: from effective and responsible '
             'use of models to detecting out of distribution data. We '
             'introduce Gaussian process probes (GPP), a unified and simple '
             'framework for probing and measuring uncertainty about concepts '
             'represented by models. As a Bayesian extension of linear probing '
             'methods, GPP asks what kind of distribution over classifiers (of '
             'concepts) is induced by the model. This distribution can be used '
             'to measure both what the model represents and how confident the '
             'probe is about what the model represents. GPP can be applied to '
             'any pre-trained model with vector representations of inputs '
             '(e.g., activations). It does not require access to training '
             'data, gradients, or the architecture. We validate GPP on '
             'datasets containing both synthetic and real images. Our '
             "experiments show it can (1) probe a model's representations of "
             'concepts even with a very small number of examples, (2) '
             'accurately measure both epistemic uncertainty (how confident the '
             'probe is) and aleatory uncertainty (how fuzzy the concepts are '
             'to the model), and (3) detect out of distribution data using '
             'those uncertainty measures as well as classic methods do. By '
             'using Gaussian processes to expand what probing can offer, GPP '
             'provides a data-efficient, versatile and uncertainty-aware tool '
             'for understanding and evaluating the capabilities of machine '
             'learning models.',
 'title': 'Gaussian Process Probes (GPP) for Uncertainty-Aware Probing',
 'url': 'https://deepmind.google/research/publications/83506/'}
2025-01-13 22:34:16,221 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/82494/> (referer: https://deepmind.google/research/publications/?page=7)
2025-01-13 22:34:16,368 - root - INFO - Scraped item: {'abstract': 'In value-based deep reinforcement learning with replay memories, '
             'the batch size parameter specifies how many transitions to '
             'sample for each gradient update. Although critical to the '
             'learning process, this value is typically not adjusted when '
             'proposing new algorithms. In this work we present a broad '
             'empirical study that suggests reducing the batch size can result '
             'in a number of significant performance gains; this is '
             'surprising, as the general tendency when training neural '
             'networks is towards larger batch sizes for improved performance. '
             'We complement our experimental findings with a set of empirical '
             'analyses towards better understanding this phenomenon.',
 'title': 'Small batch deep reinforcement learning',
 'url': 'https://deepmind.google/research/publications/82494/'}
2025-01-13 22:34:16,380 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/82494/>
{'abstract': 'In value-based deep reinforcement learning with replay memories, '
             'the batch size parameter specifies how many transitions to '
             'sample for each gradient update. Although critical to the '
             'learning process, this value is typically not adjusted when '
             'proposing new algorithms. In this work we present a broad '
             'empirical study that suggests reducing the batch size can result '
             'in a number of significant performance gains; this is '
             'surprising, as the general tendency when training neural '
             'networks is towards larger batch sizes for improved performance. '
             'We complement our experimental findings with a set of empirical '
             'analyses towards better understanding this phenomenon.',
 'title': 'Small batch deep reinforcement learning',
 'url': 'https://deepmind.google/research/publications/82494/'}
2025-01-13 22:34:16,624 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/22497/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:16,679 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/5642/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:16,698 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/24720/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:16,779 - root - INFO - Scraped item: {'abstract': 'Progress in fields of machine learning and adversarial planning '
             'has benefited significantly from bench-mark domains, from '
             'Checkers and Chess, the classic UCI data sets and Netflix '
             'challenge to BLEU,Atari,  Go,  Poker,  Starcraft,  Dota2,  and  '
             'Diplomacy.   In sequential decision-making,  agent eval-uation  '
             'has  largely  been  restricted  to  very  few  interactions  '
             'against  experts,  declaring  victory  upon reaching  some  '
             'desired  level  of  performance  (e.g.human  professional).    '
             'In  this  paper,  we  propose a benchmark for multiagent '
             'learning based on repeated play of the simple game Rock, Paper, '
             'Scissors along with a population of forty-three  tournament '
             'entries,  some of which are (intentionally)sub-optimal.   We '
             'describe metrics to measure the quality of  agents  based  both  '
             'on  average  returns and exploitability.   We then show that '
             'several re-cent RL and online learning approaches can learng ood '
             'counter-strategies and generalize well, but ultimately lose to '
             'the top-performing bots,  creating an opportunity for research '
             'in multiagent learning.',
 'title': 'Population-based Evaluation in Repeated Rock-Paper-Scissors as a '
          'Benchmark for Multiagent Reinforcement Learning',
 'url': 'https://deepmind.google/research/publications/22497/'}
2025-01-13 22:34:16,792 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/22497/>
{'abstract': 'Progress in fields of machine learning and adversarial planning '
             'has benefited significantly from bench-mark domains, from '
             'Checkers and Chess, the classic UCI data sets and Netflix '
             'challenge to BLEU,Atari,  Go,  Poker,  Starcraft,  Dota2,  and  '
             'Diplomacy.   In sequential decision-making,  agent eval-uation  '
             'has  largely  been  restricted  to  very  few  interactions  '
             'against  experts,  declaring  victory  upon reaching  some  '
             'desired  level  of  performance  (e.g.human  professional).    '
             'In  this  paper,  we  propose a benchmark for multiagent '
             'learning based on repeated play of the simple game Rock, Paper, '
             'Scissors along with a population of forty-three  tournament '
             'entries,  some of which are (intentionally)sub-optimal.   We '
             'describe metrics to measure the quality of  agents  based  both  '
             'on  average  returns and exploitability.   We then show that '
             'several re-cent RL and online learning approaches can learng ood '
             'counter-strategies and generalize well, but ultimately lose to '
             'the top-performing bots,  creating an opportunity for research '
             'in multiagent learning.',
 'title': 'Population-based Evaluation in Repeated Rock-Paper-Scissors as a '
          'Benchmark for Multiagent Reinforcement Learning',
 'url': 'https://deepmind.google/research/publications/22497/'}
2025-01-13 22:34:16,844 - root - INFO - Scraped item: {'abstract': 'We study the connection between gradient-based meta-learning and '
             'convex optimisation. We observe that gradient descent with '
             'momentum is a special case of meta-gradients, and building on '
             'recent results in optimisation, we prove convergence rates for '
             'meta learning in the single task setting. While a meta-learned '
             'update rule can yield faster convergence up to constant factor, '
             'it is not sufficient for acceleration. Instead, some form of '
             'optimism is required. We show that optimism in meta-learning can '
             'be captured through the recently proposed Bootstrapped '
             'Meta-Gradient (Flennerhag et. al., 2022) method, providing '
             'deeper insight into its underlying mechanics.',
 'title': 'Optimistic Meta-Gradients',
 'url': 'https://deepmind.google/research/publications/5642/'}
2025-01-13 22:34:16,855 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/5642/>
{'abstract': 'We study the connection between gradient-based meta-learning and '
             'convex optimisation. We observe that gradient descent with '
             'momentum is a special case of meta-gradients, and building on '
             'recent results in optimisation, we prove convergence rates for '
             'meta learning in the single task setting. While a meta-learned '
             'update rule can yield faster convergence up to constant factor, '
             'it is not sufficient for acceleration. Instead, some form of '
             'optimism is required. We show that optimism in meta-learning can '
             'be captured through the recently proposed Bootstrapped '
             'Meta-Gradient (Flennerhag et. al., 2022) method, providing '
             'deeper insight into its underlying mechanics.',
 'title': 'Optimistic Meta-Gradients',
 'url': 'https://deepmind.google/research/publications/5642/'}
2025-01-13 22:34:16,860 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/63605/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:16,904 - root - INFO - Scraped item: {'abstract': 'While policy optimization algorithms have played an important '
             'role in recent empirical success of Reinforcement Learning (RL), '
             'the existing theoretical understanding of policy optimization '
             'remains rather limited---they are either restricted to tabular '
             'MDPs or suffer from highly suboptimal sample complexity, '
             'especial in online RL where exploration is necessary. This paper '
             'proposes a simple efficient policy optimization '
             'framework---Optimistic NPG for online RL. Optimistic NPG can be '
             'viewed as simply combining of the classic natural policy '
             'gradient (NPG) algorithm [Kakade, 2001] with optimistic policy '
             'evaluation subroutines to encourage exploration. For '
             '$d$-dimensional linear MDPs, Optimistic NPG is computationally '
             'efficient, and learns an $\\epsilon$-optimal policy within '
             '$\\tilde{O}(d^2/\\epsilon^3)$ samples, which is the first '
             'computationally efficient algorithm whose sample complexity has '
             'the optimal dimension dependence $\\tilde{\\Theta}(d^2)$. It '
             'also improves over state-of-the-art results of policy '
             'optimization algorithms [Zanette et al., 2021] by a factor of '
             '$d$. For general function approximation that subsumes linear '
             'MDPs, Optimistic NPG, to our best knowledge, is also the first '
             'policy optimization algorithm that achieves the polynomial '
             'sample complexity for learning near-optimal policies.',
 'title': 'Optimistic Natural Policy Gradient: a Simple Efficient Policy '
          'Optimization Framework for Online RL',
 'url': 'https://deepmind.google/research/publications/24720/'}
2025-01-13 22:34:16,916 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/24720/>
{'abstract': 'While policy optimization algorithms have played an important '
             'role in recent empirical success of Reinforcement Learning (RL), '
             'the existing theoretical understanding of policy optimization '
             'remains rather limited---they are either restricted to tabular '
             'MDPs or suffer from highly suboptimal sample complexity, '
             'especial in online RL where exploration is necessary. This paper '
             'proposes a simple efficient policy optimization '
             'framework---Optimistic NPG for online RL. Optimistic NPG can be '
             'viewed as simply combining of the classic natural policy '
             'gradient (NPG) algorithm [Kakade, 2001] with optimistic policy '
             'evaluation subroutines to encourage exploration. For '
             '$d$-dimensional linear MDPs, Optimistic NPG is computationally '
             'efficient, and learns an $\\epsilon$-optimal policy within '
             '$\\tilde{O}(d^2/\\epsilon^3)$ samples, which is the first '
             'computationally efficient algorithm whose sample complexity has '
             'the optimal dimension dependence $\\tilde{\\Theta}(d^2)$. It '
             'also improves over state-of-the-art results of policy '
             'optimization algorithms [Zanette et al., 2021] by a factor of '
             '$d$. For general function approximation that subsumes linear '
             'MDPs, Optimistic NPG, to our best knowledge, is also the first '
             'policy optimization algorithm that achieves the polynomial '
             'sample complexity for learning near-optimal policies.',
 'title': 'Optimistic Natural Policy Gradient: a Simple Efficient Policy '
          'Optimization Framework for Online RL',
 'url': 'https://deepmind.google/research/publications/24720/'}
2025-01-13 22:34:17,006 - root - INFO - Scraped item: {'abstract': 'We present a scalable, bottom-up and intrinsically diverse data '
             'collection scheme that can be used for high-level reasoning with '
             'long and medium horizons and that has 2.2x higher throughput '
             'compared to traditional narrow top-down step-by-step collection. '
             'We collect realistic data by performing any user requests within '
             'the entirety of 3 office buildings and using multiple robot and '
             'human embodiments. With this data, we show that models trained '
             'on all embodiments perform better than ones trained on the robot '
             'data only, even when evaluated solely on robot episodes. We find '
             'that for a fixed collection budget it is beneficial to take '
             'advantage of cheaper human collection along with robot '
             'collection. We release a large and highly diverse (29,520 unique '
             'instructions) dataset dubbed RoboVQA containing 829,502 (video, '
             'text) pairs for robotics-focused visual question answering. We '
             'also demonstrate how evaluating real robot experiments with an '
             'intervention mechanism enables performing tasks to completion, '
             'making it deployable with human oversight even if imperfect '
             'while also providing a single performance metric. We demonstrate '
             'a single video-conditioned model named RoboVQA-VideoCoCa trained '
             'on our dataset that is capable of performing a variety of '
             'grounded high-level reasoning tasks in broad realistic settings '
             'with a cognitive intervention rate 46% lower than the zero-shot '
             'state of the art visual language model (VLM) baseline and is '
             'able to guide real robots through long-horizon tasks. The '
             'performance gap with zero-shot state-of-the-art models indicates '
             'that a lot of grounded data remains to be collected for '
             'real-world deployment, emphasizing the critical need for '
             'scalable data collection approaches. Finally, we show that video '
             'VLMs significantly outperform single-image VLMs with an average '
             'error rate reduction of 19% across all VQA tasks. Data and '
             'videos available athttps://robovqa.github.io',
 'title': 'RoboVQA: Multimodal Long-Horizon Reasoning for Robotics',
 'url': 'https://deepmind.google/research/publications/63605/'}
2025-01-13 22:34:17,019 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/63605/>
{'abstract': 'We present a scalable, bottom-up and intrinsically diverse data '
             'collection scheme that can be used for high-level reasoning with '
             'long and medium horizons and that has 2.2x higher throughput '
             'compared to traditional narrow top-down step-by-step collection. '
             'We collect realistic data by performing any user requests within '
             'the entirety of 3 office buildings and using multiple robot and '
             'human embodiments. With this data, we show that models trained '
             'on all embodiments perform better than ones trained on the robot '
             'data only, even when evaluated solely on robot episodes. We find '
             'that for a fixed collection budget it is beneficial to take '
             'advantage of cheaper human collection along with robot '
             'collection. We release a large and highly diverse (29,520 unique '
             'instructions) dataset dubbed RoboVQA containing 829,502 (video, '
             'text) pairs for robotics-focused visual question answering. We '
             'also demonstrate how evaluating real robot experiments with an '
             'intervention mechanism enables performing tasks to completion, '
             'making it deployable with human oversight even if imperfect '
             'while also providing a single performance metric. We demonstrate '
             'a single video-conditioned model named RoboVQA-VideoCoCa trained '
             'on our dataset that is capable of performing a variety of '
             'grounded high-level reasoning tasks in broad realistic settings '
             'with a cognitive intervention rate 46% lower than the zero-shot '
             'state of the art visual language model (VLM) baseline and is '
             'able to guide real robots through long-horizon tasks. The '
             'performance gap with zero-shot state-of-the-art models indicates '
             'that a lot of grounded data remains to be collected for '
             'real-world deployment, emphasizing the critical need for '
             'scalable data collection approaches. Finally, we show that video '
             'VLMs significantly outperform single-image VLMs with an average '
             'error rate reduction of 19% across all VQA tasks. Data and '
             'videos available athttps://robovqa.github.io',
 'title': 'RoboVQA: Multimodal Long-Horizon Reasoning for Robotics',
 'url': 'https://deepmind.google/research/publications/63605/'}
2025-01-13 22:34:17,455 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/?page=9> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:17,553 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48455/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:17,563 - root - INFO - Parsing URL: https://deepmind.google/research/publications/?page=9
2025-01-13 22:34:17,705 - root - INFO - Scraped item: {'abstract': 'We present a novel quasi-Monte Carlo mechanism to improve '
             'graph-based sampling, coined repelling random walks. By inducing '
             'correlations between the trajectories of an interacting ensemble '
             'such that their marginal transition probabilities are '
             'unmodified, we are able to explore the graph more efficiently, '
             'improving the concentration of statistical estimators whilst '
             'leaving them unbiased. The mechanism has a trivial drop-in '
             'implementation. We showcase the effectiveness of repelling '
             'random walks in a range of settings including estimation of '
             'graph kernels, the PageRank vector and graphlet concentrations. '
             'We provide detailed experimental evaluation and robust '
             'theoretical guarantees. To our knowledge, repelling random walks '
             'constitute the first rigorously studied quasi-Monte Carlo scheme '
             'correlating the directions of walkers on a graph, inviting new '
             'research in this exciting nascent domain.',
 'title': 'Repelling Random Walks',
 'url': 'https://deepmind.google/research/publications/48455/'}
2025-01-13 22:34:17,719 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48455/>
{'abstract': 'We present a novel quasi-Monte Carlo mechanism to improve '
             'graph-based sampling, coined repelling random walks. By inducing '
             'correlations between the trajectories of an interacting ensemble '
             'such that their marginal transition probabilities are '
             'unmodified, we are able to explore the graph more efficiently, '
             'improving the concentration of statistical estimators whilst '
             'leaving them unbiased. The mechanism has a trivial drop-in '
             'implementation. We showcase the effectiveness of repelling '
             'random walks in a range of settings including estimation of '
             'graph kernels, the PageRank vector and graphlet concentrations. '
             'We provide detailed experimental evaluation and robust '
             'theoretical guarantees. To our knowledge, repelling random walks '
             'constitute the first rigorously studied quasi-Monte Carlo scheme '
             'correlating the directions of walkers on a graph, inviting new '
             'research in this exciting nascent domain.',
 'title': 'Repelling Random Walks',
 'url': 'https://deepmind.google/research/publications/48455/'}
2025-01-13 22:34:17,777 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50274/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:17,824 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48555/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:17,858 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48657/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:17,926 - root - INFO - Scraped item: {'abstract': 'We present STEP-BACK PROMPTING, a simple prompting technique '
             'that enables LLMs to do abstractions to derive high-level '
             'concepts and first principles from instances containing specific '
             'details. Using the concepts and principles to guide the '
             'reasoning steps, LLMs significantly improve their abilities in '
             'following a correct reasoning path towards the solution. We '
             'conduct experiments of STEP-BACK PROMPTING with PaLM-2 models '
             'and observe substantial performance gains on a wide range of '
             'challenging reasoning-intensive tasks including STEM, Knowledge '
             'QA, and Multi-Hop Reasoning. For instance, STEP-BACK PROMPTING '
             'improves PaLM-2L performance on MMLU Physics and Chemistry by 7% '
             'and 11%, TimeQA by 34%, and MuSiQue by 7%.',
 'title': 'Step-Back Prompting Enables Reasoning via Abstraction in Large '
          'Language Models',
 'url': 'https://deepmind.google/research/publications/50274/'}
2025-01-13 22:34:17,939 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50274/>
{'abstract': 'We present STEP-BACK PROMPTING, a simple prompting technique '
             'that enables LLMs to do abstractions to derive high-level '
             'concepts and first principles from instances containing specific '
             'details. Using the concepts and principles to guide the '
             'reasoning steps, LLMs significantly improve their abilities in '
             'following a correct reasoning path towards the solution. We '
             'conduct experiments of STEP-BACK PROMPTING with PaLM-2 models '
             'and observe substantial performance gains on a wide range of '
             'challenging reasoning-intensive tasks including STEM, Knowledge '
             'QA, and Multi-Hop Reasoning. For instance, STEP-BACK PROMPTING '
             'improves PaLM-2L performance on MMLU Physics and Chemistry by 7% '
             'and 11%, TimeQA by 34%, and MuSiQue by 7%.',
 'title': 'Step-Back Prompting Enables Reasoning via Abstraction in Large '
          'Language Models',
 'url': 'https://deepmind.google/research/publications/50274/'}
2025-01-13 22:34:17,979 - root - INFO - Scraped item: {'abstract': 'We propose a novel random walk-based algorithm for unbiased '
             'estimation of arbitrary functions of a weighted adjacency '
             'matrix, coined universal graph random features (u-GRFs). This '
             'includes many of the most popular examples of kernels defined on '
             'the nodes of a graph. Our algorithm enjoys subquadratic time '
             'complexity with respect to the number of nodes, overcoming the '
             'notoriously prohibitive cubic scaling of exact graph kernel '
             'evaluation. It can also be trivially distributed across '
             'machines, permitting learning on much larger networks. At the '
             'heart of the algorithm is a modulation function which upweights '
             'or downweights the contribution from different random walks '
             'depending on their lengths. We show that by parameterising it '
             'with a neural network we can obtain u-GRFs that give '
             'higher-quality kernel estimates or perform efficient, scalable '
             'kernel learning. We provide robust theoretical analysis and '
             'support our findings with experiments including pointwise '
             'estimation of fixed graph kernels, solving non-homogeneous graph '
             'ordinary differential equations, node clustering and kernel '
             'regression on triangular meshes.',
 'title': 'Universal Graph Random Features',
 'url': 'https://deepmind.google/research/publications/48555/'}
2025-01-13 22:34:17,991 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48555/>
{'abstract': 'We propose a novel random walk-based algorithm for unbiased '
             'estimation of arbitrary functions of a weighted adjacency '
             'matrix, coined universal graph random features (u-GRFs). This '
             'includes many of the most popular examples of kernels defined on '
             'the nodes of a graph. Our algorithm enjoys subquadratic time '
             'complexity with respect to the number of nodes, overcoming the '
             'notoriously prohibitive cubic scaling of exact graph kernel '
             'evaluation. It can also be trivially distributed across '
             'machines, permitting learning on much larger networks. At the '
             'heart of the algorithm is a modulation function which upweights '
             'or downweights the contribution from different random walks '
             'depending on their lengths. We show that by parameterising it '
             'with a neural network we can obtain u-GRFs that give '
             'higher-quality kernel estimates or perform efficient, scalable '
             'kernel learning. We provide robust theoretical analysis and '
             'support our findings with experiments including pointwise '
             'estimation of fixed graph kernels, solving non-homogeneous graph '
             'ordinary differential equations, node clustering and kernel '
             'regression on triangular meshes.',
 'title': 'Universal Graph Random Features',
 'url': 'https://deepmind.google/research/publications/48555/'}
2025-01-13 22:34:18,031 - root - INFO - Scraped item: {'abstract': 'Visual understanding of our world goes beyond the semantics and '
             'flat structure of individual images. In this paper, we work '
             'towards capturing both the 3D structure as well as the dynamics '
             'of real-world scenes from monocular real-world videos. Our '
             'model, the Dynamic Scene Transformer (DyST), builds upon recent '
             'work in neural scene representation and learns a latent '
             'decomposition into scene content as well as per-view scene '
             'dynamics and camera pose. This separation is achieved through a '
             'special co-training scheme on monocular videos and our new '
             'synthetic dataset DySO. DyST learns tangible latent '
             'representations for dynamic scenes that enable view generation '
             'with separate control over the camera and the content of the '
             'scene.',
 'title': 'DyST: Towards Dynamic Neural Scene Representations on Real-World '
          'Videos',
 'url': 'https://deepmind.google/research/publications/48657/'}
2025-01-13 22:34:18,045 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48657/>
{'abstract': 'Visual understanding of our world goes beyond the semantics and '
             'flat structure of individual images. In this paper, we work '
             'towards capturing both the 3D structure as well as the dynamics '
             'of real-world scenes from monocular real-world videos. Our '
             'model, the Dynamic Scene Transformer (DyST), builds upon recent '
             'work in neural scene representation and learns a latent '
             'decomposition into scene content as well as per-view scene '
             'dynamics and camera pose. This separation is achieved through a '
             'special co-training scheme on monocular videos and our new '
             'synthetic dataset DySO. DyST learns tangible latent '
             'representations for dynamic scenes that enable view generation '
             'with separate control over the camera and the content of the '
             'scene.',
 'title': 'DyST: Towards Dynamic Neural Scene Representations on Real-World '
          'Videos',
 'url': 'https://deepmind.google/research/publications/48657/'}
2025-01-13 22:34:18,094 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/51282/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:18,116 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/47545/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:18,240 - root - INFO - Scraped item: {'abstract': '\u200b\u200b\u200b\u200bGenerative models trained on '
             'internet-scale data are capable of generating novel yet highly '
             'realistic texts, images, and videos. A natural next question is '
             'whether these models can advance science through means such as '
             'generating novel stable materials. Traditionally, models with '
             'explicit structures (e.g., graphs) have been used in modeling '
             'structural relationships in scientific data (e.g., atoms and '
             'bonds in crystals), but generating structures explicitly might '
             'be difficult to scale to large and complex systems. Another '
             'challenge to generative models of materials lies in the mismatch '
             'between generative modeling metrics and the downstream '
             'applications. For instance, common metrics such as the '
             'reconstruction error do not correlate well with the downstream '
             'goal of discovering novel stable materials. In this work, we '
             'tackle the scalability challenge by first developing a unified '
             'crystal representation that can effectively represent any '
             'crystal structures (UniMat), followed by training a diffusion '
             'probabilistic model on the UniMat representations. Our empirical '
             'results suggest that despite the lack of explicit structure '
             'modeling, UniMat can generate high fidelity crystal structures '
             'from larger and more complex chemical systems, outperforming '
             'previous graph-based approaches under various generative '
             'modeling metrics. To better connect the generation quality of '
             'materials to downstream applications such as discovering novel '
             'stable materials, we propose to use decomposition energy from '
             'Density Function Theory (DFT) calculations and the resulting '
             'stability with respect to convex hulls as additional evaluation '
             'metrics for generative models of materials. Lastly, we show that '
             'conditional generation with UniMat can scale to previously '
             'established crystal datasets with up to millions of crystals '
             'structures, and outperform random structure search (the current '
             'leading method for structure discovery) in discovering new '
             'stable materials.',
 'title': 'Scalable Diffusion for Materials Generation',
 'url': 'https://deepmind.google/research/publications/51282/'}
2025-01-13 22:34:18,257 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/51282/>
{'abstract': '\u200b\u200b\u200b\u200bGenerative models trained on '
             'internet-scale data are capable of generating novel yet highly '
             'realistic texts, images, and videos. A natural next question is '
             'whether these models can advance science through means such as '
             'generating novel stable materials. Traditionally, models with '
             'explicit structures (e.g., graphs) have been used in modeling '
             'structural relationships in scientific data (e.g., atoms and '
             'bonds in crystals), but generating structures explicitly might '
             'be difficult to scale to large and complex systems. Another '
             'challenge to generative models of materials lies in the mismatch '
             'between generative modeling metrics and the downstream '
             'applications. For instance, common metrics such as the '
             'reconstruction error do not correlate well with the downstream '
             'goal of discovering novel stable materials. In this work, we '
             'tackle the scalability challenge by first developing a unified '
             'crystal representation that can effectively represent any '
             'crystal structures (UniMat), followed by training a diffusion '
             'probabilistic model on the UniMat representations. Our empirical '
             'results suggest that despite the lack of explicit structure '
             'modeling, UniMat can generate high fidelity crystal structures '
             'from larger and more complex chemical systems, outperforming '
             'previous graph-based approaches under various generative '
             'modeling metrics. To better connect the generation quality of '
             'materials to downstream applications such as discovering novel '
             'stable materials, we propose to use decomposition energy from '
             'Density Function Theory (DFT) calculations and the resulting '
             'stability with respect to convex hulls as additional evaluation '
             'metrics for generative models of materials. Lastly, we show that '
             'conditional generation with UniMat can scale to previously '
             'established crystal datasets with up to millions of crystals '
             'structures, and outperform random structure search (the current '
             'leading method for structure discovery) in discovering new '
             'stable materials.',
 'title': 'Scalable Diffusion for Materials Generation',
 'url': 'https://deepmind.google/research/publications/51282/'}
2025-01-13 22:34:18,352 - root - INFO - Scraped item: {'abstract': 'Generative models trained on internet data have revolutionized '
             'how text, image, and video content can be created. Perhaps the '
             'next milestone for generative models is to simulate the real '
             'world in response to actions carried out by humans, robots, and '
             'other types of interactive agents. Applications of a real-world '
             'simulator range from controllable content creation in games and '
             'movies to training embodied agents purely in simulation that can '
             'be directly deployed in the real world. In this paper, we '
             'explore these possibilities around learning a universal '
             'simulator (UniSim) of real-world interactions through generative '
             'modeling. We first make the important observation that natural '
             'datasets available for learning a real-world simulator are often '
             'rich in different axes (e.g., rich labeled objects in image '
             'data, rich actions in robotics data, and rich movements in '
             'navigation data). With careful orchestration of diverse datasets '
             'each serving a different piece of the puzzle, UniSim can emulate '
             'how humans and agents interact with the world by simulating the '
             'visual outcome of both high-level instructions such as “open the '
             'drawer” and low-level controls such as “move to x, y location” '
             'from otherwise static scenes and objects. The usage of a '
             'real-world simulator is vast. As an example, we use UniSim to '
             'simulate interactive experiences to train high-level '
             'vision-language planners and low-level reinforcement learning '
             'policies, both of which exhibit significant real-world transfer '
             'from purely training in a real-world like simulator. Lastly, we '
             'show that other types of intelligence such as video captioning '
             'and detection models can also benefit from simulated experiences '
             'of UniSim, opening up even wider applications of a real-world '
             'simulator.',
 'title': 'Learning Interactive Real-World Simulator',
 'url': 'https://deepmind.google/research/publications/47545/'}
2025-01-13 22:34:18,366 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/47545/>
{'abstract': 'Generative models trained on internet data have revolutionized '
             'how text, image, and video content can be created. Perhaps the '
             'next milestone for generative models is to simulate the real '
             'world in response to actions carried out by humans, robots, and '
             'other types of interactive agents. Applications of a real-world '
             'simulator range from controllable content creation in games and '
             'movies to training embodied agents purely in simulation that can '
             'be directly deployed in the real world. In this paper, we '
             'explore these possibilities around learning a universal '
             'simulator (UniSim) of real-world interactions through generative '
             'modeling. We first make the important observation that natural '
             'datasets available for learning a real-world simulator are often '
             'rich in different axes (e.g., rich labeled objects in image '
             'data, rich actions in robotics data, and rich movements in '
             'navigation data). With careful orchestration of diverse datasets '
             'each serving a different piece of the puzzle, UniSim can emulate '
             'how humans and agents interact with the world by simulating the '
             'visual outcome of both high-level instructions such as “open the '
             'drawer” and low-level controls such as “move to x, y location” '
             'from otherwise static scenes and objects. The usage of a '
             'real-world simulator is vast. As an example, we use UniSim to '
             'simulate interactive experiences to train high-level '
             'vision-language planners and low-level reinforcement learning '
             'policies, both of which exhibit significant real-world transfer '
             'from purely training in a real-world like simulator. Lastly, we '
             'show that other types of intelligence such as video captioning '
             'and detection models can also benefit from simulated experiences '
             'of UniSim, opening up even wider applications of a real-world '
             'simulator.',
 'title': 'Learning Interactive Real-World Simulator',
 'url': 'https://deepmind.google/research/publications/47545/'}
2025-01-13 22:34:18,373 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/50474/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:18,406 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/45425/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:18,513 - root - INFO - Scraped item: {'abstract': 'We introduce the concept of scalable neural network kernels '
             '(SNNKs), the replacements of regular feedforward layers (FFLs), '
             'capable of approximating the latter, but with favorable '
             'computational properties. SNNKs effectively disentangle the '
             'inputs from the parameters of the neural network in the FFL, '
             'only to connect them in the final computation via the '
             'dot-product kernel. They are also strictly more expressive, as '
             'allowing to model complicated relationships beyond the functions '
             'of the dot-products of parameter-input vectors. We also '
             'introduce the neural network bundling process that applies SNNKs '
             'to compactify deep neural network architectures, resulting in '
             'additional compression gains. In its extreme version, it leads '
             'to the fully bundled network whose optimal parameters can be '
             'expressed via explicit formulae for several loss functions (e.g. '
             'mean squared error), opening a possibility to bypass '
             'backpropagation. As a by-product of our analysis, we introduce '
             'the mechanism of the universal random features (or URFs), '
             'applied to instantiate several SNNK variants, and interesting on '
             'its own in the context of scalable kernel methods. We provide '
             'rigorous theoretical analysis of all these concepts as well as '
             'an extensive empirical evaluation, ranging from point-wise '
             "kernel estimation to Transformers' fine-tuning with novel "
             'adapter layers inspired by SNNKs. Our mechanism provides up to '
             '5x reduction in the number of trainable parameters, while '
             'maintaining competitive accuracy.',
 'title': 'Scalable Neural Network Kernels',
 'url': 'https://deepmind.google/research/publications/50474/'}
2025-01-13 22:34:18,526 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/50474/>
{'abstract': 'We introduce the concept of scalable neural network kernels '
             '(SNNKs), the replacements of regular feedforward layers (FFLs), '
             'capable of approximating the latter, but with favorable '
             'computational properties. SNNKs effectively disentangle the '
             'inputs from the parameters of the neural network in the FFL, '
             'only to connect them in the final computation via the '
             'dot-product kernel. They are also strictly more expressive, as '
             'allowing to model complicated relationships beyond the functions '
             'of the dot-products of parameter-input vectors. We also '
             'introduce the neural network bundling process that applies SNNKs '
             'to compactify deep neural network architectures, resulting in '
             'additional compression gains. In its extreme version, it leads '
             'to the fully bundled network whose optimal parameters can be '
             'expressed via explicit formulae for several loss functions (e.g. '
             'mean squared error), opening a possibility to bypass '
             'backpropagation. As a by-product of our analysis, we introduce '
             'the mechanism of the universal random features (or URFs), '
             'applied to instantiate several SNNK variants, and interesting on '
             'its own in the context of scalable kernel methods. We provide '
             'rigorous theoretical analysis of all these concepts as well as '
             'an extensive empirical evaluation, ranging from point-wise '
             "kernel estimation to Transformers' fine-tuning with novel "
             'adapter layers inspired by SNNKs. Our mechanism provides up to '
             '5x reduction in the number of trainable parameters, while '
             'maintaining competitive accuracy.',
 'title': 'Scalable Neural Network Kernels',
 'url': 'https://deepmind.google/research/publications/50474/'}
2025-01-13 22:34:18,566 - root - INFO - Scraped item: {'abstract': 'Generative AI systems produce potential ethical and social risks '
             'that require comprehensive evaluation. In this paper, we propose '
             'a three-layered framework toward a structured, sociotechnical '
             'approach to evaluate these risks. The approach here evolves from '
             'a system safety perspective, particularly the insight that '
             'context determines whether a given capability causes harm. '
             'Applied to AI, this perspective shows that evaluation at '
             'multiple layers of analysis is required in order to assess '
             'whether or not an AI system may cause a given harm. '
             'Sociotechnical evaluation begins with the main current approach '
             'to safety evaluation, capability testing, which considers AI '
             'system outputs and their components in isolation. Building on '
             'this, it accounts for two further layers of context. The second '
             'layer centres the human interacting with a system to assess harm '
             'that may occur at the point of use. Broader systemic impacts on '
             'the structures into which an AI system is embedded require '
             'evaluation at the third, systemic evaluation layer. The second '
             'main contribution of this paper is an overview of the current '
             'state of sociotechnical evaluation. Reviewing all available '
             'evaluations for social and ethical risks known to a wide range '
             'of cross-industry researchers, we map gaps in the status quo. We '
             'then carefully lay out a roadmap of tractable steps toward '
             'closing the identified gaps.',
 'title': 'Sociotechnical Safety Evaluation of generative AI systems',
 'url': 'https://deepmind.google/research/publications/45425/'}
2025-01-13 22:34:18,581 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/45425/>
{'abstract': 'Generative AI systems produce potential ethical and social risks '
             'that require comprehensive evaluation. In this paper, we propose '
             'a three-layered framework toward a structured, sociotechnical '
             'approach to evaluate these risks. The approach here evolves from '
             'a system safety perspective, particularly the insight that '
             'context determines whether a given capability causes harm. '
             'Applied to AI, this perspective shows that evaluation at '
             'multiple layers of analysis is required in order to assess '
             'whether or not an AI system may cause a given harm. '
             'Sociotechnical evaluation begins with the main current approach '
             'to safety evaluation, capability testing, which considers AI '
             'system outputs and their components in isolation. Building on '
             'this, it accounts for two further layers of context. The second '
             'layer centres the human interacting with a system to assess harm '
             'that may occur at the point of use. Broader systemic impacts on '
             'the structures into which an AI system is embedded require '
             'evaluation at the third, systemic evaluation layer. The second '
             'main contribution of this paper is an overview of the current '
             'state of sociotechnical evaluation. Reviewing all available '
             'evaluations for social and ethical risks known to a wide range '
             'of cross-industry researchers, we map gaps in the status quo. We '
             'then carefully lay out a roadmap of tractable steps toward '
             'closing the identified gaps.',
 'title': 'Sociotechnical Safety Evaluation of generative AI systems',
 'url': 'https://deepmind.google/research/publications/45425/'}
2025-01-13 22:34:18,755 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/44214/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:18,899 - root - INFO - Scraped item: {'abstract': 'This work studies a central extremal graph theory problem '
             'inspired by a 1975 conjecture of Erdos, which aims to find '
             'graphs with a given size (number of nodes) that maximize the '
             'number of edges without having 3- or 4-cycles. We formulate this '
             'problem as a sequential decision-making problem and compare '
             'AlphaZero, a neural network-guided tree search, with tabu '
             'search, a heuristic local search method. Using either method, by '
             'introducing a curriculum—jump-starting the search for larger '
             'graphs using good graphs found at smaller sizes—we improve the '
             'state-of-the-art lower bounds for several sizes. We also propose '
             'a flexible graph-generation environment and a '
             'permutation-invariant network architecture for learning to '
             'search in the space of graphs.',
 'title': 'Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu '
          'Search',
 'url': 'https://deepmind.google/research/publications/44214/'}
2025-01-13 22:34:18,931 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/44214/>
{'abstract': 'This work studies a central extremal graph theory problem '
             'inspired by a 1975 conjecture of Erdos, which aims to find '
             'graphs with a given size (number of nodes) that maximize the '
             'number of edges without having 3- or 4-cycles. We formulate this '
             'problem as a sequential decision-making problem and compare '
             'AlphaZero, a neural network-guided tree search, with tabu '
             'search, a heuristic local search method. Using either method, by '
             'introducing a curriculum—jump-starting the search for larger '
             'graphs using good graphs found at smaller sizes—we improve the '
             'state-of-the-art lower bounds for several sizes. We also propose '
             'a flexible graph-generation environment and a '
             'permutation-invariant network architecture for learning to '
             'search in the space of graphs.',
 'title': 'Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu '
          'Search',
 'url': 'https://deepmind.google/research/publications/44214/'}
2025-01-13 22:34:19,005 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48757/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:19,085 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/5630/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:19,145 - root - INFO - Scraped item: {'abstract': 'In order for generalist robot policies to operate robustly in '
             'the real world, they must be able to accomplish many tasks in a '
             'wide array of situations, potentially beyond those seen in '
             'training datasets.\n'
             'Recent works have studied generalization in such settings, by '
             'leveraging policy conditioning with modalities such as natural '
             'language or object-centric visual representations.\n'
             'While these methods have shown promise in high-level '
             'generalization to semantics, objects, or visual distribution '
             'shifts, there remain significant open challenges in novel '
             'low-level motion generalization.\n'
             'This challenge is both a theoretical and practical barrier in '
             'scaling robot learning methods, as real-world robot situations '
             'may demand significantly more low-level motion capabilities than '
             'contained in common large-scale tabletop pick and place '
             'datasets.\n'
             'Towards tackling this, we propose policy conditioning with rough '
             'trajectory sketches, which strike a balance between being '
             'detailed enough to express low-level motion-centric guidance '
             'while being coarse enough to require learning-based policies to '
             'interpret the trajectory sketch in the context of situational '
             'visual observations.\n'
             'The trajectory sketch is also a scalable and flexible '
             'representation: during training it can be generated in hindsight '
             'from proprioception sensors and during inference time it can be '
             'specified through simple human inputs like drawing or videos, or '
             'through automated methods such as modern image-generating or '
             'waypoint-generating methods.\n'
             'We present trajectory-conditioned policies within a holistic '
             'framework, which we demonstrate at scale on a variety of real '
             'world robotic tasks which require diverse motions that go beyond '
             'tabletop pick and place tasks that our method was trained on.',
 'title': 'RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory '
          'Sketches',
 'url': 'https://deepmind.google/research/publications/48757/'}
2025-01-13 22:34:19,159 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48757/>
{'abstract': 'In order for generalist robot policies to operate robustly in '
             'the real world, they must be able to accomplish many tasks in a '
             'wide array of situations, potentially beyond those seen in '
             'training datasets.\n'
             'Recent works have studied generalization in such settings, by '
             'leveraging policy conditioning with modalities such as natural '
             'language or object-centric visual representations.\n'
             'While these methods have shown promise in high-level '
             'generalization to semantics, objects, or visual distribution '
             'shifts, there remain significant open challenges in novel '
             'low-level motion generalization.\n'
             'This challenge is both a theoretical and practical barrier in '
             'scaling robot learning methods, as real-world robot situations '
             'may demand significantly more low-level motion capabilities than '
             'contained in common large-scale tabletop pick and place '
             'datasets.\n'
             'Towards tackling this, we propose policy conditioning with rough '
             'trajectory sketches, which strike a balance between being '
             'detailed enough to express low-level motion-centric guidance '
             'while being coarse enough to require learning-based policies to '
             'interpret the trajectory sketch in the context of situational '
             'visual observations.\n'
             'The trajectory sketch is also a scalable and flexible '
             'representation: during training it can be generated in hindsight '
             'from proprioception sensors and during inference time it can be '
             'specified through simple human inputs like drawing or videos, or '
             'through automated methods such as modern image-generating or '
             'waypoint-generating methods.\n'
             'We present trajectory-conditioned policies within a holistic '
             'framework, which we demonstrate at scale on a variety of real '
             'world robotic tasks which require diverse motions that go beyond '
             'tabletop pick and place tasks that our method was trained on.',
 'title': 'RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory '
          'Sketches',
 'url': 'https://deepmind.google/research/publications/48757/'}
2025-01-13 22:34:19,221 - root - INFO - Scraped item: {'abstract': 'Understanding the visual world is a constructive and '
             'compositional process. Whilst a frontal-\n'
             'hippocampal circuit is known to be essential for this task, '
             'little is known about the associated neuronal\n'
             'computations. Although visual understanding appears '
             'superficially distinct from other known functions\n'
             'of this circuit, such as spatial reasoning, compositional '
             'inference, and model-based planning, recent\n'
             'models suggest deeper computational similarities. Here, using '
             'fMRI, we show that representations of\n'
             'visual objects in these brain regions are relational and '
             'compositional – key computational properties\n'
             'theorised to support rapid construction of hippocampal maps. '
             'Using MEG, we show that rapid\n'
             'sequences of representations, akin to replay in spatial '
             'navigation and planning problems, are also\n'
             'engaged in visual understanding. Whilst these sequences have '
             'previously been proposed as\n'
             'mechanisms to plan possible futures or learn from the past, here '
             'they are used to understand the\n'
             'present. Replay sequences change content over timescales of '
             'understanding and form constructive\n'
             'hypotheses about possible object configurations. These '
             'hypotheses play out in an order that supports\n'
             'relational inference, progressing from predictable to uncertain '
             'scene elements, gradually constraining\n'
             'possible configurations, and converging on the correct '
             'configuration. Together, these results suggest\n'
             'a computational bridge between apparently distinct functions of '
             'hippocampal-prefrontal circuitry, and\n'
             'a role for generative replay in compositional inference and '
             'hypothesis testing.',
 'title': 'Generative replay for compositional visual understanding in the '
          'prefrontal-hippocampal circuit',
 'url': 'https://deepmind.google/research/publications/5630/'}
2025-01-13 22:34:19,238 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/5630/>
{'abstract': 'Understanding the visual world is a constructive and '
             'compositional process. Whilst a frontal-\n'
             'hippocampal circuit is known to be essential for this task, '
             'little is known about the associated neuronal\n'
             'computations. Although visual understanding appears '
             'superficially distinct from other known functions\n'
             'of this circuit, such as spatial reasoning, compositional '
             'inference, and model-based planning, recent\n'
             'models suggest deeper computational similarities. Here, using '
             'fMRI, we show that representations of\n'
             'visual objects in these brain regions are relational and '
             'compositional – key computational properties\n'
             'theorised to support rapid construction of hippocampal maps. '
             'Using MEG, we show that rapid\n'
             'sequences of representations, akin to replay in spatial '
             'navigation and planning problems, are also\n'
             'engaged in visual understanding. Whilst these sequences have '
             'previously been proposed as\n'
             'mechanisms to plan possible futures or learn from the past, here '
             'they are used to understand the\n'
             'present. Replay sequences change content over timescales of '
             'understanding and form constructive\n'
             'hypotheses about possible object configurations. These '
             'hypotheses play out in an order that supports\n'
             'relational inference, progressing from predictable to uncertain '
             'scene elements, gradually constraining\n'
             'possible configurations, and converging on the correct '
             'configuration. Together, these results suggest\n'
             'a computational bridge between apparently distinct functions of '
             'hippocampal-prefrontal circuitry, and\n'
             'a role for generative replay in compositional inference and '
             'hypothesis testing.',
 'title': 'Generative replay for compositional visual understanding in the '
          'prefrontal-hippocampal circuit',
 'url': 'https://deepmind.google/research/publications/5630/'}
2025-01-13 22:34:19,251 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/35223/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:19,300 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/83400/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:19,329 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/58352/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:19,393 - root - INFO - Scraped item: {'abstract': 'As dialogue agents become increasingly human-like in their '
             'performance, it is imperative that we develop effective ways to '
             'describe their behaviour in high-level terms without falling '
             'into the trap of anthropomorphism. In this paper, we foreground '
             'the concept of role-play. Casting dialogue agent behaviour in '
             'terms of role-play allows us to draw on familiar folk '
             'psychological terms, without ascribing human characteristics to '
             'language models they in fact lack. Two important cases of '
             'dialogue agent behaviour are addressed this way, namely '
             '(apparent) deception and (apparent) self-awareness.',
 'title': 'Role Play with Large Language Models',
 'url': 'https://deepmind.google/research/publications/35223/'}
2025-01-13 22:34:19,407 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/35223/>
{'abstract': 'As dialogue agents become increasingly human-like in their '
             'performance, it is imperative that we develop effective ways to '
             'describe their behaviour in high-level terms without falling '
             'into the trap of anthropomorphism. In this paper, we foreground '
             'the concept of role-play. Casting dialogue agent behaviour in '
             'terms of role-play allows us to draw on familiar folk '
             'psychological terms, without ascribing human characteristics to '
             'language models they in fact lack. Two important cases of '
             'dialogue agent behaviour are addressed this way, namely '
             '(apparent) deception and (apparent) self-awareness.',
 'title': 'Role Play with Large Language Models',
 'url': 'https://deepmind.google/research/publications/35223/'}
2025-01-13 22:34:19,445 - root - INFO - Scraped item: {'abstract': 'Large language models (LLMs) can learn to perform a wide range '
             'of natural language tasks from just a handful of in-context '
             'examples. However, for generating strings from highly structured '
             'languages (e.g., semantic parsing to complex domain-specific '
             'languages), it is challenging for the LLM to generalize from '
             'just a few exemplars. We propose \\emph{grammar prompting}, a '
             'simple approach to enable LLMs to use external knowledge and '
             'domain-specific constraints, expressed through a grammar in '
             'Backus--Naur Form (BNF), during in-context learning. Grammar '
             'prompting augments each demonstration example with a specialized '
             'grammar that is minimally sufficient for generating the '
             'particular output example, where the specialized grammar is a '
             'subset of the full DSL grammar. For inference, the LLM first '
             'predicts a BNF grammar given a test input, and then generates '
             'the output according to the rules of the grammar. Experiments '
             'demonstrate that grammar prompting can enable LLMs to perform '
             'competitively on a diverse set of DSL generation tasks, '
             'including semantic parsing (SMCalFlow, Overnight, GeoQuery), '
             'PDDL planning, and SMILES-based molecule generation.',
 'title': 'Grammar Prompting for Domain-Specific Language Generation with '
          'Large Language Models',
 'url': 'https://deepmind.google/research/publications/83400/'}
2025-01-13 22:34:19,462 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/83400/>
{'abstract': 'Large language models (LLMs) can learn to perform a wide range '
             'of natural language tasks from just a handful of in-context '
             'examples. However, for generating strings from highly structured '
             'languages (e.g., semantic parsing to complex domain-specific '
             'languages), it is challenging for the LLM to generalize from '
             'just a few exemplars. We propose \\emph{grammar prompting}, a '
             'simple approach to enable LLMs to use external knowledge and '
             'domain-specific constraints, expressed through a grammar in '
             'Backus--Naur Form (BNF), during in-context learning. Grammar '
             'prompting augments each demonstration example with a specialized '
             'grammar that is minimally sufficient for generating the '
             'particular output example, where the specialized grammar is a '
             'subset of the full DSL grammar. For inference, the LLM first '
             'predicts a BNF grammar given a test input, and then generates '
             'the output according to the rules of the grammar. Experiments '
             'demonstrate that grammar prompting can enable LLMs to perform '
             'competitively on a diverse set of DSL generation tasks, '
             'including semantic parsing (SMCalFlow, Overnight, GeoQuery), '
             'PDDL planning, and SMILES-based molecule generation.',
 'title': 'Grammar Prompting for Domain-Specific Language Generation with '
          'Large Language Models',
 'url': 'https://deepmind.google/research/publications/83400/'}
2025-01-13 22:34:19,501 - root - INFO - Scraped item: {'abstract': 'This report presents the takeaways of the inaugural Workshop on '
             'Generative AI and Law, held in July 2023. A cross-disciplinary '
             'group of practitioners and scholars from computer science and '
             'law convened to discuss the technical, doctrinal, and policy '
             'challenges presented by law for generative AI, and by generative '
             'AI for law, with an emphasis on US law in particular. We '
             'conclude that there is an essential need for 1) a shared '
             'knowledge base that provides a common conceptual language for '
             'experts across disciplines; 2) clarification of the distinctive '
             'technical capabilities of generative-AI systems as compared and '
             'contrasted to other computer and AI systems; 3) a logical '
             'taxonomy of the legal issues these systems raise; and, 4) a '
             'concrete research agenda to promote collaboration and '
             'knowledge-sharing on emerging issues at the intersection of '
             'generative AI and law. In this report, we synthesize the key '
             'takeaways from the GenLaw workshop that begin to address these '
             'four needs.',
 'title': 'Report of the 1st Workshop on Generative AI and Law',
 'url': 'https://deepmind.google/research/publications/58352/'}
2025-01-13 22:34:19,514 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/58352/>
{'abstract': 'This report presents the takeaways of the inaugural Workshop on '
             'Generative AI and Law, held in July 2023. A cross-disciplinary '
             'group of practitioners and scholars from computer science and '
             'law convened to discuss the technical, doctrinal, and policy '
             'challenges presented by law for generative AI, and by generative '
             'AI for law, with an emphasis on US law in particular. We '
             'conclude that there is an essential need for 1) a shared '
             'knowledge base that provides a common conceptual language for '
             'experts across disciplines; 2) clarification of the distinctive '
             'technical capabilities of generative-AI systems as compared and '
             'contrasted to other computer and AI systems; 3) a logical '
             'taxonomy of the legal issues these systems raise; and, 4) a '
             'concrete research agenda to promote collaboration and '
             'knowledge-sharing on emerging issues at the intersection of '
             'generative AI and law. In this report, we synthesize the key '
             'takeaways from the GenLaw workshop that begin to address these '
             'four needs.',
 'title': 'Report of the 1st Workshop on Generative AI and Law',
 'url': 'https://deepmind.google/research/publications/58352/'}
2025-01-13 22:34:19,998 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/8258/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,025 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/35526/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:20,085 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/32195/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,094 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/57039/> (referer: https://deepmind.google/research/publications/?page=8)
2025-01-13 22:34:20,139 - root - INFO - Scraped item: {'abstract': 'Sampling from known probability distributions is a ubiquitous '
             'task in computational science, underlying calculations in '
             'domains from linguistics to biology and physics. Generative '
             'machine-learning (ML) models have emerged as a promising tool in '
             'this space, building on the success of this approach in '
             'applications such as image, text and audio generation. Often, '
             'however, generative tasks in scientific domains have unique '
             'structures and features — such as complex symmetries and the '
             'requirement of exactness guarantees — that present both '
             'challenges and opportunities for ML. This Perspective outlines '
             'the advances in ML-based sampling motivated by lattice quantum '
             'field theory, in particular for the theory of quantum '
             'chromodynamics. Enabling calculations of the structure and '
             'interactions of matter from our most fundamental understanding '
             'of particle physics, lattice quantum chromodynamics is one of '
             'the main consumers of open-science supercomputing worldwide. The '
             'design of ML algorithms for this application faces profound '
             'challenges, including the necessity of scaling custom ML '
             'architectures to the largest supercomputers, but also promises '
             'immense benefits, and is spurring a wave of development in '
             'ML-based sampling more broadly. In lattice field theory, if this '
             'approach can realize its early promise it will be a '
             'transformative step towards first-principles physics '
             'calculations in particle, nuclear and condensed matter physics '
             'that are intractable with traditional approaches.',
 'title': 'Advances in ML-based sampling for Lattice-QCD',
 'url': 'https://deepmind.google/research/publications/8258/'}
2025-01-13 22:34:20,153 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/8258/>
{'abstract': 'Sampling from known probability distributions is a ubiquitous '
             'task in computational science, underlying calculations in '
             'domains from linguistics to biology and physics. Generative '
             'machine-learning (ML) models have emerged as a promising tool in '
             'this space, building on the success of this approach in '
             'applications such as image, text and audio generation. Often, '
             'however, generative tasks in scientific domains have unique '
             'structures and features — such as complex symmetries and the '
             'requirement of exactness guarantees — that present both '
             'challenges and opportunities for ML. This Perspective outlines '
             'the advances in ML-based sampling motivated by lattice quantum '
             'field theory, in particular for the theory of quantum '
             'chromodynamics. Enabling calculations of the structure and '
             'interactions of matter from our most fundamental understanding '
             'of particle physics, lattice quantum chromodynamics is one of '
             'the main consumers of open-science supercomputing worldwide. The '
             'design of ML algorithms for this application faces profound '
             'challenges, including the necessity of scaling custom ML '
             'architectures to the largest supercomputers, but also promises '
             'immense benefits, and is spurring a wave of development in '
             'ML-based sampling more broadly. In lattice field theory, if this '
             'approach can realize its early promise it will be a '
             'transformative step towards first-principles physics '
             'calculations in particle, nuclear and condensed matter physics '
             'that are intractable with traditional approaches.',
 'title': 'Advances in ML-based sampling for Lattice-QCD',
 'url': 'https://deepmind.google/research/publications/8258/'}
2025-01-13 22:34:20,160 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34011/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,197 - root - INFO - Scraped item: {'abstract': 'Coordinated pair bonds are common in birds and also occur in '
             'many other taxa. How do animals solve the social dilemmas they '
             'face in coordinating with a partner? We developed an '
             'evolutionary model to explore this question, based on '
             'observations that a) neuroendocrine feedback provides emotional '
             'bookkeeping which is thought to play a key role in vertebrate '
             'social bonds and b) these bonds are developed and maintained via '
             'courtship interactions that include low-stakes social dilemmas. '
             'Using agent-based simulation, we found that emotional '
             'bookkeeping and courtship sustained cooperation in the iterated '
             'prisoner’s dilemma in noisy environments, especially when '
             'combined. However, when deceitful defection was possible at low '
             'cost, courtship often increased cooperation, whereas emotional '
             'bookkeeping decreased it.',
 'title': 'Emotions and courtship help bonded pairs cooperate, but emotional '
          'agents are vulnerable to deceit',
 'url': 'https://deepmind.google/research/publications/35526/'}
2025-01-13 22:34:20,209 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/35526/>
{'abstract': 'Coordinated pair bonds are common in birds and also occur in '
             'many other taxa. How do animals solve the social dilemmas they '
             'face in coordinating with a partner? We developed an '
             'evolutionary model to explore this question, based on '
             'observations that a) neuroendocrine feedback provides emotional '
             'bookkeeping which is thought to play a key role in vertebrate '
             'social bonds and b) these bonds are developed and maintained via '
             'courtship interactions that include low-stakes social dilemmas. '
             'Using agent-based simulation, we found that emotional '
             'bookkeeping and courtship sustained cooperation in the iterated '
             'prisoner’s dilemma in noisy environments, especially when '
             'combined. However, when deceitful defection was possible at low '
             'cost, courtship often increased cooperation, whereas emotional '
             'bookkeeping decreased it.',
 'title': 'Emotions and courtship help bonded pairs cooperate, but emotional '
          'agents are vulnerable to deceit',
 'url': 'https://deepmind.google/research/publications/35526/'}
2025-01-13 22:34:20,249 - root - INFO - Scraped item: {'abstract': 'A shared goal of several machine learning communities like '
             'continual learning, meta-learning and transfer learning, is to '
             'design algorithms and models that efficiently and robustly adapt '
             'to unseen tasks. An even more ambitious goal is to build models '
             'that never stop adapting, and that become increasingly more '
             'efficient through time by suitably transferring the accrued '
             'knowledge.\n'
             'Beyond the study of the actual learning algorithm and model '
             'architecture, there are several hurdles towards our quest to '
             'build such models, such as the choice of learning protocol, '
             'metric of success and data needed to validate research '
             'hypotheses. In this work, we introduce the Never-Ending '
             "VIsual-classification Stream (NEVIS'22), a benchmark consisting "
             'of a stream of over $100$ visual classification tasks, sorted '
             'chronologically and extracted from papers sampled uniformly from '
             'computer vision proceedings spanning the last three decades. The '
             'resulting stream reflects what the research community thought '
             'was meaningful at any point in time, and it serves as an ideal '
             'test bed to assess how well models can adapt to new tasks, and '
             'do so better and more efficiently as time goes by. Despite being '
             'limited to classification, the resulting stream has a rich '
             'diversity of tasks from OCR, to texture analysis, scene '
             'recognition, and so forth. The diversity is also reflected in '
             'the wide range of dataset sizes, spanning over four orders of '
             "magnitude. Overall, NEVIS'22 poses an unprecedented challenge "
             'for current sequential learning approaches due to the scale and '
             'diversity of tasks, yet with a low entry barrier as it is '
             'limited to a single modality and well understood supervised '
             'learning problems. Moreover, we provide a reference '
             'implementation including strong baselines and an evaluation '
             'protocol to compare methods in terms of their trade-off between '
             "accuracy and compute. We hope that NEVIS'22 can be useful to "
             'researchers working on continual learning, meta-learning, AutoML '
             'and more generally sequential learning, and help these '
             'communities join forces towards more robust models that '
             'efficiently adapt to a never ending stream of data.',
 'title': 'Nevis’22: A Stream of 100 Tasks Sampled from 30 Years of Computer '
          'Vision Research',
 'url': 'https://deepmind.google/research/publications/32195/'}
2025-01-13 22:34:20,263 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/32195/>
{'abstract': 'A shared goal of several machine learning communities like '
             'continual learning, meta-learning and transfer learning, is to '
             'design algorithms and models that efficiently and robustly adapt '
             'to unseen tasks. An even more ambitious goal is to build models '
             'that never stop adapting, and that become increasingly more '
             'efficient through time by suitably transferring the accrued '
             'knowledge.\n'
             'Beyond the study of the actual learning algorithm and model '
             'architecture, there are several hurdles towards our quest to '
             'build such models, such as the choice of learning protocol, '
             'metric of success and data needed to validate research '
             'hypotheses. In this work, we introduce the Never-Ending '
             "VIsual-classification Stream (NEVIS'22), a benchmark consisting "
             'of a stream of over $100$ visual classification tasks, sorted '
             'chronologically and extracted from papers sampled uniformly from '
             'computer vision proceedings spanning the last three decades. The '
             'resulting stream reflects what the research community thought '
             'was meaningful at any point in time, and it serves as an ideal '
             'test bed to assess how well models can adapt to new tasks, and '
             'do so better and more efficiently as time goes by. Despite being '
             'limited to classification, the resulting stream has a rich '
             'diversity of tasks from OCR, to texture analysis, scene '
             'recognition, and so forth. The diversity is also reflected in '
             'the wide range of dataset sizes, spanning over four orders of '
             "magnitude. Overall, NEVIS'22 poses an unprecedented challenge "
             'for current sequential learning approaches due to the scale and '
             'diversity of tasks, yet with a low entry barrier as it is '
             'limited to a single modality and well understood supervised '
             'learning problems. Moreover, we provide a reference '
             'implementation including strong baselines and an evaluation '
             'protocol to compare methods in terms of their trade-off between '
             "accuracy and compute. We hope that NEVIS'22 can be useful to "
             'researchers working on continual learning, meta-learning, AutoML '
             'and more generally sequential learning, and help these '
             'communities join forces towards more robust models that '
             'efficiently adapt to a never ending stream of data.',
 'title': 'Nevis’22: A Stream of 100 Tasks Sampled from 30 Years of Computer '
          'Vision Research',
 'url': 'https://deepmind.google/research/publications/32195/'}
2025-01-13 22:34:20,303 - root - INFO - Scraped item: {'abstract': 'Large language models (LLM) have become a critical component in '
             'many applications of machine learning. However, standard '
             'approaches to training LLM require a large number of tightly '
             'interconnected accelerators, with devices exchanging gradients '
             'and other intermediate states at each optimization step.  While '
             'it is difficult to build and maintain a single computing cluster '
             'hosting many accelerators, it might be easier to find several '
             'computing clusters each hosting a smaller number of devices.  In '
             'this work, we propose a distributed optimization algorithm, '
             'Distributed Low-Communication (DiLoCo), that enables training of '
             'language models on islands of devices that are poorly connected. '
             'The approach is a variant of federated averaging, where the '
             'number of inner steps is large, the inner optimizer is AdamW, '
             'and  the outer optimizer is Nesterov momentum. On the widely '
             'used C4 dataset, we show that DiLoCo on 8 workers performs as '
             'well as fully synchronous optimization while communicating 500 '
             'times less. DiLoCo exhibits great robustness to the data '
             'distribution of each worker.  It is also robust to resources '
             'becoming unavailable over time, and vice versa, it can '
             'seamlessly leverage resources that become available during '
             'training.',
 'title': 'DiLoCo: Distributed Low-Communication Training of Language Models',
 'url': 'https://deepmind.google/research/publications/57039/'}
2025-01-13 22:34:20,318 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/57039/>
{'abstract': 'Large language models (LLM) have become a critical component in '
             'many applications of machine learning. However, standard '
             'approaches to training LLM require a large number of tightly '
             'interconnected accelerators, with devices exchanging gradients '
             'and other intermediate states at each optimization step.  While '
             'it is difficult to build and maintain a single computing cluster '
             'hosting many accelerators, it might be easier to find several '
             'computing clusters each hosting a smaller number of devices.  In '
             'this work, we propose a distributed optimization algorithm, '
             'Distributed Low-Communication (DiLoCo), that enables training of '
             'language models on islands of devices that are poorly connected. '
             'The approach is a variant of federated averaging, where the '
             'number of inner steps is large, the inner optimizer is AdamW, '
             'and  the outer optimizer is Nesterov momentum. On the widely '
             'used C4 dataset, we show that DiLoCo on 8 workers performs as '
             'well as fully synchronous optimization while communicating 500 '
             'times less. DiLoCo exhibits great robustness to the data '
             'distribution of each worker.  It is also robust to resources '
             'becoming unavailable over time, and vice versa, it can '
             'seamlessly leverage resources that become available during '
             'training.',
 'title': 'DiLoCo: Distributed Low-Communication Training of Language Models',
 'url': 'https://deepmind.google/research/publications/57039/'}
2025-01-13 22:34:20,359 - root - INFO - Scraped item: {'abstract': 'Globally-scalable route optimization based on human preferences '
             'remains an open problem. Although past work created increasingly '
             'general solutions for the inverse reinforcement learning (IRL) '
             'formulation, these have not been successfully scaled to '
             'world-sized MDPs (200M states), large datasets (110M samples), '
             'and nearly foundation-sized models (360M parameters). In this '
             'work, we surpass this scale through a series of advancements '
             'focused on graph compression, parallelization, and problem '
             'initialization based on dominant eigenvectors. We introduce '
             'Receding Horizon Inverse Planning (RHIP), an approximated IRL '
             'algorithm which generalizes existing work and enables control of '
             'key performance trade-offs via a planning horizon parameter. Our '
             'policy achieves an 18% improvement in global route quality, and, '
             'to our knowledge, is the largest instance of IRL in a real-world '
             'setting to date. We include insightful negative results on '
             'state-of-the-art eigenvalue solvers, and identify future '
             'opportunities to further improve performance via IRL-specific '
             'batching strategies. Our results show critical benefits to more '
             'sustainable modes of transportation (e.g. two-wheelers), where '
             'factors beyond journey time (e.g. route safety) play an outsized '
             'role.',
 'title': 'Massively Scalable Inverse Reinforcement Learning for Route '
          'Optimization',
 'url': 'https://deepmind.google/research/publications/34011/'}
2025-01-13 22:34:20,370 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34011/>
{'abstract': 'Globally-scalable route optimization based on human preferences '
             'remains an open problem. Although past work created increasingly '
             'general solutions for the inverse reinforcement learning (IRL) '
             'formulation, these have not been successfully scaled to '
             'world-sized MDPs (200M states), large datasets (110M samples), '
             'and nearly foundation-sized models (360M parameters). In this '
             'work, we surpass this scale through a series of advancements '
             'focused on graph compression, parallelization, and problem '
             'initialization based on dominant eigenvectors. We introduce '
             'Receding Horizon Inverse Planning (RHIP), an approximated IRL '
             'algorithm which generalizes existing work and enables control of '
             'key performance trade-offs via a planning horizon parameter. Our '
             'policy achieves an 18% improvement in global route quality, and, '
             'to our knowledge, is the largest instance of IRL in a real-world '
             'setting to date. We include insightful negative results on '
             'state-of-the-art eigenvalue solvers, and identify future '
             'opportunities to further improve performance via IRL-specific '
             'batching strategies. Our results show critical benefits to more '
             'sustainable modes of transportation (e.g. two-wheelers), where '
             'factors beyond journey time (e.g. route safety) play an outsized '
             'role.',
 'title': 'Massively Scalable Inverse Reinforcement Learning for Route '
          'Optimization',
 'url': 'https://deepmind.google/research/publications/34011/'}
2025-01-13 22:34:20,411 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/13609/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,490 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/37648/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,601 - root - INFO - Scraped item: {'abstract': 'Language models are increasingly attracting interest from '
             'writers. However, they have limited usefulness for long form '
             'creative writing because they lack long-range semantic '
             'coherence. We address this limitation by applying language '
             'models hierarchically ,in a system we call Dramatron. By '
             'building structural context via prompt chaining, Dramatron can '
             'generate coherent scripts and screenplays complete with a title, '
             'characters, story beats, location descriptions, and dialogue. We '
             'illustrate Dramatron’s usefulness as an interactive co-creative '
             'system with a user-study of 15 theatre and film industry '
             'professionals, who co-wrote theatre scripts and screenplays with '
             'Dramatron and engaged in open-ended interviews. We report '
             'reflections from our interviewees, and from independent '
             'reviewers who watched recent stagings of these works, to '
             'illustrate how both Dramatron and hierarchical text generation '
             'are useful for human-machine co-creativity. Finally, we discuss '
             'the suitability of Dramatron for co-creativity, ethical '
             'considerations–including plagiarism and bias–and participation '
             'models for the design and deployment of such tools.',
 'title': 'Co-Writing Screenplays and Theatre Scripts with Language Models: An '
          'Evaluation by Industry Professionals',
 'url': 'https://deepmind.google/research/publications/13609/'}
2025-01-13 22:34:20,614 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/13609/>
{'abstract': 'Language models are increasingly attracting interest from '
             'writers. However, they have limited usefulness for long form '
             'creative writing because they lack long-range semantic '
             'coherence. We address this limitation by applying language '
             'models hierarchically ,in a system we call Dramatron. By '
             'building structural context via prompt chaining, Dramatron can '
             'generate coherent scripts and screenplays complete with a title, '
             'characters, story beats, location descriptions, and dialogue. We '
             'illustrate Dramatron’s usefulness as an interactive co-creative '
             'system with a user-study of 15 theatre and film industry '
             'professionals, who co-wrote theatre scripts and screenplays with '
             'Dramatron and engaged in open-ended interviews. We report '
             'reflections from our interviewees, and from independent '
             'reviewers who watched recent stagings of these works, to '
             'illustrate how both Dramatron and hierarchical text generation '
             'are useful for human-machine co-creativity. Finally, we discuss '
             'the suitability of Dramatron for co-creativity, ethical '
             'considerations–including plagiarism and bias–and participation '
             'models for the design and deployment of such tools.',
 'title': 'Co-Writing Screenplays and Theatre Scripts with Language Models: An '
          'Evaluation by Industry Professionals',
 'url': 'https://deepmind.google/research/publications/13609/'}
2025-01-13 22:34:20,655 - root - INFO - Scraped item: {'abstract': 'Golden-section search and bisection search are the two main '
             'principled algorithms for 1d minimization of quasiconvex '
             '(unimodal) functions.\n'
             'The first one only uses function queries, while the second one\n'
             'also uses gradient queries.\n'
             'Other algorithms exist under much stronger assumptions, such as '
             "Newton's method for twice-differentiable, strongly convex "
             'functions with Lipschitz gradients.\n'
             'However, to the best of our knowledge, there is no principled '
             'exact line search algorithm that for general convex functions — '
             'including piecewise-linear and max-compositions of convex '
             'functions — that takes advantage of convexity.',
 'title': 'Line Search for Convex Minimization',
 'url': 'https://deepmind.google/research/publications/37648/'}
2025-01-13 22:34:20,668 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/37648/>
{'abstract': 'Golden-section search and bisection search are the two main '
             'principled algorithms for 1d minimization of quasiconvex '
             '(unimodal) functions.\n'
             'The first one only uses function queries, while the second one\n'
             'also uses gradient queries.\n'
             'Other algorithms exist under much stronger assumptions, such as '
             "Newton's method for twice-differentiable, strongly convex "
             'functions with Lipschitz gradients.\n'
             'However, to the best of our knowledge, there is no principled '
             'exact line search algorithm that for general convex functions — '
             'including piecewise-linear and max-compositions of convex '
             'functions — that takes advantage of convexity.',
 'title': 'Line Search for Convex Minimization',
 'url': 'https://deepmind.google/research/publications/37648/'}
2025-01-13 22:34:20,673 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/34416/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,716 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/21589/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,771 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/41485/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,821 - root - INFO - Scraped item: {'abstract': 'Reinforcement Learning (RL) algorithms typically utilize '
             'learning and/or planning techniques to derive effective '
             'policies. The integration of both approaches has proven to be '
             'highly successful in addressing complex sequential '
             'decision-making challenges, as evidenced by algorithms such as '
             'AlphaZero and MuZero, which consolidate the planning process '
             'into a parametric search-policy. AIXI, the most potent '
             'theoretical universal agent, leverages planning through '
             'comprehensive search as its primary means to find an optimal '
             'policy. Here we define an alternative universal agent, which we '
             'call Self-AIXI, that on the contrary to AIXI, maximally exploits '
             'learning to obtain good policies. It does so by self-predicting '
             'its own stream of action data, which is generated, similarly to '
             'other TD(0) agents, by taking an action maximization step over '
             'the current on-policy (universal mixture-policy) Q-value '
             'estimates. We prove that Self-AIXI converges to AIXI, and '
             'inherits a series of properties like maximal Legg-Hutter '
             'intelligence and the self-optimizing property.',
 'title': 'Self-Predictive Universal AI',
 'url': 'https://deepmind.google/research/publications/34416/'}
2025-01-13 22:34:20,834 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/34416/>
{'abstract': 'Reinforcement Learning (RL) algorithms typically utilize '
             'learning and/or planning techniques to derive effective '
             'policies. The integration of both approaches has proven to be '
             'highly successful in addressing complex sequential '
             'decision-making challenges, as evidenced by algorithms such as '
             'AlphaZero and MuZero, which consolidate the planning process '
             'into a parametric search-policy. AIXI, the most potent '
             'theoretical universal agent, leverages planning through '
             'comprehensive search as its primary means to find an optimal '
             'policy. Here we define an alternative universal agent, which we '
             'call Self-AIXI, that on the contrary to AIXI, maximally exploits '
             'learning to obtain good policies. It does so by self-predicting '
             'its own stream of action data, which is generated, similarly to '
             'other TD(0) agents, by taking an action maximization step over '
             'the current on-policy (universal mixture-policy) Q-value '
             'estimates. We prove that Self-AIXI converges to AIXI, and '
             'inherits a series of properties like maximal Legg-Hutter '
             'intelligence and the self-optimizing property.',
 'title': 'Self-Predictive Universal AI',
 'url': 'https://deepmind.google/research/publications/34416/'}
2025-01-13 22:34:20,875 - root - INFO - Scraped item: {'abstract': 'Levin Tree Search (LTS) is a tree/graph search algorithm guided '
             'by a (conditional and contextual) probability distribution over '
             'action sequences. It comes with strong theoretical guarantees on '
             'the search effort required before finding a solution. It also '
             'comes with its own loss function (aka objective function) so '
             'that a parameterized policy can be learnt to minimize the search '
             'effort.',
 'title': 'Levin Tree Search with Context Models',
 'url': 'https://deepmind.google/research/publications/21589/'}
2025-01-13 22:34:20,886 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/21589/>
{'abstract': 'Levin Tree Search (LTS) is a tree/graph search algorithm guided '
             'by a (conditional and contextual) probability distribution over '
             'action sequences. It comes with strong theoretical guarantees on '
             'the search effort required before finding a solution. It also '
             'comes with its own loss function (aka objective function) so '
             'that a parameterized policy can be learnt to minimize the search '
             'effort.',
 'title': 'Levin Tree Search with Context Models',
 'url': 'https://deepmind.google/research/publications/21589/'}
2025-01-13 22:34:20,890 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/16942/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,929 - root - INFO - Scraped item: {'abstract': 'We present a variational Monte Carlo algorithm for estimating '
             'the lowest excited states of a quantum system which is a natural '
             'generalization of the estimation of ground states. The method '
             'requires no explicit orthogonalization of the different states, '
             'instead transforming the problem of finding excited states of a '
             'given system into that of finding the ground state of an '
             'expanded system. Expected values of arbitrary observables can be '
             'calculated, including mixed expectations between different '
             'states such as the transition dipole moment. Although the method '
             'is entirely general, it works particularly well in conjunction '
             'with recent work on using neural networks as variational Ansätze '
             'for many-electron systems, and we show that by combining this '
             'method with the FermiNet and Psiformer Ansätze we can accurately '
             'recover vertical excitation energies and oscillator strengths on '
             'molecules as large as benzene. Beyond the examples on molecules '
             'presented here, we expect this technique will be of great '
             'interest for applications of variational quantum Monte Carlo to '
             'atomic, nuclear and condensed matter physics.',
 'title': 'Natural Quantum Monte Carlo Computation of Excited States',
 'url': 'https://deepmind.google/research/publications/41485/'}
2025-01-13 22:34:20,942 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/41485/>
{'abstract': 'We present a variational Monte Carlo algorithm for estimating '
             'the lowest excited states of a quantum system which is a natural '
             'generalization of the estimation of ground states. The method '
             'requires no explicit orthogonalization of the different states, '
             'instead transforming the problem of finding excited states of a '
             'given system into that of finding the ground state of an '
             'expanded system. Expected values of arbitrary observables can be '
             'calculated, including mixed expectations between different '
             'states such as the transition dipole moment. Although the method '
             'is entirely general, it works particularly well in conjunction '
             'with recent work on using neural networks as variational Ansätze '
             'for many-electron systems, and we show that by combining this '
             'method with the FermiNet and Psiformer Ansätze we can accurately '
             'recover vertical excitation energies and oscillator strengths on '
             'molecules as large as benzene. Beyond the examples on molecules '
             'presented here, we expect this technique will be of great '
             'interest for applications of variational quantum Monte Carlo to '
             'atomic, nuclear and condensed matter physics.',
 'title': 'Natural Quantum Monte Carlo Computation of Excited States',
 'url': 'https://deepmind.google/research/publications/41485/'}
2025-01-13 22:34:20,948 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/38759/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:20,953 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/82491/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,043 - root - INFO - Scraped item: {'abstract': 'We present a machine-learning model based on normalizing flows '
             'that is trained to sample from the isobaric-isothermal ensemble. '
             'In our approach, we approximate the joint distribution of a '
             'fully-flexible triclinic simulation box and particle coordinates '
             'to achieve a desired internal pressure. This novel extension of '
             'flow-based sampling to the isobaric-isothermal ensemble yields '
             'direct estimates of Gibbs free energies. We test our NPT-flow on '
             'monatomic water in the cubic and hexagonal ice phases and find '
             'excellent agreement of Gibbs free energies and other observables '
             'compared with established baselines.',
 'title': 'Estimating Gibbs free energies via isobaric-isothermal flows',
 'url': 'https://deepmind.google/research/publications/16942/'}
2025-01-13 22:34:21,062 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/16942/>
{'abstract': 'We present a machine-learning model based on normalizing flows '
             'that is trained to sample from the isobaric-isothermal ensemble. '
             'In our approach, we approximate the joint distribution of a '
             'fully-flexible triclinic simulation box and particle coordinates '
             'to achieve a desired internal pressure. This novel extension of '
             'flow-based sampling to the isobaric-isothermal ensemble yields '
             'direct estimates of Gibbs free energies. We test our NPT-flow on '
             'monatomic water in the cubic and hexagonal ice phases and find '
             'excellent agreement of Gibbs free energies and other observables '
             'compared with established baselines.',
 'title': 'Estimating Gibbs free energies via isobaric-isothermal flows',
 'url': 'https://deepmind.google/research/publications/16942/'}
2025-01-13 22:34:21,067 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/21083/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,106 - root - INFO - Scraped item: {'abstract': 'For robots to be useful outside labs and factories we need to be '
             'able to teach them new useful behaviors quickly. Current '
             'approaches lack either the generality to onboard new tasks '
             'without task-specific engineering, or else lack the '
             'data-efficiency to do so in an amount of time that enables '
             'practical use. In this work we explore dense tracking as a '
             'representational bottleneck to allow fast and general-purpose '
             'learning from demonstration. Our approach utilizes '
             'Track-Any-Point (TAP) models to isolate the relevant motion in a '
             'demonstration, and parameterize a low-level controller to '
             'reproduce this motion across changes in the scene. We show that '
             'this results in robust robot policies that can solve complex '
             'object-arrangement tasks such as kitting, stacking up to four '
             'objects, and even full path-following tasks such as applying '
             'glue and sticking objects together, all from demonstrations that '
             'can be collected in minutes.',
 'title': 'RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation',
 'url': 'https://deepmind.google/research/publications/38759/'}
2025-01-13 22:34:21,119 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/38759/>
{'abstract': 'For robots to be useful outside labs and factories we need to be '
             'able to teach them new useful behaviors quickly. Current '
             'approaches lack either the generality to onboard new tasks '
             'without task-specific engineering, or else lack the '
             'data-efficiency to do so in an amount of time that enables '
             'practical use. In this work we explore dense tracking as a '
             'representational bottleneck to allow fast and general-purpose '
             'learning from demonstration. Our approach utilizes '
             'Track-Any-Point (TAP) models to isolate the relevant motion in a '
             'demonstration, and parameterize a low-level controller to '
             'reproduce this motion across changes in the scene. We show that '
             'this results in robust robot policies that can solve complex '
             'object-arrangement tasks such as kitting, stacking up to four '
             'objects, and even full path-following tasks such as applying '
             'glue and sticking objects together, all from demonstrations that '
             'can be collected in minutes.',
 'title': 'RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation',
 'url': 'https://deepmind.google/research/publications/38759/'}
2025-01-13 22:34:21,158 - root - INFO - Scraped item: {'abstract': 'A crucial design decision for any robot learning pipeline is the '
             'choice of policy representation: what type of model should be '
             'used to generate the next set of robot actions? Owing to the '
             'inherent multi-modal nature of many robotic tasks, combined with '
             'the recent successes in generative modeling, researchers have '
             'turned to state-of-the-art probabilistic models such as '
             'diffusion models for policy representation. In this work, we '
             'revisit the choice of energy-based models (EBM) as a policy '
             'class. We show that the prevailing folklore---that energy models '
             'in high dimensional continuous spaces are notoriously difficult '
             'to train and hence impractical---is false. We develop a '
             'practical training objective and algorithm for energy models '
             'which combines several key ingredients: (i) ranking noise '
             'contrastive estimation (R-NCE), (ii) learnable negative '
             'samplers, and (iii) non-adversarial joint training. We prove '
             'that our proposed objective function is asymptotically '
             'consistent and quantify its limiting variance. On the other '
             'hand, we show that the Implicit Behavior Cloning (IBC) objective '
             'is actually biased even at the population level, providing a '
             'mathematical explanation for the poor performance of IBC trained '
             'energy policies in several independent follow-up works. We '
             'further extend our algorithm to learn a continuous stochastic '
             'process that bridges noise and data, modeling this process with '
             'a family of EBMs indexed by scale variable. In doing so, we '
             'demonstrate that the core idea behind recent progress in '
             'generative modeling is actually compatible with EBMs. '
             'Altogether, our proposed training algorithms enable us to train '
             'energy based models as policies which compete with---and even '
             'outperform---diffusion models and other state-of-the-art '
             'approaches in several challenging multi-modal benchmarks: '
             'obstacle avoidance path planning and contact-rich block pushing.',
 'title': 'Revisiting Energy Based Models as Policies: Ranking Noise '
          'Contrastive Estimation and Interpolating Energy Models',
 'url': 'https://deepmind.google/research/publications/82491/'}
2025-01-13 22:34:21,172 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/82491/>
{'abstract': 'A crucial design decision for any robot learning pipeline is the '
             'choice of policy representation: what type of model should be '
             'used to generate the next set of robot actions? Owing to the '
             'inherent multi-modal nature of many robotic tasks, combined with '
             'the recent successes in generative modeling, researchers have '
             'turned to state-of-the-art probabilistic models such as '
             'diffusion models for policy representation. In this work, we '
             'revisit the choice of energy-based models (EBM) as a policy '
             'class. We show that the prevailing folklore---that energy models '
             'in high dimensional continuous spaces are notoriously difficult '
             'to train and hence impractical---is false. We develop a '
             'practical training objective and algorithm for energy models '
             'which combines several key ingredients: (i) ranking noise '
             'contrastive estimation (R-NCE), (ii) learnable negative '
             'samplers, and (iii) non-adversarial joint training. We prove '
             'that our proposed objective function is asymptotically '
             'consistent and quantify its limiting variance. On the other '
             'hand, we show that the Implicit Behavior Cloning (IBC) objective '
             'is actually biased even at the population level, providing a '
             'mathematical explanation for the poor performance of IBC trained '
             'energy policies in several independent follow-up works. We '
             'further extend our algorithm to learn a continuous stochastic '
             'process that bridges noise and data, modeling this process with '
             'a family of EBMs indexed by scale variable. In doing so, we '
             'demonstrate that the core idea behind recent progress in '
             'generative modeling is actually compatible with EBMs. '
             'Altogether, our proposed training algorithms enable us to train '
             'energy based models as policies which compete with---and even '
             'outperform---diffusion models and other state-of-the-art '
             'approaches in several challenging multi-modal benchmarks: '
             'obstacle avoidance path planning and contact-rich block pushing.',
 'title': 'Revisiting Energy Based Models as Policies: Ranking Noise '
          'Contrastive Estimation and Interpolating Energy Models',
 'url': 'https://deepmind.google/research/publications/82491/'}
2025-01-13 22:34:21,215 - root - INFO - Scraped item: {'abstract': 'The vast majority of missense variants observed in the human '
             'genome are of unknown clinical significance. We present '
             'AlphaMissense, an adaptation of AlphaFold fine-tuned on human '
             'and primate variant population frequency databases to predict '
             'missense variant pathogenicity. By combining structural context '
             'and evolutionary conservation, our model achieves '
             'state-of-the-art results across a wide range of genetic and '
             'experimental benchmarks, all without explicitly training on such '
             'data. The average pathogenicity score of genes is also '
             'predictive for their cell essentiality, capable of identifying '
             'short essential genes that existing statistical approaches are '
             'underpowered to detect. As a resource to the community, we '
             'provide a database of predictions for all possible human single '
             'amino acid substitutions and classify 89% of missense variants '
             'as either likely benign or likely pathogenic.',
 'title': 'Accurate proteome-wide missense variant effect prediction with '
          'AlphaMissense',
 'url': 'https://deepmind.google/research/publications/21083/'}
2025-01-13 22:34:21,226 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/21083/>
{'abstract': 'The vast majority of missense variants observed in the human '
             'genome are of unknown clinical significance. We present '
             'AlphaMissense, an adaptation of AlphaFold fine-tuned on human '
             'and primate variant population frequency databases to predict '
             'missense variant pathogenicity. By combining structural context '
             'and evolutionary conservation, our model achieves '
             'state-of-the-art results across a wide range of genetic and '
             'experimental benchmarks, all without explicitly training on such '
             'data. The average pathogenicity score of genes is also '
             'predictive for their cell essentiality, capable of identifying '
             'short essential genes that existing statistical approaches are '
             'underpowered to detect. As a resource to the community, we '
             'provide a database of predictions for all possible human single '
             'amino acid substitutions and classify 89% of missense variants '
             'as either likely benign or likely pathogenic.',
 'title': 'Accurate proteome-wide missense variant effect prediction with '
          'AlphaMissense',
 'url': 'https://deepmind.google/research/publications/21083/'}
2025-01-13 22:34:21,415 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/22295/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,520 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/26336/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,555 - root - INFO - Scraped item: {'abstract': 'We show how to "compile" human-readable programs into standard '
             'decoder-only transformer models. Our compiler, Tracr, generates '
             'models with known structure. This structure can be used to '
             'design experiments. For example, we use it to study '
             '"superposition" in transformers that execute multi-step '
             'algorithms. Additionally, the known structure of Tracr-compiled '
             'models can serve as ground-truth for evaluating interpretability '
             'methods. Commonly, because the "programs" learned by '
             'transformers are unknown it is unclear whether an interpretation '
             'succeeded. We demonstrate our approach by implementing and '
             'examining programs including computing token frequencies, '
             'sorting, and parenthesis checking. We provide an open-source '
             'implementation of Tracr '
             'athttps://github.com/google-deepmind/tracr.',
 'title': 'Tracr: Compiled Transformers as a Laboratory for Interpretability',
 'url': 'https://deepmind.google/research/publications/22295/'}
2025-01-13 22:34:21,567 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/22295/>
{'abstract': 'We show how to "compile" human-readable programs into standard '
             'decoder-only transformer models. Our compiler, Tracr, generates '
             'models with known structure. This structure can be used to '
             'design experiments. For example, we use it to study '
             '"superposition" in transformers that execute multi-step '
             'algorithms. Additionally, the known structure of Tracr-compiled '
             'models can serve as ground-truth for evaluating interpretability '
             'methods. Commonly, because the "programs" learned by '
             'transformers are unknown it is unclear whether an interpretation '
             'succeeded. We demonstrate our approach by implementing and '
             'examining programs including computing token frequencies, '
             'sorting, and parenthesis checking. We provide an open-source '
             'implementation of Tracr '
             'athttps://github.com/google-deepmind/tracr.',
 'title': 'Tracr: Compiled Transformers as a Laboratory for Interpretability',
 'url': 'https://deepmind.google/research/publications/22295/'}
2025-01-13 22:34:21,659 - root - INFO - Scraped item: {'abstract': 'We present a novel model for Tracking Any Point (TAP) that '
             'effectively tracks any queried point on any physical surface '
             'throughout a video sequence. Our approach employs two stages: '
             '(1) a matching stage, which independently locates a suitable '
             'candidate point match for the query point on every other frame, '
             'and (2) a refinement stage, which updates both the trajectory '
             'and query features based on local correlations. The resulting '
             'model surpasses all baseline methods by a significant margin on '
             'the TAP-Vid benchmark, as demonstrated by an approximate 20% '
             'absolute average Jaccard (AJ) improvement on DAVIS. Our model '
             'facilitates fast inference on long and high-resolution video '
             'sequences. On a modern GPU, our implementation has the capacity '
             'to track points faster than real-time, and can be flexibly '
             'extended to higher-resolution videos. Given the high-quality '
             'trajectories extracted from a large dataset, we demonstrate a '
             'proof-of-concept diffusion model which generates trajectories '
             'from static images, enabling plausible animations. '
             'Visualizations, source code, and pretrained models can be found '
             'athttps://deepmind-tapir.github.io/',
 'title': 'TAPIR: Tracking Any Point with per-frame Initialization and '
          'temporal Refinement',
 'url': 'https://deepmind.google/research/publications/26336/'}
2025-01-13 22:34:21,673 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/26336/>
{'abstract': 'We present a novel model for Tracking Any Point (TAP) that '
             'effectively tracks any queried point on any physical surface '
             'throughout a video sequence. Our approach employs two stages: '
             '(1) a matching stage, which independently locates a suitable '
             'candidate point match for the query point on every other frame, '
             'and (2) a refinement stage, which updates both the trajectory '
             'and query features based on local correlations. The resulting '
             'model surpasses all baseline methods by a significant margin on '
             'the TAP-Vid benchmark, as demonstrated by an approximate 20% '
             'absolute average Jaccard (AJ) improvement on DAVIS. Our model '
             'facilitates fast inference on long and high-resolution video '
             'sequences. On a modern GPU, our implementation has the capacity '
             'to track points faster than real-time, and can be flexibly '
             'extended to higher-resolution videos. Given the high-quality '
             'trajectories extracted from a large dataset, we demonstrate a '
             'proof-of-concept diffusion model which generates trajectories '
             'from static images, enabling plausible animations. '
             'Visualizations, source code, and pretrained models can be found '
             'athttps://deepmind-tapir.github.io/',
 'title': 'TAPIR: Tracking Any Point with per-frame Initialization and '
          'temporal Refinement',
 'url': 'https://deepmind.google/research/publications/26336/'}
2025-01-13 22:34:21,701 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/14720/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,803 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/56635/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,837 - root - INFO - Scraped item: {'abstract': 'The ability to perceive and understand 3D scenes is crucial for '
             'many applications in computer vision and robotics. Inverse '
             'graphics is an appealing approach to 3D scene understanding that '
             'aims to infer the 3D scene structure from 2D images. In this '
             'paper, we introduce probabilistic modeling to the inverse '
             'graphics framework to quantify uncertainty and achieve '
             'robustness in 6D pose estimation tasks. Specifically, we propose '
             '3D Neural Embedding Likelihood (3DNEL) as a unified '
             'probabilistic model over RGB-D images, and develop efficient '
             'inference procedures on 3D scene descriptions. 3DNEL effectively '
             'combines learned neural embeddings from RGB with depth '
             'information to improve robustness in sim-to-real 6D object pose '
             'estimation from RGB-D images. Performance on the YCB-Video '
             'dataset is on par with state-of-the-art yet is much more robust '
             'in challenging regimes. In contrast to discriminative '
             "approaches, 3DNEL's probabilistic generative formulation jointly "
             'models multiple objects in a scene, quantifies uncertainty in a '
             'principled way, and handles object pose tracking under heavy '
             'occlusion. Finally, 3DNEL provides a principled framework for '
             'incorporating prior knowledge about the scene and objects, which '
             'allows natural extension to additional tasks like camera pose '
             'tracking from video.',
 'title': '3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for '
          'Robust 6D Pose Estimation',
 'url': 'https://deepmind.google/research/publications/14720/'}
2025-01-13 22:34:21,852 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/14720/>
{'abstract': 'The ability to perceive and understand 3D scenes is crucial for '
             'many applications in computer vision and robotics. Inverse '
             'graphics is an appealing approach to 3D scene understanding that '
             'aims to infer the 3D scene structure from 2D images. In this '
             'paper, we introduce probabilistic modeling to the inverse '
             'graphics framework to quantify uncertainty and achieve '
             'robustness in 6D pose estimation tasks. Specifically, we propose '
             '3D Neural Embedding Likelihood (3DNEL) as a unified '
             'probabilistic model over RGB-D images, and develop efficient '
             'inference procedures on 3D scene descriptions. 3DNEL effectively '
             'combines learned neural embeddings from RGB with depth '
             'information to improve robustness in sim-to-real 6D object pose '
             'estimation from RGB-D images. Performance on the YCB-Video '
             'dataset is on par with state-of-the-art yet is much more robust '
             'in challenging regimes. In contrast to discriminative '
             "approaches, 3DNEL's probabilistic generative formulation jointly "
             'models multiple objects in a scene, quantifies uncertainty in a '
             'principled way, and handles object pose tracking under heavy '
             'occlusion. Finally, 3DNEL provides a principled framework for '
             'incorporating prior knowledge about the scene and objects, which '
             'allows natural extension to additional tasks like camera pose '
             'tracking from video.',
 'title': '3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for '
          'Robust 6D Pose Estimation',
 'url': 'https://deepmind.google/research/publications/14720/'}
2025-01-13 22:34:21,863 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/43202/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:21,941 - root - INFO - Scraped item: {'abstract': 'Influence functions (IF) have been seen as a technique for '
             'explaining model predictions through the lens of the training '
             'data. Their utility is assumed to be in identifying training '
             'examples "responsible" for a prediction so that, for example, '
             'correcting a prediction is possible by intervening on those '
             'examples (removing or editing them) and retraining the model. '
             'However, recent empirical studies have shown that the existing '
             'methods of estimating IF predict the leave-one-out-and-retrain '
             'effect poorly.\n'
             'In order to understand the mismatch between the theoretical '
             'promise and the practical results, we analyse five assumptions '
             'made by IF methods which are problematic for modern-scale deep '
             'neural networks and which concern convexity, numeric stability, '
             'training trajectory and parameter divergence. This allows us to '
             'clarify what can be expected theoretically from IF. We show that '
             'while most assumptions can be addressed successfully, the '
             'parameter divergence poses a clear limitation on the predictive '
             'power of IF: influence fades over training time even with '
             'deterministic training. We illustrate this theoretical result '
             'with BERT and ResNet models.\n'
             'Another conclusion from the theoretical analysis is that IF are '
             'still useful for model debugging and correcting even though some '
             'of the assumptions made in prior work do not hold: using natural '
             'language processing and computer vision tasks, we verify that '
             'mis-predictions can be successfully corrected by taking only a '
             'few fine-tuning steps on influential examples.',
 'title': 'Theoretical and Practical Perspectives on what Influence Functions '
          'Do',
 'url': 'https://deepmind.google/research/publications/56635/'}
2025-01-13 22:34:21,956 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/56635/>
{'abstract': 'Influence functions (IF) have been seen as a technique for '
             'explaining model predictions through the lens of the training '
             'data. Their utility is assumed to be in identifying training '
             'examples "responsible" for a prediction so that, for example, '
             'correcting a prediction is possible by intervening on those '
             'examples (removing or editing them) and retraining the model. '
             'However, recent empirical studies have shown that the existing '
             'methods of estimating IF predict the leave-one-out-and-retrain '
             'effect poorly.\n'
             'In order to understand the mismatch between the theoretical '
             'promise and the practical results, we analyse five assumptions '
             'made by IF methods which are problematic for modern-scale deep '
             'neural networks and which concern convexity, numeric stability, '
             'training trajectory and parameter divergence. This allows us to '
             'clarify what can be expected theoretically from IF. We show that '
             'while most assumptions can be addressed successfully, the '
             'parameter divergence poses a clear limitation on the predictive '
             'power of IF: influence fades over training time even with '
             'deterministic training. We illustrate this theoretical result '
             'with BERT and ResNet models.\n'
             'Another conclusion from the theoretical analysis is that IF are '
             'still useful for model debugging and correcting even though some '
             'of the assumptions made in prior work do not hold: using natural '
             'language processing and computer vision tasks, we verify that '
             'mis-predictions can be successfully corrected by taking only a '
             'few fine-tuning steps on influential examples.',
 'title': 'Theoretical and Practical Perspectives on what Influence Functions '
          'Do',
 'url': 'https://deepmind.google/research/publications/56635/'}
2025-01-13 22:34:22,005 - root - INFO - Scraped item: {'abstract': 'Understanding how climate change affects us and learning about '
             'available solutions are key steps toward empowering individuals '
             'and communities to mitigate and adapt successfully. As Large '
             'Language Models (LLMs) rise in popularity, it is necessary to '
             'assess their capability in this domain. In this study, we '
             'present a comprehensive evaluation framework, grounded in '
             'science communication principles, to analyze LLM responses on '
             'climate change topics. This framework emphasizes both the '
             'presentational and epistemological adequacy of answers, offering '
             'a fine-grained analysis of LLM response systems. Spanning 8 '
             'dimensions, our framework discerns up to 30 distinct issues in '
             'model outputs. The task is an excellent real-world example for a '
             'growing number of problems where LLM abilities can exceed those '
             'of humans. To address these challenges, we provide a practical '
             'protocol for scalable oversight using AI assistance, and rely on '
             'raters with relevant educational background. We evaluate several '
             'recent LLMs and conduct a thorough analysis of the results. Our '
             'comprehensive analysis sheds light on the potential and '
             'limitations of LLMs in the realm of climate communication.',
 'title': 'Assessing LLMs on Climate Information',
 'url': 'https://deepmind.google/research/publications/43202/'}
2025-01-13 22:34:22,017 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/43202/>
{'abstract': 'Understanding how climate change affects us and learning about '
             'available solutions are key steps toward empowering individuals '
             'and communities to mitigate and adapt successfully. As Large '
             'Language Models (LLMs) rise in popularity, it is necessary to '
             'assess their capability in this domain. In this study, we '
             'present a comprehensive evaluation framework, grounded in '
             'science communication principles, to analyze LLM responses on '
             'climate change topics. This framework emphasizes both the '
             'presentational and epistemological adequacy of answers, offering '
             'a fine-grained analysis of LLM response systems. Spanning 8 '
             'dimensions, our framework discerns up to 30 distinct issues in '
             'model outputs. The task is an excellent real-world example for a '
             'growing number of problems where LLM abilities can exceed those '
             'of humans. To address these challenges, we provide a practical '
             'protocol for scalable oversight using AI assistance, and rely on '
             'raters with relevant educational background. We evaluate several '
             'recent LLMs and conduct a thorough analysis of the results. Our '
             'comprehensive analysis sheds light on the potential and '
             'limitations of LLMs in the realm of climate communication.',
 'title': 'Assessing LLMs on Climate Information',
 'url': 'https://deepmind.google/research/publications/43202/'}
2025-01-13 22:34:22,032 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/51283/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:22,172 - root - INFO - Scraped item: {'abstract': 'Chain-of-thought (CoT) prompting for language models '
             'demonstrates impressive performance across reasoning tasks, but '
             'typically demands labeled exemplars of the reasoning process. In '
             'this work, we introduce a new prompting approach, analogical '
             'reasoning, designed to automatically guide the reasoning process '
             'of large language models. Drawing inspiration from how humans '
             'recall relevant past experiences when addressing new challenges, '
             'our approach makes language models self-generate relevant '
             'exemplars or lessons in the context, before proceeding to solve '
             'the given problem. This method presents several advantages: it '
             'obviates the need for manual annotation or external data '
             'retrieval, offering generality and convenience, while also '
             'tailoring generated exemplars to each unique problem, offering '
             'adaptability. Experimental results show that our approach '
             'outperforms 0-shot CoT and few-shot CoT in a variety of '
             'reasoning tasks, including math problem solving in GSM8K and '
             'MATH, code generation in Codeforces, and other reasoning tasks '
             'in BIG-Bench, with an average accuracy gain of +5%.',
 'title': 'Large Language Models as Analogical Reasoners',
 'url': 'https://deepmind.google/research/publications/51283/'}
2025-01-13 22:34:22,186 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/51283/>
{'abstract': 'Chain-of-thought (CoT) prompting for language models '
             'demonstrates impressive performance across reasoning tasks, but '
             'typically demands labeled exemplars of the reasoning process. In '
             'this work, we introduce a new prompting approach, analogical '
             'reasoning, designed to automatically guide the reasoning process '
             'of large language models. Drawing inspiration from how humans '
             'recall relevant past experiences when addressing new challenges, '
             'our approach makes language models self-generate relevant '
             'exemplars or lessons in the context, before proceeding to solve '
             'the given problem. This method presents several advantages: it '
             'obviates the need for manual annotation or external data '
             'retrieval, offering generality and convenience, while also '
             'tailoring generated exemplars to each unique problem, offering '
             'adaptability. Experimental results show that our approach '
             'outperforms 0-shot CoT and few-shot CoT in a variety of '
             'reasoning tasks, including math problem solving in GSM8K and '
             'MATH, code generation in Codeforces, and other reasoning tasks '
             'in BIG-Bench, with an average accuracy gain of +5%.',
 'title': 'Large Language Models as Analogical Reasoners',
 'url': 'https://deepmind.google/research/publications/51283/'}
2025-01-13 22:34:22,217 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/48252/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:22,299 - scrapy.core.engine - DEBUG - Crawled (200) <GET https://deepmind.google/research/publications/29062/> (referer: https://deepmind.google/research/publications/?page=9)
2025-01-13 22:34:22,391 - root - INFO - Scraped item: {'abstract': 'Large Language Models (LLMs) have emerged as a groundbreaking '
             'technology with their unparalleled text generation capabilities '
             'across various applications. Nevertheless, concerns persist '
             'regarding the accuracy and appropriateness of their generated '
             'content. A contemporary methodology, self-correction, has been '
             'proposed as a remedy to these issues. Building upon this '
             'premise, this paper critically examines the role and efficacy of '
             'self-correction within LLMs, shedding light on its true '
             'potential and limitations. Central to our investigation is the '
             'notion of intrinsic self-correction, whereby an LLM attempts to '
             'correct its initial responses based solely on its inherent '
             'capabilities, without any external feedback. Contrary to popular '
             'belief, our research indicates that LLMs might find this task '
             'challenging, especially in the context of reasoning, and at '
             'times, their performance might even degrade post '
             'self-correction. Given our findings, we encourage the community '
             'to approach this concept with both prudence and critical '
             'consideration.',
 'title': 'Large Language Models Cannot Self-Correct Reasoning Yet',
 'url': 'https://deepmind.google/research/publications/48252/'}
2025-01-13 22:34:22,404 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/48252/>
{'abstract': 'Large Language Models (LLMs) have emerged as a groundbreaking '
             'technology with their unparalleled text generation capabilities '
             'across various applications. Nevertheless, concerns persist '
             'regarding the accuracy and appropriateness of their generated '
             'content. A contemporary methodology, self-correction, has been '
             'proposed as a remedy to these issues. Building upon this '
             'premise, this paper critically examines the role and efficacy of '
             'self-correction within LLMs, shedding light on its true '
             'potential and limitations. Central to our investigation is the '
             'notion of intrinsic self-correction, whereby an LLM attempts to '
             'correct its initial responses based solely on its inherent '
             'capabilities, without any external feedback. Contrary to popular '
             'belief, our research indicates that LLMs might find this task '
             'challenging, especially in the context of reasoning, and at '
             'times, their performance might even degrade post '
             'self-correction. Given our findings, we encourage the community '
             'to approach this concept with both prudence and critical '
             'consideration.',
 'title': 'Large Language Models Cannot Self-Correct Reasoning Yet',
 'url': 'https://deepmind.google/research/publications/48252/'}
2025-01-13 22:34:22,443 - root - INFO - Scraped item: {'abstract': 'The Nash equilibrium—a combination of choices by the players of '
             'a game from which no self-interested player would deviate—is the '
             'predominant solution concept in game theory. Even though every '
             'game has a Nash equilibrium, it is not known whether there are '
             'deterministic behaviors of the players who play a game '
             'repeatedly that are guaranteed to converge to a Nash equilibrium '
             'of the game from all starting points. If one assumes that the '
             'players’ behavior is a discrete-time or continuous-time rule '
             'whereby the current mixed strategy profile is mapped to the '
             'next, this question becomes a problem in the theory of dynamical '
             'systems. We apply this theory, and in particular Conley index '
             'theory, to prove a general impossibility result: There exist '
             'games, for which all game dynamics fail to converge to Nash '
             'equilibria from all starting points. The games which help prove '
             'this impossibility result are degenerate, but we conjecture that '
             'the same result holds, under computational complexity '
             'assumptions, for nondegenerate games. We also prove a stronger '
             'impossibility result for the solution concept of approximate '
             'Nash equilibria: For a set of games of positive measure, no game '
             'dynamics can converge to the set of approximate Nash equilibria '
             'for a sufficiently small yet substantial approximation bound. '
             'Our results establish that, although the notions of Nash '
             'equilibrium and its computation-inspired approximations are '
             'universally applicable in all games, they are fundamentally '
             'incomplete as predictors of long-term player behavior.',
 'title': 'An Impossibility Theorem in Game Dynamics',
 'url': 'https://deepmind.google/research/publications/29062/'}
2025-01-13 22:34:22,455 - scrapy.core.scraper - DEBUG - Scraped from <200 https://deepmind.google/research/publications/29062/>
{'abstract': 'The Nash equilibrium—a combination of choices by the players of '
             'a game from which no self-interested player would deviate—is the '
             'predominant solution concept in game theory. Even though every '
             'game has a Nash equilibrium, it is not known whether there are '
             'deterministic behaviors of the players who play a game '
             'repeatedly that are guaranteed to converge to a Nash equilibrium '
             'of the game from all starting points. If one assumes that the '
             'players’ behavior is a discrete-time or continuous-time rule '
             'whereby the current mixed strategy profile is mapped to the '
             'next, this question becomes a problem in the theory of dynamical '
             'systems. We apply this theory, and in particular Conley index '
             'theory, to prove a general impossibility result: There exist '
             'games, for which all game dynamics fail to converge to Nash '
             'equilibria from all starting points. The games which help prove '
             'this impossibility result are degenerate, but we conjecture that '
             'the same result holds, under computational complexity '
             'assumptions, for nondegenerate games. We also prove a stronger '
             'impossibility result for the solution concept of approximate '
             'Nash equilibria: For a set of games of positive measure, no game '
             'dynamics can converge to the set of approximate Nash equilibria '
             'for a sufficiently small yet substantial approximation bound. '
             'Our results establish that, although the notions of Nash '
             'equilibrium and its computation-inspired approximations are '
             'universally applicable in all games, they are fundamentally '
             'incomplete as predictors of long-term player behavior.',
 'title': 'An Impossibility Theorem in Game Dynamics',
 'url': 'https://deepmind.google/research/publications/29062/'}
2025-01-13 22:34:22,460 - scrapy.core.engine - INFO - Closing spider (finished)
2025-01-13 22:34:22,466 - scrapy.statscollectors - INFO - Dumping Scrapy stats:
{'downloader/request_bytes': 57927,
 'downloader/request_count': 189,
 'downloader/request_method_count/GET': 189,
 'downloader/response_bytes': 2902968,
 'downloader/response_count': 189,
 'downloader/response_status_count/200': 188,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 28.430974,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 14, 6, 34, 22, 461678, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 14120419,
 'httpcompression/response_count': 189,
 'item_scraped_count': 179,
 'items_per_minute': None,
 'log_count/DEBUG': 397,
 'log_count/INFO': 198,
 'request_depth_max': 9,
 'response_received_count': 189,
 'responses_per_minute': None,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 188,
 'scheduler/dequeued/memory': 188,
 'scheduler/enqueued': 188,
 'scheduler/enqueued/memory': 188,
 'start_time': datetime.datetime(2025, 1, 14, 6, 33, 54, 30704, tzinfo=datetime.timezone.utc)}
2025-01-13 22:34:22,469 - scrapy.core.engine - INFO - Spider closed (finished)
